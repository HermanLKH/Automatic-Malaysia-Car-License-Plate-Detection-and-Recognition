{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "493b766c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cuda\n"
     ]
    }
   ],
   "source": [
    "# cell 1\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from config import (IMG_HEIGHT, IMG_WIDTH, NUM_FIDUCIAL,\n",
    "                    INPUT_CHANNEL, OUTPUT_CHANNEL, HIDDEN_SIZE,\n",
    "                    CHARACTERS, MAX_LABEL_LENGTH)\n",
    "from dataset import LmdbDataset, AlignCollate\n",
    "# from utils import CTCLabelConverter, Averager\n",
    "from utils import AttnLabelConverter, Averager\n",
    "from model import CRNN\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Running on\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2c361de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All seeds set to 300188, cudnn.deterministic=True\n"
     ]
    }
   ],
   "source": [
    "# ─── cell 0: reproducibility ────────────────────────────────────────────────\n",
    "SEED = 300188\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# Make cuDNN deterministic (slower but reproducible)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "print(f\"All seeds set to {SEED}, cudnn.deterministic={torch.backends.cudnn.deterministic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea60e7b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 884 valid samples from lmdb_data/train\n",
      "Loaded 252 valid samples from lmdb_data/val\n",
      "884 train / 252 val samples\n"
     ]
    }
   ],
   "source": [
    "# cell 2\n",
    "# paths to your LMDBs\n",
    "train_lmdb = \"lmdb_data/train\"\n",
    "val_lmdb   = \"lmdb_data/val\"\n",
    "\n",
    "# instantiate datasets\n",
    "train_dataset = LmdbDataset(train_lmdb)\n",
    "val_dataset   = LmdbDataset(val_lmdb)\n",
    "\n",
    "# collate_fn resizes + normalizes\n",
    "collate_fn = AlignCollate(\n",
    "    imgH=IMG_HEIGHT, imgW=IMG_WIDTH, keep_ratio_with_pad=False\n",
    ")\n",
    "\n",
    "# loaders\n",
    "BATCH_SIZE = 32\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "    num_workers=0, collate_fn=collate_fn, pin_memory=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "    num_workers=0, collate_fn=collate_fn, pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"{len(train_dataset)} train / {len(val_dataset)} val samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e3d612b",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter   = AttnLabelConverter(CHARACTERS)\n",
    "num_classes = len(converter.character)   # includes [GO] and [s]\n",
    "\n",
    "model = CRNN(\n",
    "    IMG_HEIGHT,      # imgH\n",
    "    IMG_WIDTH,       # imgW\n",
    "    INPUT_CHANNEL,   # input_channel\n",
    "    OUTPUT_CHANNEL,  # output_channel\n",
    "    HIDDEN_SIZE,     # hidden_size\n",
    "    num_classes,     # num_classes (with GO/s)\n",
    "    True,            # use_attention\n",
    "    NUM_FIDUCIAL     # num_fiducial\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0).to(device)\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=1.0)\n",
    "\n",
    "model.Transformation = nn.Identity() # <-- no transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a80e2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── cell 4: validate (Attention) ─────────────────────────────────────────────\n",
    "NUM_EPOCHS       = 500\n",
    "PRINT_EVERY      = len(train_dataset) // BATCH_SIZE + 1\n",
    "PATIENCE       = 100          # stop if no val_acc ↑ for 50 epochs\n",
    "\n",
    "def validate(model, loader):\n",
    "    model.eval()\n",
    "    avg_loss = Averager()\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, texts in loader:\n",
    "            images = images.to(device)\n",
    "\n",
    "            # encode full text → shape [B, L+1], plus lengths\n",
    "            text, length = converter.encode(texts, batch_max_length=MAX_LABEL_LENGTH)\n",
    "            text_input  = text[:, :-1].to(device)  # drop final [s]\n",
    "            text_target = text[:,  1:].to(device)  # everything after [GO]\n",
    "\n",
    "            # forward\n",
    "            preds = model(images, text_input, is_train=False,\n",
    "                          batch_max_length=MAX_LABEL_LENGTH)\n",
    "            B, S, C = preds.size()\n",
    "\n",
    "            # cross‐entropy over (B×S) predictions\n",
    "            loss = criterion(\n",
    "                preds.view(B * S, C),\n",
    "                text_target.contiguous().view(B * S)\n",
    "            )\n",
    "            avg_loss.add(loss)\n",
    "\n",
    "            # greedy decode\n",
    "            _, pred_inds = preds.max(2)                   # [B, S]\n",
    "            pred_strs = converter.decode(pred_inds, length)  # pass length\n",
    "\n",
    "            # strip off anything after the \"[s]\" token\n",
    "            pred_strs = [s.split('[s]')[0] for s in pred_strs]\n",
    "\n",
    "            total += len(texts)\n",
    "            correct += sum(p == g for p, g in zip(pred_strs, texts))\n",
    "\n",
    "    acc = correct / total * 100\n",
    "    return avg_loss.val(), acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36d430a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded pretrained Attn weights\n"
     ]
    }
   ],
   "source": [
    "# ─── cell 5: load pretrained CTC weights (skip old Prediction head) ────────────\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "orig      = torch.load(\"pretrained_model/TPS-ResNet-BiLSTM-Attn.pth\", map_location=device)\n",
    "# strip off the \"module.\" prefix if you wrapped in DataParallel\n",
    "stripped  = OrderedDict((k[len(\"module.\"):], v)\n",
    "                        for k, v in orig.items()\n",
    "                        if k.startswith(\"module.\"))\n",
    "\n",
    "own = model.state_dict()\n",
    "for k, v in stripped.items():\n",
    "    # skip the old attention head entirely\n",
    "    if k.startswith(\"Prediction.\") or k.startswith(\"Transformation.\"):\n",
    "        continue\n",
    "    # only overwrite if shapes match\n",
    "    if k in own and v.size() == own[k].size():\n",
    "        own[k] = v\n",
    "\n",
    "model.load_state_dict(own)\n",
    "print(\"✅ Loaded pretrained Attn weights\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d861ce44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Starting epoch 1  (printing every 28 iters)\n",
      "[Epoch 1] iter 28/28, avg loss: 3.2293\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "DAF7469                   | 83                        | 0.2460\n",
      "ANF8688                   | 888                       | 0.2279\n",
      "TDB7888                   | 73                        | 0.2391\n",
      "QAE2205                   | 9                         | 0.2438\n",
      "QTD33                     | 93                        | 0.2377\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 1 done in 2.2s | train_loss=3.2293  valid_loss=2.9961  valid_acc=0.00%\n",
      "\n",
      "no improvement for 1/100 epochs\n",
      "\n",
      "→ Starting epoch 2  (printing every 28 iters)\n",
      "[Epoch 2] iter 28/28, avg loss: 2.7912\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WB4567T                   | QQA77777777               | 0.3154\n",
      "VJN2867                   | QWW8222222                | 0.3260\n",
      "AMB8327                   | QQW22222222               | 0.3345\n",
      "MDV8552                   | QQA333333                 | 0.3254\n",
      "W3426P                    | QQA22222                  | 0.4296\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 2 done in 2.0s | train_loss=2.7912  valid_loss=2.9033  valid_acc=0.00%\n",
      "\n",
      "no improvement for 2/100 epochs\n",
      "\n",
      "→ Starting epoch 3  (printing every 28 iters)\n",
      "[Epoch 3] iter 28/28, avg loss: 2.4893\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QKT8216                   | QBB88                     | 0.5875\n",
      "VAT4116                   | QQA55                     | 0.5035\n",
      "SD2367N                   | QQ550                     | 0.5221\n",
      "RC9863                    | QJB333                    | 0.5474\n",
      "NAD9748                   | QAA771                    | 0.5206\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 3 done in 2.0s | train_loss=2.4893  valid_loss=2.3276  valid_acc=0.00%\n",
      "\n",
      "no improvement for 3/100 epochs\n",
      "\n",
      "→ Starting epoch 4  (printing every 28 iters)\n",
      "[Epoch 4] iter 28/28, avg loss: 2.2478\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "JFR4363                   | QB333                     | 0.5012\n",
      "QRS3073                   | QA333                     | 0.4915\n",
      "VJL3065                   | WJ666                     | 0.4362\n",
      "JLC8890                   | QB9999                    | 0.4494\n",
      "TCF8978                   | QB9999                    | 0.4460\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 4 done in 2.0s | train_loss=2.2478  valid_loss=2.3877  valid_acc=0.00%\n",
      "\n",
      "no improvement for 4/100 epochs\n",
      "\n",
      "→ Starting epoch 5  (printing every 28 iters)\n",
      "[Epoch 5] iter 28/28, avg loss: 2.0865\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WFK2926                   | WW2222                    | 0.4324\n",
      "TCJ8981                   | QB88888                   | 0.4624\n",
      "JV271                     | VW7711                    | 0.3801\n",
      "BJM8453                   | QBB88                     | 0.4358\n",
      "KDU3612                   | QCB611                    | 0.3965\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 5 done in 1.9s | train_loss=2.0865  valid_loss=1.9942  valid_acc=0.00%\n",
      "\n",
      "no improvement for 5/100 epochs\n",
      "\n",
      "→ Starting epoch 6  (printing every 28 iters)\n",
      "[Epoch 6] iter 28/28, avg loss: 1.8726\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WC7447Q                   | QAA7777                   | 0.4173\n",
      "QTD33                     | VD3333                    | 0.5621\n",
      "MDV8552                   | JJ5552                    | 0.4858\n",
      "BQL4682                   | QA4622                    | 0.4616\n",
      "BNB8655                   | JJ6655                    | 0.4905\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 6 done in 1.9s | train_loss=1.8726  valid_loss=1.8732  valid_acc=0.00%\n",
      "\n",
      "no improvement for 6/100 epochs\n",
      "\n",
      "→ Starting epoch 7  (printing every 28 iters)\n",
      "[Epoch 7] iter 28/28, avg loss: 1.6541\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WJH663                    | WHH6633                   | 0.6214\n",
      "VFH2157                   | VWU277                    | 0.4666\n",
      "WB5779C                   | BB7777                    | 0.5112\n",
      "JGA2946                   | QAA2666                   | 0.5822\n",
      "QAA8698P                  | QAA8888                   | 0.6016\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 7 done in 1.9s | train_loss=1.6541  valid_loss=1.8699  valid_acc=0.00%\n",
      "\n",
      "no improvement for 7/100 epochs\n",
      "\n",
      "→ Starting epoch 8  (printing every 28 iters)\n",
      "[Epoch 8] iter 28/28, avg loss: 1.5360\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAA7228U                  | QAA7222                   | 0.6300\n",
      "JJT5762                   | JJJ7766                   | 0.6376\n",
      "VBV198                    | VVB1998                   | 0.5099\n",
      "FG8999                    | JDD99999                  | 0.5868\n",
      "QCK2525                   | QCC2555                   | 0.6128\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 8 done in 1.9s | train_loss=1.5360  valid_loss=1.5921  valid_acc=0.40%\n",
      "\n",
      "💾 New best model saved (epoch 8, val_acc=0.40%)\n",
      "\n",
      "→ Starting epoch 9  (printing every 28 iters)\n",
      "[Epoch 9] iter 28/28, avg loss: 1.2962\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "SMK5                      | SMK555                    | 0.5966\n",
      "VEN6862                   | VNN8622                   | 0.6639\n",
      "QKW3360                   | QW33660                   | 0.6073\n",
      "T/BB578                   | BBB5888                   | 0.6823\n",
      "MDV8552                   | JJ88522                   | 0.5771\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 9 done in 2.0s | train_loss=1.2962  valid_loss=1.3431  valid_acc=1.59%\n",
      "\n",
      "💾 New best model saved (epoch 9, val_acc=1.59%)\n",
      "\n",
      "→ Starting epoch 10  (printing every 28 iters)\n",
      "[Epoch 10] iter 28/28, avg loss: 1.1552\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "JCY7217                   | JCY217                    | 0.6444\n",
      "SJB6000                   | JJB000                    | 0.6568\n",
      "TCC1724                   | WC1124                    | 0.6215\n",
      "QBB9955                   | QB9955                    | 0.7457\n",
      "JTW5239                   | VW5599                    | 0.6575\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 10 done in 1.9s | train_loss=1.1552  valid_loss=1.5822  valid_acc=3.17%\n",
      "\n",
      "💾 New best model saved (epoch 10, val_acc=3.17%)\n",
      "\n",
      "→ Starting epoch 11  (printing every 28 iters)\n",
      "[Epoch 11] iter 28/28, avg loss: 0.9724\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "ABE8012                   | BBB8122                   | 0.6427\n",
      "VFV2696                   | JFG2666                   | 0.6057\n",
      "NEA9731                   | AEE9711                   | 0.5876\n",
      "DBR9492                   | BBB4422                   | 0.6240\n",
      "T/JA7639                  | TAA6639                   | 0.6055\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 11 done in 1.8s | train_loss=0.9724  valid_loss=1.2604  valid_acc=7.94%\n",
      "\n",
      "💾 New best model saved (epoch 11, val_acc=7.94%)\n",
      "\n",
      "→ Starting epoch 12  (printing every 28 iters)\n",
      "[Epoch 12] iter 28/28, avg loss: 0.6949\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WGS3960                   | WGS3900                   | 0.7879\n",
      "WA3593F                   | WAA399F                   | 0.7359\n",
      "WTP2102                   | WTP2102                   | 0.8151\n",
      "T/BD8758                  | T/B8758                   | 0.6942\n",
      "WGT7178                   | WGT7178                   | 0.7605\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 12 done in 1.8s | train_loss=0.6949  valid_loss=0.8378  valid_acc=42.46%\n",
      "\n",
      "💾 New best model saved (epoch 12, val_acc=42.46%)\n",
      "\n",
      "→ Starting epoch 13  (printing every 28 iters)\n",
      "[Epoch 13] iter 28/28, avg loss: 0.6452\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VHW6283                   | WHH6883                   | 0.6205\n",
      "TT9184                    | TT99844                   | 0.6187\n",
      "QRU2519                   | QUU211                    | 0.6728\n",
      "KDS3030                   | KDS330                    | 0.7577\n",
      "VLU1213                   | VLU121                    | 0.7447\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 13 done in 1.8s | train_loss=0.6452  valid_loss=1.0467  valid_acc=23.41%\n",
      "\n",
      "no improvement for 1/100 epochs\n",
      "\n",
      "→ Starting epoch 14  (printing every 28 iters)\n",
      "[Epoch 14] iter 28/28, avg loss: 0.5123\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QMU595                    | QMU595                    | 0.8759\n",
      "JWA8158                   | AAA8158                   | 0.7344\n",
      "MDS7934                   | MDS7934                   | 0.8406\n",
      "WLC9954                   | WLC9954                   | 0.8302\n",
      "BCU7612                   | QAG7612                   | 0.7012\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 14 done in 1.8s | train_loss=0.5123  valid_loss=0.8313  valid_acc=40.48%\n",
      "\n",
      "no improvement for 2/100 epochs\n",
      "\n",
      "→ Starting epoch 15  (printing every 28 iters)\n",
      "[Epoch 15] iter 28/28, avg loss: 0.4104\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "PPA4817                   | PPP8811                   | 0.6901\n",
      "T/JA6344                  | T/JA6344                  | 0.8763\n",
      "WMX9993                   | WMX9993                   | 0.9324\n",
      "JNB388                    | JNB3888                   | 0.9024\n",
      "HWE8782                   | HWE8782                   | 0.8464\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 15 done in 1.8s | train_loss=0.4104  valid_loss=0.8504  valid_acc=44.05%\n",
      "\n",
      "💾 New best model saved (epoch 15, val_acc=44.05%)\n",
      "\n",
      "→ Starting epoch 16  (printing every 28 iters)\n",
      "[Epoch 16] iter 28/28, avg loss: 0.4735\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAA7649N                  | QAA764NN                  | 0.7704\n",
      "QSP5188                   | QRR5188                   | 0.7404\n",
      "BRW3368                   | BRW3368                   | 0.9320\n",
      "QAW7097                   | QAW7097                   | 0.9446\n",
      "VFV2696                   | VFV2696                   | 0.7900\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 16 done in 1.8s | train_loss=0.4735  valid_loss=0.7780  valid_acc=48.81%\n",
      "\n",
      "💾 New best model saved (epoch 16, val_acc=48.81%)\n",
      "\n",
      "→ Starting epoch 17  (printing every 28 iters)\n",
      "[Epoch 17] iter 28/28, avg loss: 0.2753\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "PKA440                    | KAA440                    | 0.7982\n",
      "MBP8122                   | MBP8122                   | 0.9174\n",
      "SJF5203                   | PJJ5203                   | 0.7436\n",
      "VHG1732                   | VHG1732                   | 0.9059\n",
      "VBKL364                   | VBK3364                   | 0.8631\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 17 done in 1.8s | train_loss=0.2753  valid_loss=0.7578  valid_acc=48.02%\n",
      "\n",
      "no improvement for 1/100 epochs\n",
      "\n",
      "→ Starting epoch 18  (printing every 28 iters)\n",
      "[Epoch 18] iter 28/28, avg loss: 0.3276\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAX6845                   | QAX6845                   | 0.9571\n",
      "JUS8529                   | JUS8529                   | 0.8731\n",
      "VJA520                    | VJA520                    | 0.9001\n",
      "JVH1978                   | JVH1978                   | 0.9215\n",
      "QAA1918D                  | QAA1918D                  | 0.8996\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 18 done in 1.9s | train_loss=0.3276  valid_loss=0.7450  valid_acc=52.78%\n",
      "\n",
      "💾 New best model saved (epoch 18, val_acc=52.78%)\n",
      "\n",
      "→ Starting epoch 19  (printing every 28 iters)\n",
      "[Epoch 19] iter 28/28, avg loss: 0.1808\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QTV6692                   | QTV6692                   | 0.9308\n",
      "QAA65T                    | QAA65TT                   | 0.8676\n",
      "NCY8966                   | NCY8966                   | 0.9499\n",
      "QAB6561A                  | QAB6361A                  | 0.8643\n",
      "BLX6662                   | BLX6662                   | 0.9492\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 19 done in 1.9s | train_loss=0.1808  valid_loss=0.8541  valid_acc=50.79%\n",
      "\n",
      "no improvement for 1/100 epochs\n",
      "\n",
      "→ Starting epoch 20  (printing every 28 iters)\n",
      "[Epoch 20] iter 28/28, avg loss: 0.2303\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "BLJ6613                   | BLJ6613                   | 0.9263\n",
      "W/TP3358                  | W/TP3358                  | 0.8476\n",
      "QLB8533                   | QLB8533                   | 0.9447\n",
      "VLS3922                   | VLS3922                   | 0.9682\n",
      "JGA2946                   | JGA2946                   | 0.9391\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 20 done in 1.9s | train_loss=0.2303  valid_loss=0.8218  valid_acc=53.57%\n",
      "\n",
      "💾 New best model saved (epoch 20, val_acc=53.57%)\n",
      "\n",
      "→ Starting epoch 21  (printing every 28 iters)\n",
      "[Epoch 21] iter 28/28, avg loss: 0.2659\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "ALA1689                   | ALA1689                   | 0.9448\n",
      "WTT1097                   | WTT1097                   | 0.8231\n",
      "QLA8686                   | QLA8686                   | 0.9536\n",
      "TCA7899                   | TCA7899                   | 0.9723\n",
      "JVY4767                   | VYY4767                   | 0.7673\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 21 done in 1.9s | train_loss=0.2659  valid_loss=0.8126  valid_acc=52.78%\n",
      "\n",
      "no improvement for 1/100 epochs\n",
      "\n",
      "→ Starting epoch 22  (printing every 28 iters)\n",
      "[Epoch 22] iter 28/28, avg loss: 0.1441\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "TCJ8981                   | TCJ8981                   | 0.8763\n",
      "AMT5830                   | AMT5830                   | 0.9703\n",
      "QMA3390                   | QMA3390                   | 0.9769\n",
      "PMU3220                   | PMU3220                   | 0.9457\n",
      "QAE2205                   | QAE2205                   | 0.9213\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 22 done in 2.0s | train_loss=0.1441  valid_loss=0.8243  valid_acc=54.76%\n",
      "\n",
      "💾 New best model saved (epoch 22, val_acc=54.76%)\n",
      "\n",
      "→ Starting epoch 23  (printing every 28 iters)\n",
      "[Epoch 23] iter 28/28, avg loss: 0.1038\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VJG3205                   | VJG3205                   | 0.9076\n",
      "JVV4188                   | JVV4188                   | 0.9396\n",
      "QCG650                    | QCG650                    | 0.9228\n",
      "WXP416                    | WXP416                    | 0.9619\n",
      "NH2225                    | NH2225                    | 0.9375\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 23 done in 1.9s | train_loss=0.1038  valid_loss=0.8487  valid_acc=51.98%\n",
      "\n",
      "no improvement for 1/100 epochs\n",
      "\n",
      "→ Starting epoch 24  (printing every 28 iters)\n",
      "[Epoch 24] iter 28/28, avg loss: 0.1550\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "PKV4279                   | PKV4277                   | 0.9220\n",
      "AHU7727                   | AHU7727                   | 0.9495\n",
      "T/BD8758                  | T/BD8777                  | 0.8583\n",
      "WYJ7760                   | WYJ7760                   | 0.8912\n",
      "JRA7032                   | JAA7732                   | 0.8062\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 24 done in 1.9s | train_loss=0.1550  valid_loss=0.8421  valid_acc=46.83%\n",
      "\n",
      "no improvement for 2/100 epochs\n",
      "\n",
      "→ Starting epoch 25  (printing every 28 iters)\n",
      "[Epoch 25] iter 28/28, avg loss: 0.0869\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VJD5050                   | VJD5050                   | 0.9790\n",
      "WTT1097                   | WTT1097                   | 0.9133\n",
      "QMY4519                   | QMY4519                   | 0.9873\n",
      "VGU781                    | VUU781                    | 0.8364\n",
      "NDP6199                   | NDP6199                   | 0.9520\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 25 done in 1.9s | train_loss=0.0869  valid_loss=0.8781  valid_acc=54.76%\n",
      "\n",
      "no improvement for 3/100 epochs\n",
      "\n",
      "→ Starting epoch 26  (printing every 28 iters)\n",
      "[Epoch 26] iter 28/28, avg loss: 0.0512\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WA3593F                   | WA3593F                   | 0.9600\n",
      "W763L                     | W763L                     | 0.9461\n",
      "WDK4927                   | WDK4927                   | 0.9454\n",
      "VEJ6785                   | VEJ6785                   | 0.8931\n",
      "QAA6493D                  | QAA6493D                  | 0.9005\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 26 done in 1.9s | train_loss=0.0512  valid_loss=0.8603  valid_acc=56.35%\n",
      "\n",
      "💾 New best model saved (epoch 26, val_acc=56.35%)\n",
      "\n",
      "→ Starting epoch 27  (printing every 28 iters)\n",
      "[Epoch 27] iter 28/28, avg loss: 0.1831\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QTA2566                   | QTA2566                   | 0.9660\n",
      "PDG4307                   | PDG4307                   | 0.8983\n",
      "BKB9642                   | BKB9642                   | 0.8988\n",
      "QKC1927                   | QKC1927                   | 0.9920\n",
      "QAB437B                   | QAB437B                   | 0.9504\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 27 done in 1.9s | train_loss=0.1831  valid_loss=0.8522  valid_acc=55.95%\n",
      "\n",
      "no improvement for 1/100 epochs\n",
      "\n",
      "→ Starting epoch 28  (printing every 28 iters)\n",
      "[Epoch 28] iter 28/28, avg loss: 0.0750\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WSM1382                   | WSM1382                   | 0.9323\n",
      "SMC5054                   | SMC5054                   | 0.9448\n",
      "PRF6163                   | PRF6163                   | 0.9496\n",
      "BPS7534                   | BPS7534                   | 0.9294\n",
      "TV333                     | TV333                     | 0.9294\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 28 done in 1.8s | train_loss=0.0750  valid_loss=0.9146  valid_acc=54.37%\n",
      "\n",
      "no improvement for 2/100 epochs\n",
      "\n",
      "→ Starting epoch 29  (printing every 28 iters)\n",
      "[Epoch 29] iter 28/28, avg loss: 0.0427\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VJN2867                   | VJN2867                   | 0.9542\n",
      "KW655                     | KW655                     | 0.8460\n",
      "QPD9089                   | QDD9089                   | 0.8743\n",
      "JV271                     | JV271                     | 0.9038\n",
      "QRT99                     | QTT99                     | 0.8306\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 29 done in 1.9s | train_loss=0.0427  valid_loss=0.8961  valid_acc=55.95%\n",
      "\n",
      "no improvement for 3/100 epochs\n",
      "\n",
      "→ Starting epoch 30  (printing every 28 iters)\n",
      "[Epoch 30] iter 28/28, avg loss: 0.0441\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAW7097                   | QAW7097                   | 0.9848\n",
      "DFC7000                   | DFC7000                   | 0.9565\n",
      "VBKL364                   | VBKL364                   | 0.9268\n",
      "VHW6283                   | VHW6283                   | 0.9312\n",
      "VKS9371                   | VKS9371                   | 0.9456\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 30 done in 1.8s | train_loss=0.0441  valid_loss=0.8924  valid_acc=56.75%\n",
      "\n",
      "💾 New best model saved (epoch 30, val_acc=56.75%)\n",
      "\n",
      "→ Starting epoch 31  (printing every 28 iters)\n",
      "[Epoch 31] iter 28/28, avg loss: 0.0351\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QM9779R                   | QM9779R                   | 0.9582\n",
      "VAT4116                   | VAT4116                   | 0.9444\n",
      "QLA8686                   | QLA8686                   | 0.9735\n",
      "JNA5822                   | JNA5822                   | 0.9769\n",
      "BNB8655                   | BBB8655                   | 0.9563\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 31 done in 1.8s | train_loss=0.0351  valid_loss=0.9478  valid_acc=55.56%\n",
      "\n",
      "no improvement for 1/100 epochs\n",
      "\n",
      "→ Starting epoch 32  (printing every 28 iters)\n",
      "[Epoch 32] iter 28/28, avg loss: 0.0235\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "DFC7000                   | DFC7000                   | 0.9630\n",
      "8559                      | 8559                      | 0.8928\n",
      "WEE9484                   | WEE9484                   | 0.9801\n",
      "QS2775V                   | QS2775V                   | 0.9692\n",
      "JPX9136                   | JPX9136                   | 0.9913\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 32 done in 1.8s | train_loss=0.0235  valid_loss=0.9093  valid_acc=57.94%\n",
      "\n",
      "💾 New best model saved (epoch 32, val_acc=57.94%)\n",
      "\n",
      "→ Starting epoch 33  (printing every 28 iters)\n",
      "[Epoch 33] iter 28/28, avg loss: 0.0158\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QTT7328                   | QTT7328                   | 0.9440\n",
      "ABS8858                   | ABS8858                   | 0.9822\n",
      "NCY8966                   | NCY8966                   | 0.9839\n",
      "NDL7330                   | NDL7330                   | 0.9662\n",
      "KAK2779                   | KAK2779                   | 0.9665\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 33 done in 1.8s | train_loss=0.0158  valid_loss=0.9488  valid_acc=56.35%\n",
      "\n",
      "no improvement for 1/100 epochs\n",
      "\n",
      "→ Starting epoch 34  (printing every 28 iters)\n",
      "[Epoch 34] iter 28/28, avg loss: 0.0110\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "KEN7203                   | KEN7203                   | 0.9630\n",
      "TCN6262                   | TCN6262                   | 0.9186\n",
      "JPD6859                   | JPP6859                   | 0.9206\n",
      "BDP4954                   | BDP4954                   | 0.9740\n",
      "QS1016K                   | QS1016K                   | 0.9821\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 34 done in 1.8s | train_loss=0.0110  valid_loss=0.9560  valid_acc=57.54%\n",
      "\n",
      "no improvement for 2/100 epochs\n",
      "\n",
      "→ Starting epoch 35  (printing every 28 iters)\n",
      "[Epoch 35] iter 28/28, avg loss: 0.0082\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WVL713                    | WVL713                    | 0.9484\n",
      "SJF5203                   | SJF5203                   | 0.9752\n",
      "JUH2988                   | JUH2988                   | 0.9894\n",
      "QAB1985H                  | QAB1985H                  | 0.9919\n",
      "QAM1319                   | QAM1319                   | 0.9758\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 35 done in 1.9s | train_loss=0.0082  valid_loss=0.9653  valid_acc=56.75%\n",
      "\n",
      "no improvement for 3/100 epochs\n",
      "\n",
      "→ Starting epoch 36  (printing every 28 iters)\n",
      "[Epoch 36] iter 28/28, avg loss: 0.0063\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WYC8600                   | WYC8600                   | 0.9752\n",
      "QAB2899K                  | QAB2899K                  | 0.9395\n",
      "BQL4682                   | BQL4682                   | 0.9489\n",
      "WFN4042                   | WFN4042                   | 0.9876\n",
      "QAB751H                   | QAB751H                   | 0.9936\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 36 done in 1.9s | train_loss=0.0063  valid_loss=0.9702  valid_acc=57.14%\n",
      "\n",
      "no improvement for 4/100 epochs\n",
      "\n",
      "→ Starting epoch 37  (printing every 28 iters)\n",
      "[Epoch 37] iter 28/28, avg loss: 0.0060\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "T/JJ115                   | T/JJ115                   | 0.9523\n",
      "NDH2698                   | NDH2698                   | 0.9758\n",
      "QRT99                     | QRT99                     | 0.9415\n",
      "T/M3041                   | T/M3041                   | 0.9538\n",
      "AKF4463                   | AKF4463                   | 0.9579\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 37 done in 1.9s | train_loss=0.0060  valid_loss=0.9725  valid_acc=56.75%\n",
      "\n",
      "no improvement for 5/100 epochs\n",
      "\n",
      "→ Starting epoch 38  (printing every 28 iters)\n",
      "[Epoch 38] iter 28/28, avg loss: 0.0054\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QCK8417                   | QCK8417                   | 0.9690\n",
      "AJA8335                   | AJA8335                   | 0.9327\n",
      "JDS809                    | JDS809                    | 0.9383\n",
      "PRH5551                   | PRH5551                   | 0.9883\n",
      "JPC3442                   | JPC3442                   | 0.9895\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 38 done in 1.9s | train_loss=0.0054  valid_loss=0.9835  valid_acc=57.14%\n",
      "\n",
      "no improvement for 6/100 epochs\n",
      "\n",
      "→ Starting epoch 39  (printing every 28 iters)\n",
      "[Epoch 39] iter 28/28, avg loss: 0.0047\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QCH2454                   | QCH2454                   | 0.9909\n",
      "QLA8686                   | QLA8686                   | 0.9693\n",
      "VKM8090                   | VKM8090                   | 0.9780\n",
      "VAM9906                   | VAM9906                   | 0.9143\n",
      "WB7028W                   | WB7028W                   | 0.9872\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 39 done in 1.9s | train_loss=0.0047  valid_loss=0.9945  valid_acc=57.14%\n",
      "\n",
      "no improvement for 7/100 epochs\n",
      "\n",
      "→ Starting epoch 40  (printing every 28 iters)\n",
      "[Epoch 40] iter 28/28, avg loss: 0.0045\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "RT1911                    | RT1911                    | 0.9767\n",
      "T/BD8758                  | T/BD8758                  | 0.9708\n",
      "FC9447                    | FC9447                    | 0.9975\n",
      "AEP7737                   | AEP7737                   | 0.9310\n",
      "VDP6513                   | VDP6513                   | 0.9964\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 40 done in 1.9s | train_loss=0.0045  valid_loss=0.9927  valid_acc=56.35%\n",
      "\n",
      "no improvement for 8/100 epochs\n",
      "\n",
      "→ Starting epoch 41  (printing every 28 iters)\n",
      "[Epoch 41] iter 28/28, avg loss: 0.0049\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "RK3002                    | RK3002                    | 0.9118\n",
      "QAE2205                   | QAE2205                   | 0.9886\n",
      "WQX3834                   | WQX3834                   | 0.9632\n",
      "1M4U3172                  | 1M4U3172                  | 0.9939\n",
      "JWQ5113                   | JWQ5113                   | 0.9760\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 41 done in 1.9s | train_loss=0.0049  valid_loss=1.0013  valid_acc=57.14%\n",
      "\n",
      "no improvement for 9/100 epochs\n",
      "\n",
      "→ Starting epoch 42  (printing every 28 iters)\n",
      "[Epoch 42] iter 28/28, avg loss: 0.0056\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "AKW716                    | AKW716                    | 0.9696\n",
      "QM5826G                   | QM5826G                   | 0.9757\n",
      "WNB2635                   | WNB2635                   | 0.9940\n",
      "QAA4174                   | QAA4174                   | 0.9720\n",
      "VML1256                   | VML1256                   | 0.9805\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 42 done in 1.9s | train_loss=0.0056  valid_loss=1.0294  valid_acc=55.95%\n",
      "\n",
      "no improvement for 10/100 epochs\n",
      "\n",
      "→ Starting epoch 43  (printing every 28 iters)\n",
      "[Epoch 43] iter 28/28, avg loss: 0.0102\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "TCJ8981                   | TCJ8981                   | 0.9626\n",
      "QAR6858                   | QAR6858                   | 0.9657\n",
      "QTD33                     | QTD33                     | 0.9684\n",
      "JSH4299                   | JSH4299                   | 0.9333\n",
      "QS1016K                   | QS1016K                   | 0.9159\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 43 done in 1.9s | train_loss=0.0102  valid_loss=1.0663  valid_acc=49.60%\n",
      "\n",
      "no improvement for 11/100 epochs\n",
      "\n",
      "→ Starting epoch 44  (printing every 28 iters)\n",
      "[Epoch 44] iter 28/28, avg loss: 0.1514\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WGS3960                   | WGS3960                   | 0.9745\n",
      "PNX7192                   | PNX7192                   | 0.9551\n",
      "WJH663                    | WJH663                    | 0.9524\n",
      "JTS9633                   | JTS9633                   | 0.9431\n",
      "QCH2778                   | QCH2778                   | 0.9926\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 44 done in 1.9s | train_loss=0.1514  valid_loss=0.9467  valid_acc=55.16%\n",
      "\n",
      "no improvement for 12/100 epochs\n",
      "\n",
      "→ Starting epoch 45  (printing every 28 iters)\n",
      "[Epoch 45] iter 28/28, avg loss: 0.1295\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "BNB8655                   | BNB8655                   | 0.9390\n",
      "JEV50                     | JEV50                     | 0.9003\n",
      "QAW7097                   | QAW7097                   | 0.9826\n",
      "JRG3303                   | JRG3303                   | 0.9032\n",
      "MBD8703                   | MBD8703                   | 0.9428\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 45 done in 1.9s | train_loss=0.1295  valid_loss=1.0159  valid_acc=50.00%\n",
      "\n",
      "no improvement for 13/100 epochs\n",
      "\n",
      "→ Starting epoch 46  (printing every 28 iters)\n",
      "[Epoch 46] iter 28/28, avg loss: 0.1564\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QRS3073                   | QRS3073                   | 0.9773\n",
      "NCH6650                   | NCH6650                   | 0.8806\n",
      "QM9C                      | QMM99                     | 0.8109\n",
      "JWJ7952                   | JWJ7952                   | 0.8621\n",
      "104101DC                  | 104101D                   | 0.7754\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 46 done in 1.9s | train_loss=0.1564  valid_loss=1.0327  valid_acc=51.19%\n",
      "\n",
      "no improvement for 14/100 epochs\n",
      "\n",
      "→ Starting epoch 47  (printing every 28 iters)\n",
      "[Epoch 47] iter 28/28, avg loss: 0.0837\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "NBC771                    | NBC771                    | 0.9841\n",
      "AMM5551                   | AMM5551                   | 0.9636\n",
      "QCK2525                   | QCK2525                   | 0.9737\n",
      "WXA7223                   | WXA7223                   | 0.9917\n",
      "PHV5919                   | PHV5919                   | 0.9588\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 47 done in 1.9s | train_loss=0.0837  valid_loss=0.9618  valid_acc=52.78%\n",
      "\n",
      "no improvement for 15/100 epochs\n",
      "\n",
      "→ Starting epoch 48  (printing every 28 iters)\n",
      "[Epoch 48] iter 28/28, avg loss: 0.0433\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WB6988D                   | WB6988D                   | 0.9059\n",
      "JRG2793                   | JRG2793                   | 0.9788\n",
      "QAB3330B                  | QAB3330B                  | 0.9744\n",
      "QPB615                    | QPB615                    | 0.9849\n",
      "BNG7865                   | BNG7865                   | 0.9485\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 48 done in 1.9s | train_loss=0.0433  valid_loss=0.8928  valid_acc=57.14%\n",
      "\n",
      "no improvement for 16/100 epochs\n",
      "\n",
      "→ Starting epoch 49  (printing every 28 iters)\n",
      "[Epoch 49] iter 28/28, avg loss: 0.0187\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QS2775V                   | QS2775V                   | 0.9553\n",
      "JJE2328                   | JJE2328                   | 0.9397\n",
      "WTW4423                   | WTW4423                   | 0.9387\n",
      "QAB8977J                  | QAB8977J                  | 0.9271\n",
      "AKX8453                   | AKX8453                   | 0.9474\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 49 done in 2.0s | train_loss=0.0187  valid_loss=0.9312  valid_acc=57.54%\n",
      "\n",
      "no improvement for 17/100 epochs\n",
      "\n",
      "→ Starting epoch 50  (printing every 28 iters)\n",
      "[Epoch 50] iter 28/28, avg loss: 0.0081\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "8559                      | 8559                      | 0.9015\n",
      "QM5966P                   | QM5966P                   | 0.9734\n",
      "JDS809                    | JDS809                    | 0.9365\n",
      "WUG4754                   | WUG4754                   | 0.9478\n",
      "JSF2692                   | JSF2692                   | 0.9881\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 50 done in 1.9s | train_loss=0.0081  valid_loss=0.9346  valid_acc=58.73%\n",
      "\n",
      "💾 New best model saved (epoch 50, val_acc=58.73%)\n",
      "\n",
      "→ Starting epoch 51  (printing every 28 iters)\n",
      "[Epoch 51] iter 28/28, avg loss: 0.0081\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "NDN3779                   | NDN3779                   | 0.9809\n",
      "WSJ8268                   | WSJ8268                   | 0.9961\n",
      "SMC3363                   | SMC3363                   | 0.9763\n",
      "MW2567                    | MW2567                    | 0.9841\n",
      "WCP5520                   | WCP5520                   | 0.9978\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 51 done in 1.9s | train_loss=0.0081  valid_loss=0.9453  valid_acc=57.54%\n",
      "\n",
      "no improvement for 1/100 epochs\n",
      "\n",
      "→ Starting epoch 52  (printing every 28 iters)\n",
      "[Epoch 52] iter 28/28, avg loss: 0.0052\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "MY3045                    | MY3045                    | 0.9114\n",
      "MCD9708                   | MCD9708                   | 0.9700\n",
      "AMY5489                   | AMY5489                   | 0.9533\n",
      "QLA8686                   | QLA8686                   | 0.9647\n",
      "JWQ5113                   | JWQ5113                   | 0.9855\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 52 done in 1.9s | train_loss=0.0052  valid_loss=0.9690  valid_acc=57.14%\n",
      "\n",
      "no improvement for 2/100 epochs\n",
      "\n",
      "→ Starting epoch 53  (printing every 28 iters)\n",
      "[Epoch 53] iter 28/28, avg loss: 0.0119\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "KDQ4187                   | KDQ4187                   | 0.9942\n",
      "PQS5137                   | PQS5137                   | 0.9890\n",
      "ADM1298                   | ADM1298                   | 0.9985\n",
      "JLY2201                   | JLY2201                   | 0.9586\n",
      "QAB9551A                  | QAB9551A                  | 0.9924\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 53 done in 1.9s | train_loss=0.0119  valid_loss=0.9645  valid_acc=57.54%\n",
      "\n",
      "no improvement for 3/100 epochs\n",
      "\n",
      "→ Starting epoch 54  (printing every 28 iters)\n",
      "[Epoch 54] iter 28/28, avg loss: 0.0070\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VGE3354                   | VGE3354                   | 0.9894\n",
      "VFH2157                   | VFH2157                   | 0.9749\n",
      "SK5285B                   | SK5285B                   | 0.9619\n",
      "QAB8768D                  | QAB8768D                  | 0.9947\n",
      "MCN7929                   | MCN7929                   | 0.9856\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 54 done in 1.9s | train_loss=0.0070  valid_loss=0.9660  valid_acc=58.33%\n",
      "\n",
      "no improvement for 4/100 epochs\n",
      "\n",
      "→ Starting epoch 55  (printing every 28 iters)\n",
      "[Epoch 55] iter 28/28, avg loss: 0.0038\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "BRJ8996                   | BRJ8996                   | 0.9824\n",
      "LD9188                    | LD9188                    | 0.9739\n",
      "JSH9196                   | JSH9196                   | 0.9879\n",
      "VEJ6785                   | VEJ6785                   | 0.9770\n",
      "JSH4299                   | JSH4299                   | 0.9382\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 55 done in 1.9s | train_loss=0.0038  valid_loss=0.9571  valid_acc=58.73%\n",
      "\n",
      "no improvement for 5/100 epochs\n",
      "\n",
      "→ Starting epoch 56  (printing every 28 iters)\n",
      "[Epoch 56] iter 28/28, avg loss: 0.0028\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "BDA8389                   | BDA8389                   | 0.9961\n",
      "QTY1471                   | QTY1471                   | 0.9907\n",
      "NBG6607                   | NBG6607                   | 0.9430\n",
      "KFM514                    | KFM514                    | 0.9482\n",
      "WA1309F                   | WA1309F                   | 0.9913\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 56 done in 1.9s | train_loss=0.0028  valid_loss=0.9689  valid_acc=58.73%\n",
      "\n",
      "no improvement for 6/100 epochs\n",
      "\n",
      "→ Starting epoch 57  (printing every 28 iters)\n",
      "[Epoch 57] iter 28/28, avg loss: 0.0026\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VML5392                   | VML5392                   | 0.9852\n",
      "PDG4307                   | PDG4307                   | 0.9829\n",
      "VHC5744                   | VHC5744                   | 0.9672\n",
      "VDP5735                   | VDP5735                   | 0.9669\n",
      "JLK9805                   | JLK9805                   | 0.9654\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 57 done in 1.9s | train_loss=0.0026  valid_loss=0.9705  valid_acc=59.13%\n",
      "\n",
      "💾 New best model saved (epoch 57, val_acc=59.13%)\n",
      "\n",
      "→ Starting epoch 58  (printing every 28 iters)\n",
      "[Epoch 58] iter 28/28, avg loss: 0.0023\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QKU9019                   | QKU9019                   | 0.9847\n",
      "AHU7727                   | AHU7727                   | 0.9711\n",
      "QAB7991C                  | QAB7991C                  | 0.9951\n",
      "AM7017                    | AM7017                    | 0.9914\n",
      "WD1915A                   | WD1915A                   | 0.9794\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 58 done in 1.9s | train_loss=0.0023  valid_loss=0.9797  valid_acc=59.13%\n",
      "\n",
      "no improvement for 1/100 epochs\n",
      "\n",
      "→ Starting epoch 59  (printing every 28 iters)\n",
      "[Epoch 59] iter 28/28, avg loss: 0.0021\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "TCJ8981                   | TCJ8981                   | 0.9940\n",
      "BRA2127                   | BRA2127                   | 0.9514\n",
      "JVD7333                   | JVD7333                   | 0.9854\n",
      "QS5039N                   | QS5039N                   | 0.9716\n",
      "WC8640J                   | WC8640J                   | 0.9858\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 59 done in 1.9s | train_loss=0.0021  valid_loss=0.9837  valid_acc=58.73%\n",
      "\n",
      "no improvement for 2/100 epochs\n",
      "\n",
      "→ Starting epoch 60  (printing every 28 iters)\n",
      "[Epoch 60] iter 28/28, avg loss: 0.0021\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "JLK9805                   | JLK9805                   | 0.9682\n",
      "WNT3307                   | WNT3307                   | 0.9953\n",
      "QAA5515N                  | QAA5515N                  | 0.9799\n",
      "1M4U3172                  | 1M4U3172                  | 0.9878\n",
      "ALN8722                   | ALN8722                   | 0.9941\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 60 done in 2.0s | train_loss=0.0021  valid_loss=0.9904  valid_acc=58.73%\n",
      "\n",
      "no improvement for 3/100 epochs\n",
      "\n",
      "→ Starting epoch 61  (printing every 28 iters)\n",
      "[Epoch 61] iter 28/28, avg loss: 0.0036\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "MDJ5126                   | MDJ5126                   | 0.9973\n",
      "QM5966P                   | QM5966P                   | 0.9923\n",
      "1M4U3172                  | 1M4U3172                  | 0.9930\n",
      "MDH7007                   | MDH7007                   | 0.9958\n",
      "QCE9329                   | QCE9329                   | 0.9972\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 61 done in 2.0s | train_loss=0.0036  valid_loss=0.9894  valid_acc=57.94%\n",
      "\n",
      "no improvement for 4/100 epochs\n",
      "\n",
      "→ Starting epoch 62  (printing every 28 iters)\n",
      "[Epoch 62] iter 28/28, avg loss: 0.0038\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QCH6494                   | QCH6494                   | 0.9769\n",
      "VBB457                    | VBB457                    | 0.9883\n",
      "VJN2867                   | VJN2867                   | 0.9734\n",
      "KAK2474                   | KAK2474                   | 0.8948\n",
      "MDV8552                   | MDV8552                   | 0.9716\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 62 done in 1.9s | train_loss=0.0038  valid_loss=0.9844  valid_acc=59.52%\n",
      "\n",
      "💾 New best model saved (epoch 62, val_acc=59.52%)\n",
      "\n",
      "→ Starting epoch 63  (printing every 28 iters)\n",
      "[Epoch 63] iter 28/28, avg loss: 0.0091\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VFM6378                   | VFM6378                   | 0.9938\n",
      "NDB8499                   | NDB8499                   | 0.9897\n",
      "VEJ6785                   | VEJ6785                   | 0.9792\n",
      "QPB615                    | QPB615                    | 0.9752\n",
      "KFX7711                   | KFX7711                   | 0.9572\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 63 done in 1.9s | train_loss=0.0091  valid_loss=1.0033  valid_acc=59.13%\n",
      "\n",
      "no improvement for 1/100 epochs\n",
      "\n",
      "→ Starting epoch 64  (printing every 28 iters)\n",
      "[Epoch 64] iter 28/28, avg loss: 0.0065\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WJE4152                   | WJE4152                   | 0.9943\n",
      "NDN3779                   | NDN3779                   | 0.9749\n",
      "VHW6283                   | VHW6283                   | 0.9790\n",
      "QAB9009H                  | QAB9009H                  | 0.9736\n",
      "VX2808                    | VX2808                    | 0.9729\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 64 done in 2.0s | train_loss=0.0065  valid_loss=1.0108  valid_acc=58.73%\n",
      "\n",
      "no improvement for 2/100 epochs\n",
      "\n",
      "→ Starting epoch 65  (printing every 28 iters)\n",
      "[Epoch 65] iter 28/28, avg loss: 0.0038\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "BNB93                     | BNB93                     | 0.9483\n",
      "QS1595E                   | QS1595E                   | 0.9811\n",
      "JRA7032                   | JRA7032                   | 0.9527\n",
      "QCH2454                   | QCH2454                   | 0.9990\n",
      "BLR9830                   | BLR9830                   | 0.9405\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 65 done in 2.0s | train_loss=0.0038  valid_loss=0.9946  valid_acc=58.73%\n",
      "\n",
      "no improvement for 3/100 epochs\n",
      "\n",
      "→ Starting epoch 66  (printing every 28 iters)\n",
      "[Epoch 66] iter 28/28, avg loss: 0.0040\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "KEN7203                   | KEN7203                   | 0.9644\n",
      "QAP5276                   | QAP5276                   | 0.9630\n",
      "NAP4617                   | NAP4617                   | 0.9577\n",
      "WA1309F                   | WA1309F                   | 0.9870\n",
      "QKL8220                   | QKL8220                   | 0.9789\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 66 done in 2.0s | train_loss=0.0040  valid_loss=0.9938  valid_acc=58.33%\n",
      "\n",
      "no improvement for 4/100 epochs\n",
      "\n",
      "→ Starting epoch 67  (printing every 28 iters)\n",
      "[Epoch 67] iter 28/28, avg loss: 0.0023\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAN3559                   | QAN3559                   | 0.9746\n",
      "PLS114                    | PLS114                    | 0.9628\n",
      "NDM4685                   | NDM4685                   | 0.9621\n",
      "QKU9019                   | QKU9019                   | 0.9718\n",
      "VBA7999                   | VBA7999                   | 0.9519\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 67 done in 1.9s | train_loss=0.0023  valid_loss=0.9991  valid_acc=58.73%\n",
      "\n",
      "no improvement for 5/100 epochs\n",
      "\n",
      "→ Starting epoch 68  (printing every 28 iters)\n",
      "[Epoch 68] iter 28/28, avg loss: 0.0020\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "PDV5663                   | PDV5663                   | 0.9885\n",
      "VNN6819                   | VNN6819                   | 0.9957\n",
      "QS9698N                   | QS9698N                   | 0.9730\n",
      "QKU9019                   | QKU9019                   | 0.9763\n",
      "QAA8698P                  | QAA8698P                  | 0.9746\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 68 done in 1.9s | train_loss=0.0020  valid_loss=1.0025  valid_acc=58.33%\n",
      "\n",
      "no improvement for 6/100 epochs\n",
      "\n",
      "→ Starting epoch 69  (printing every 28 iters)\n",
      "[Epoch 69] iter 28/28, avg loss: 0.0018\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VLD745                    | VLD745                    | 0.9979\n",
      "VGX3015                   | VGX3015                   | 0.9584\n",
      "QAA8656V                  | QAA8656V                  | 0.9729\n",
      "WC8869U                   | WC8869U                   | 0.9961\n",
      "NAD9748                   | NAD9748                   | 0.9593\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 69 done in 1.9s | train_loss=0.0018  valid_loss=1.0059  valid_acc=58.73%\n",
      "\n",
      "no improvement for 7/100 epochs\n",
      "\n",
      "→ Starting epoch 70  (printing every 28 iters)\n",
      "[Epoch 70] iter 28/28, avg loss: 0.0016\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WDC4844                   | WDC4844                   | 0.9396\n",
      "QTY1471                   | QTY1471                   | 0.9954\n",
      "QCH2778                   | QCH2778                   | 0.9992\n",
      "JWJ7952                   | JWJ7952                   | 0.9477\n",
      "MDJ5126                   | MDJ5126                   | 0.9956\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 70 done in 1.9s | train_loss=0.0016  valid_loss=1.0097  valid_acc=59.13%\n",
      "\n",
      "no improvement for 8/100 epochs\n",
      "\n",
      "→ Starting epoch 71  (printing every 28 iters)\n",
      "[Epoch 71] iter 28/28, avg loss: 0.0015\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAB7991C                  | QAB7991C                  | 0.9959\n",
      "PBW9097                   | PBW9097                   | 0.9602\n",
      "WXX2093                   | WXX2093                   | 0.9383\n",
      "HWE8782                   | HWE8782                   | 0.9641\n",
      "NH2225                    | NH2225                    | 0.9655\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 71 done in 1.9s | train_loss=0.0015  valid_loss=1.0129  valid_acc=58.73%\n",
      "\n",
      "no improvement for 9/100 epochs\n",
      "\n",
      "→ Starting epoch 72  (printing every 28 iters)\n",
      "[Epoch 72] iter 28/28, avg loss: 0.0014\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WC8640J                   | WC8640J                   | 0.9787\n",
      "AHU7727                   | AHU7727                   | 0.9419\n",
      "RC9863                    | RC9863                    | 0.9680\n",
      "RAX1533                   | RAX1533                   | 0.9769\n",
      "JRW5859                   | JRW5859                   | 0.9987\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 72 done in 1.9s | train_loss=0.0014  valid_loss=1.0194  valid_acc=58.73%\n",
      "\n",
      "no improvement for 10/100 epochs\n",
      "\n",
      "→ Starting epoch 73  (printing every 28 iters)\n",
      "[Epoch 73] iter 28/28, avg loss: 0.0015\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VEH6204                   | VEH6204                   | 0.9650\n",
      "QAB401E                   | QAB401E                   | 0.9914\n",
      "QAM1319                   | QAM1319                   | 0.9778\n",
      "JWK5515                   | JWK5515                   | 0.9844\n",
      "KDC4153                   | KDC4153                   | 0.9584\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 73 done in 1.9s | train_loss=0.0015  valid_loss=1.0235  valid_acc=58.73%\n",
      "\n",
      "no improvement for 11/100 epochs\n",
      "\n",
      "→ Starting epoch 74  (printing every 28 iters)\n",
      "[Epoch 74] iter 28/28, avg loss: 0.0015\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "NDN4403                   | NDN4403                   | 0.9735\n",
      "BMG317                    | BMG317                    | 0.9201\n",
      "NAN6440                   | NAN6440                   | 0.9753\n",
      "WGT7178                   | WGT7178                   | 0.9837\n",
      "KDS3030                   | KDS3030                   | 0.9697\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 74 done in 1.9s | train_loss=0.0015  valid_loss=1.0286  valid_acc=59.13%\n",
      "\n",
      "no improvement for 12/100 epochs\n",
      "\n",
      "→ Starting epoch 75  (printing every 28 iters)\n",
      "[Epoch 75] iter 28/28, avg loss: 0.0014\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "BDP4954                   | BDP4954                   | 0.9880\n",
      "NDH2698                   | NDH2698                   | 0.9882\n",
      "QAA6070P                  | QAA6070P                  | 0.9974\n",
      "MDC8333                   | MDC8333                   | 0.9788\n",
      "WD1915A                   | WD1915A                   | 0.9935\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 75 done in 1.9s | train_loss=0.0014  valid_loss=1.0272  valid_acc=58.73%\n",
      "\n",
      "no improvement for 13/100 epochs\n",
      "\n",
      "→ Starting epoch 76  (printing every 28 iters)\n",
      "[Epoch 76] iter 28/28, avg loss: 0.0013\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "CEN2010                   | CEN2010                   | 0.9825\n",
      "WDJ9407                   | WDJ9407                   | 0.9991\n",
      "SK1636C                   | SK1636C                   | 0.9980\n",
      "BDW7792                   | BDW7792                   | 0.9696\n",
      "BSE7899                   | BSE7899                   | 0.9768\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 76 done in 1.9s | train_loss=0.0013  valid_loss=1.0333  valid_acc=58.73%\n",
      "\n",
      "no improvement for 14/100 epochs\n",
      "\n",
      "→ Starting epoch 77  (printing every 28 iters)\n",
      "[Epoch 77] iter 28/28, avg loss: 0.0013\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAA7135S                  | QAA7135S                  | 0.9721\n",
      "PLT2670                   | PLT2670                   | 0.9765\n",
      "WB7028W                   | WB7028W                   | 0.9961\n",
      "WLH6202                   | WLH6202                   | 0.9631\n",
      "QAB751H                   | QAB751H                   | 0.9760\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 77 done in 1.9s | train_loss=0.0013  valid_loss=1.0342  valid_acc=57.94%\n",
      "\n",
      "no improvement for 15/100 epochs\n",
      "\n",
      "→ Starting epoch 78  (printing every 28 iters)\n",
      "[Epoch 78] iter 28/28, avg loss: 0.0013\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WTM3755                   | WTM3755                   | 0.9649\n",
      "MCD9708                   | MCD9708                   | 0.9935\n",
      "KDQ4187                   | KDQ4187                   | 0.9909\n",
      "TBE9333                   | TBE9333                   | 0.9697\n",
      "AEE7918                   | AEE7918                   | 0.9776\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 78 done in 1.9s | train_loss=0.0013  valid_loss=1.0359  valid_acc=58.73%\n",
      "\n",
      "no improvement for 16/100 epochs\n",
      "\n",
      "→ Starting epoch 79  (printing every 28 iters)\n",
      "[Epoch 79] iter 28/28, avg loss: 0.0012\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "DEY9981                   | DEY9981                   | 0.9791\n",
      "QAW7097                   | QAW7097                   | 0.9995\n",
      "JLC8890                   | JLC8890                   | 0.9765\n",
      "WC3688R                   | WC3688R                   | 0.9749\n",
      "JXP4469                   | JXP4469                   | 0.9775\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 79 done in 1.9s | train_loss=0.0012  valid_loss=1.0371  valid_acc=58.73%\n",
      "\n",
      "no improvement for 17/100 epochs\n",
      "\n",
      "→ Starting epoch 80  (printing every 28 iters)\n",
      "[Epoch 80] iter 28/28, avg loss: 0.0011\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QRR2912                   | QRR2912                   | 0.9928\n",
      "PRP5757                   | PRP5757                   | 0.9778\n",
      "VAW902                    | VAW902                    | 0.9938\n",
      "MCV3797                   | MCV3797                   | 0.9667\n",
      "WQD6028                   | WQD6028                   | 0.9942\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 80 done in 1.9s | train_loss=0.0011  valid_loss=1.0390  valid_acc=59.13%\n",
      "\n",
      "no improvement for 18/100 epochs\n",
      "\n",
      "→ Starting epoch 81  (printing every 28 iters)\n",
      "[Epoch 81] iter 28/28, avg loss: 0.0011\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "DCS8812                   | DCS8812                   | 0.9841\n",
      "QCK8054                   | QCK8054                   | 0.9802\n",
      "VMN5788                   | VMN5788                   | 0.9756\n",
      "QS2582P                   | QS2582P                   | 0.9601\n",
      "AGX7136                   | AGX7136                   | 0.9810\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 81 done in 1.9s | train_loss=0.0011  valid_loss=1.0444  valid_acc=58.73%\n",
      "\n",
      "no improvement for 19/100 epochs\n",
      "\n",
      "→ Starting epoch 82  (printing every 28 iters)\n",
      "[Epoch 82] iter 28/28, avg loss: 0.0010\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QKY2146                   | QKY2146                   | 0.9720\n",
      "VFC331                    | VFC331                    | 0.9609\n",
      "VX2808                    | VX2808                    | 0.9765\n",
      "NAN6440                   | NAN6440                   | 0.9563\n",
      "QMA9741                   | QMA9741                   | 0.9758\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 82 done in 1.9s | train_loss=0.0010  valid_loss=1.0462  valid_acc=59.52%\n",
      "\n",
      "no improvement for 20/100 epochs\n",
      "\n",
      "→ Starting epoch 83  (printing every 28 iters)\n",
      "[Epoch 83] iter 28/28, avg loss: 0.0010\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAR6858                   | QAR6858                   | 0.9922\n",
      "NBU40                     | NBU40                     | 0.9796\n",
      "WUS4893                   | WUS4893                   | 0.9466\n",
      "VFH2157                   | VFH2157                   | 0.9818\n",
      "BSE7899                   | BSE7899                   | 0.9762\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 83 done in 2.0s | train_loss=0.0010  valid_loss=1.0458  valid_acc=58.73%\n",
      "\n",
      "no improvement for 21/100 epochs\n",
      "\n",
      "→ Starting epoch 84  (printing every 28 iters)\n",
      "[Epoch 84] iter 28/28, avg loss: 0.0009\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WMT813                    | WMT813                    | 0.9673\n",
      "RS6069                    | RS6069                    | 0.9909\n",
      "BRV1389                   | BRV1389                   | 0.9605\n",
      "SML6789                   | SML6789                   | 0.9678\n",
      "NDP6199                   | NDP6199                   | 0.9586\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 84 done in 1.9s | train_loss=0.0009  valid_loss=1.0466  valid_acc=58.33%\n",
      "\n",
      "no improvement for 22/100 epochs\n",
      "\n",
      "→ Starting epoch 85  (printing every 28 iters)\n",
      "[Epoch 85] iter 28/28, avg loss: 0.0009\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "ABX8314                   | ABX8314                   | 0.9723\n",
      "UNIMAS6119                | UNIMAS6119                | 0.9837\n",
      "PDV5663                   | PDV5663                   | 0.9855\n",
      "T/BB578                   | T/BB578                   | 0.9781\n",
      "QS5039N                   | QS5039N                   | 0.9688\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 85 done in 1.9s | train_loss=0.0009  valid_loss=1.0525  valid_acc=58.73%\n",
      "\n",
      "no improvement for 23/100 epochs\n",
      "\n",
      "→ Starting epoch 86  (printing every 28 iters)\n",
      "[Epoch 86] iter 28/28, avg loss: 0.0009\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WYJ7760                   | WYJ7760                   | 0.9815\n",
      "JWE3023                   | JWE3023                   | 0.9757\n",
      "QM7691Q                   | QM7691Q                   | 0.9734\n",
      "JVB7580                   | JVB7580                   | 0.9819\n",
      "BKJ3569                   | BKJ3569                   | 0.9411\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 86 done in 1.9s | train_loss=0.0009  valid_loss=1.0540  valid_acc=59.52%\n",
      "\n",
      "no improvement for 24/100 epochs\n",
      "\n",
      "→ Starting epoch 87  (printing every 28 iters)\n",
      "[Epoch 87] iter 28/28, avg loss: 0.0010\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VCW2744                   | VCW2744                   | 0.9919\n",
      "WA7920W                   | WA7920W                   | 0.9629\n",
      "WFR9497                   | WFR9497                   | 0.9884\n",
      "JKN9008                   | JKN9008                   | 0.9874\n",
      "KDS818                    | KDS818                    | 0.9709\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 87 done in 1.8s | train_loss=0.0010  valid_loss=1.0526  valid_acc=58.33%\n",
      "\n",
      "no improvement for 25/100 epochs\n",
      "\n",
      "→ Starting epoch 88  (printing every 28 iters)\n",
      "[Epoch 88] iter 28/28, avg loss: 0.0017\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WB1733P                   | WB1733P                   | 0.9419\n",
      "FFF1519                   | FFF1519                   | 0.9972\n",
      "QAB371C                   | QAB371C                   | 0.9983\n",
      "HWE8782                   | HWE8782                   | 0.9839\n",
      "QM9779R                   | QM9779R                   | 0.9776\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 88 done in 1.8s | train_loss=0.0017  valid_loss=1.0600  valid_acc=58.73%\n",
      "\n",
      "no improvement for 26/100 epochs\n",
      "\n",
      "→ Starting epoch 89  (printing every 28 iters)\n",
      "[Epoch 89] iter 28/28, avg loss: 0.0014\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "JRW5859                   | JRW5859                   | 0.9989\n",
      "QAR53                     | QAR53                     | 0.9944\n",
      "RM8688                    | RM8688                    | 0.9917\n",
      "VDP6513                   | VDP6513                   | 0.9904\n",
      "ANM7267                   | ANM7267                   | 0.9977\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 89 done in 1.8s | train_loss=0.0014  valid_loss=1.0585  valid_acc=58.73%\n",
      "\n",
      "no improvement for 27/100 epochs\n",
      "\n",
      "→ Starting epoch 90  (printing every 28 iters)\n",
      "[Epoch 90] iter 28/28, avg loss: 0.0009\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WYJ7760                   | WYJ7760                   | 0.9886\n",
      "QAA3953V                  | QAA3953V                  | 0.9755\n",
      "T/JJ115                   | T/JJ115                   | 0.9673\n",
      "WCG7220                   | WCG7220                   | 0.9663\n",
      "VMH942                    | VMH942                    | 0.9592\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 90 done in 1.8s | train_loss=0.0009  valid_loss=1.0610  valid_acc=58.73%\n",
      "\n",
      "no improvement for 28/100 epochs\n",
      "\n",
      "→ Starting epoch 91  (printing every 28 iters)\n",
      "[Epoch 91] iter 28/28, avg loss: 0.0008\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "BGW2901                   | BGW2901                   | 0.9654\n",
      "QM9C                      | QM9C                      | 0.9375\n",
      "FD10                      | FD10                      | 0.9330\n",
      "BRV1389                   | BRV1389                   | 0.9845\n",
      "WC8869U                   | WC8869U                   | 0.9973\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 91 done in 1.9s | train_loss=0.0008  valid_loss=1.0630  valid_acc=58.33%\n",
      "\n",
      "no improvement for 29/100 epochs\n",
      "\n",
      "→ Starting epoch 92  (printing every 28 iters)\n",
      "[Epoch 92] iter 28/28, avg loss: 0.0008\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VBKL364                   | VBKL364                   | 0.9885\n",
      "QM4997P                   | QM4997P                   | 0.9853\n",
      "QAA6858M                  | QAA6858M                  | 0.9971\n",
      "SMK5                      | SMK5                      | 0.9300\n",
      "MDS7934                   | MDS7934                   | 0.9899\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 92 done in 1.8s | train_loss=0.0008  valid_loss=1.0663  valid_acc=58.73%\n",
      "\n",
      "no improvement for 30/100 epochs\n",
      "\n",
      "→ Starting epoch 93  (printing every 28 iters)\n",
      "[Epoch 93] iter 28/28, avg loss: 0.0008\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WXQ6691                   | WXQ6691                   | 0.9836\n",
      "AJA8335                   | AJA8335                   | 0.9668\n",
      "JFR4363                   | JFR4363                   | 0.9828\n",
      "QAB7991C                  | QAB7991C                  | 0.9988\n",
      "NDW2622                   | NDW2622                   | 0.9968\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 93 done in 1.8s | train_loss=0.0008  valid_loss=1.0628  valid_acc=58.73%\n",
      "\n",
      "no improvement for 31/100 epochs\n",
      "\n",
      "→ Starting epoch 94  (printing every 28 iters)\n",
      "[Epoch 94] iter 28/28, avg loss: 0.0008\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VFM6378                   | VFM6378                   | 0.9891\n",
      "ANM7267                   | ANM7267                   | 0.9977\n",
      "WVL713                    | WVL713                    | 0.9670\n",
      "MAM6063                   | MAM6063                   | 0.9462\n",
      "QKU9019                   | QKU9019                   | 0.9774\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 94 done in 1.8s | train_loss=0.0008  valid_loss=1.0656  valid_acc=59.13%\n",
      "\n",
      "no improvement for 32/100 epochs\n",
      "\n",
      "→ Starting epoch 95  (printing every 28 iters)\n",
      "[Epoch 95] iter 28/28, avg loss: 0.0007\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "SJG8699                   | SJG8699                   | 0.9969\n",
      "QAA7228U                  | QAA7228U                  | 0.9682\n",
      "WYJ7760                   | WYJ7760                   | 0.9913\n",
      "QAA8698P                  | QAA8698P                  | 0.9697\n",
      "QAA8392N                  | QAA8392N                  | 0.9781\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 95 done in 1.8s | train_loss=0.0007  valid_loss=1.0706  valid_acc=58.33%\n",
      "\n",
      "no improvement for 33/100 epochs\n",
      "\n",
      "→ Starting epoch 96  (printing every 28 iters)\n",
      "[Epoch 96] iter 28/28, avg loss: 0.0007\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VHR7459                   | VHR7459                   | 0.9845\n",
      "WA7920W                   | WA7920W                   | 0.9627\n",
      "VML1256                   | VML1256                   | 0.9809\n",
      "PJN5826                   | PJN5826                   | 0.9624\n",
      "B3106A                    | B3106A                    | 0.9488\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 96 done in 1.8s | train_loss=0.0007  valid_loss=1.0711  valid_acc=58.33%\n",
      "\n",
      "no improvement for 34/100 epochs\n",
      "\n",
      "→ Starting epoch 97  (printing every 28 iters)\n",
      "[Epoch 97] iter 28/28, avg loss: 0.0007\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VHC9931                   | VHC9931                   | 0.9899\n",
      "WMX9993                   | WMX9993                   | 0.9913\n",
      "VHW6283                   | VHW6283                   | 0.9726\n",
      "VHQ5451                   | VHQ5451                   | 0.9759\n",
      "JVD7333                   | JVD7333                   | 0.9921\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 97 done in 1.9s | train_loss=0.0007  valid_loss=1.0693  valid_acc=58.73%\n",
      "\n",
      "no improvement for 35/100 epochs\n",
      "\n",
      "→ Starting epoch 98  (printing every 28 iters)\n",
      "[Epoch 98] iter 28/28, avg loss: 0.0007\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QM4493M                   | QM4493M                   | 0.9795\n",
      "KDS818                    | KDS818                    | 0.9468\n",
      "JLW8830                   | JLW8830                   | 0.9655\n",
      "MDJ6389                   | MDJ6389                   | 0.9932\n",
      "LE7021                    | LE7021                    | 0.9671\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 98 done in 1.9s | train_loss=0.0007  valid_loss=1.0725  valid_acc=59.52%\n",
      "\n",
      "no improvement for 36/100 epochs\n",
      "\n",
      "→ Starting epoch 99  (printing every 28 iters)\n",
      "[Epoch 99] iter 28/28, avg loss: 0.0007\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "SJB6000                   | SJB6000                   | 0.9721\n",
      "QAA4174                   | QAA4174                   | 0.9767\n",
      "JTU3636                   | JTU3636                   | 0.9441\n",
      "MDH9889                   | MDH9889                   | 0.9957\n",
      "QAW2391                   | QAW2391                   | 0.9746\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 99 done in 1.9s | train_loss=0.0007  valid_loss=1.0733  valid_acc=59.13%\n",
      "\n",
      "no improvement for 37/100 epochs\n",
      "\n",
      "→ Starting epoch 100  (printing every 28 iters)\n",
      "[Epoch 100] iter 28/28, avg loss: 0.0007\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WB7028W                   | WB7028W                   | 0.9952\n",
      "VAQ511                    | VAQ511                    | 0.9774\n",
      "DAF7469                   | DAF7469                   | 0.9847\n",
      "PKS9266                   | PKS9266                   | 0.9805\n",
      "JPC3442                   | JPC3442                   | 0.9767\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 100 done in 1.9s | train_loss=0.0007  valid_loss=1.0747  valid_acc=58.73%\n",
      "\n",
      "no improvement for 38/100 epochs\n",
      "\n",
      "→ Starting epoch 101  (printing every 28 iters)\n",
      "[Epoch 101] iter 28/28, avg loss: 0.0006\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "PJN5826                   | PJN5826                   | 0.9627\n",
      "JRP7041                   | JRP7041                   | 0.9787\n",
      "JSH9196                   | JSH9196                   | 0.9830\n",
      "BJB6131                   | BJB6131                   | 0.9413\n",
      "AJA8335                   | AJA8335                   | 0.9730\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 101 done in 1.8s | train_loss=0.0006  valid_loss=1.0781  valid_acc=59.13%\n",
      "\n",
      "no improvement for 39/100 epochs\n",
      "\n",
      "→ Starting epoch 102  (printing every 28 iters)\n",
      "[Epoch 102] iter 28/28, avg loss: 0.0006\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QCE9329                   | QCE9329                   | 0.9899\n",
      "QKC1927                   | QKC1927                   | 0.9966\n",
      "JRW5859                   | JRW5859                   | 0.9853\n",
      "T/N4793                   | T/N4793                   | 0.9709\n",
      "AGX7136                   | AGX7136                   | 0.9575\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 102 done in 1.9s | train_loss=0.0006  valid_loss=1.0793  valid_acc=59.52%\n",
      "\n",
      "no improvement for 40/100 epochs\n",
      "\n",
      "→ Starting epoch 103  (printing every 28 iters)\n",
      "[Epoch 103] iter 28/28, avg loss: 0.0006\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WXX2093                   | WXX2093                   | 0.9610\n",
      "PEA1781                   | PEA1781                   | 0.9701\n",
      "RC9863                    | RC9863                    | 0.9953\n",
      "TCJ8981                   | TCJ8981                   | 0.9969\n",
      "QAA6858M                  | QAA6858M                  | 0.9987\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 103 done in 1.9s | train_loss=0.0006  valid_loss=1.0830  valid_acc=58.73%\n",
      "\n",
      "no improvement for 41/100 epochs\n",
      "\n",
      "→ Starting epoch 104  (printing every 28 iters)\n",
      "[Epoch 104] iter 28/28, avg loss: 0.0006\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "NCU3622                   | NCU3622                   | 0.9773\n",
      "QLA8686                   | QLA8686                   | 0.9930\n",
      "NDM4685                   | NDM4685                   | 0.9852\n",
      "QKY4531                   | QKY4531                   | 0.9942\n",
      "CEN2010                   | CEN2010                   | 0.9852\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 104 done in 1.9s | train_loss=0.0006  valid_loss=1.0820  valid_acc=58.73%\n",
      "\n",
      "no improvement for 42/100 epochs\n",
      "\n",
      "→ Starting epoch 105  (printing every 28 iters)\n",
      "[Epoch 105] iter 28/28, avg loss: 0.0006\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WPB3184                   | WPB3184                   | 0.9790\n",
      "VGT9721                   | VGT9721                   | 0.9652\n",
      "VAQ2618                   | VAQ2618                   | 0.9877\n",
      "MDB5515                   | MDB5515                   | 0.9909\n",
      "VBB457                    | VBB457                    | 0.9884\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 105 done in 1.9s | train_loss=0.0006  valid_loss=1.0838  valid_acc=58.73%\n",
      "\n",
      "no improvement for 43/100 epochs\n",
      "\n",
      "→ Starting epoch 106  (printing every 28 iters)\n",
      "[Epoch 106] iter 28/28, avg loss: 0.0006\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "JTW5239                   | JTW5239                   | 0.9831\n",
      "BRJ8996                   | BRJ8996                   | 0.9920\n",
      "VEQ9310                   | VEQ9310                   | 0.9754\n",
      "VKR5274                   | VKR5274                   | 0.9935\n",
      "QCG9886                   | QCG9886                   | 0.9983\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 106 done in 1.9s | train_loss=0.0006  valid_loss=1.0866  valid_acc=59.52%\n",
      "\n",
      "no improvement for 44/100 epochs\n",
      "\n",
      "→ Starting epoch 107  (printing every 28 iters)\n",
      "[Epoch 107] iter 28/28, avg loss: 0.0006\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QBB7772                   | QBB7772                   | 0.9943\n",
      "RC9863                    | RC9863                    | 0.9956\n",
      "WNC8559                   | WNC8559                   | 0.9769\n",
      "SYU3073                   | SYU3073                   | 0.9037\n",
      "BGT233                    | BGT233                    | 0.9833\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 107 done in 1.9s | train_loss=0.0006  valid_loss=1.0822  valid_acc=59.13%\n",
      "\n",
      "no improvement for 45/100 epochs\n",
      "\n",
      "→ Starting epoch 108  (printing every 28 iters)\n",
      "[Epoch 108] iter 28/28, avg loss: 0.0006\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "BQP5287                   | BQP5287                   | 0.9751\n",
      "MDS7658                   | MDS7658                   | 0.9810\n",
      "TBT9322                   | TBT9322                   | 0.9729\n",
      "TCN6262                   | TCN6262                   | 0.9906\n",
      "AJC6227                   | AJC6227                   | 0.9919\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 108 done in 1.9s | train_loss=0.0006  valid_loss=1.0821  valid_acc=59.13%\n",
      "\n",
      "no improvement for 46/100 epochs\n",
      "\n",
      "→ Starting epoch 109  (printing every 28 iters)\n",
      "[Epoch 109] iter 28/28, avg loss: 0.0006\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAB8000C                  | QAB8000C                  | 0.9987\n",
      "QAU4660                   | QAU4660                   | 0.9839\n",
      "QCE8362                   | QCE8362                   | 0.9720\n",
      "AEE7918                   | AEE7918                   | 0.9835\n",
      "NAD9748                   | NAD9748                   | 0.9716\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 109 done in 1.8s | train_loss=0.0006  valid_loss=1.0844  valid_acc=59.52%\n",
      "\n",
      "no improvement for 47/100 epochs\n",
      "\n",
      "→ Starting epoch 110  (printing every 28 iters)\n",
      "[Epoch 110] iter 28/28, avg loss: 0.0005\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "TCF8978                   | TCF8978                   | 0.9863\n",
      "VBV198                    | VBV198                    | 0.9964\n",
      "KFL5361                   | KFL5361                   | 0.9337\n",
      "VJE3434                   | VJE3434                   | 0.9972\n",
      "WB5779C                   | WB5779C                   | 0.9987\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 110 done in 1.9s | train_loss=0.0005  valid_loss=1.0884  valid_acc=58.33%\n",
      "\n",
      "no improvement for 48/100 epochs\n",
      "\n",
      "→ Starting epoch 111  (printing every 28 iters)\n",
      "[Epoch 111] iter 28/28, avg loss: 0.0005\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "JPX9136                   | JPX9136                   | 0.9769\n",
      "MDJ5126                   | MDJ5126                   | 0.9920\n",
      "RK3002                    | RK3002                    | 0.9924\n",
      "T/BB578                   | T/BB578                   | 0.9747\n",
      "QM5966P                   | QM5966P                   | 0.9824\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 111 done in 1.9s | train_loss=0.0005  valid_loss=1.0867  valid_acc=59.13%\n",
      "\n",
      "no improvement for 49/100 epochs\n",
      "\n",
      "→ Starting epoch 112  (printing every 28 iters)\n",
      "[Epoch 112] iter 28/28, avg loss: 0.0005\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "JV271                     | JV271                     | 0.9697\n",
      "W5870P                    | W5870P                    | 0.9405\n",
      "PAC6969                   | PAC6969                   | 0.9763\n",
      "QAB371C                   | QAB371C                   | 0.9995\n",
      "WLP6892                   | WLP6892                   | 0.9738\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 112 done in 1.8s | train_loss=0.0005  valid_loss=1.0931  valid_acc=59.13%\n",
      "\n",
      "no improvement for 50/100 epochs\n",
      "\n",
      "→ Starting epoch 113  (printing every 28 iters)\n",
      "[Epoch 113] iter 28/28, avg loss: 0.0005\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VET8129                   | VET8129                   | 0.9968\n",
      "ANQ3799                   | ANQ3799                   | 0.9825\n",
      "QAB1040A                  | QAB1040A                  | 0.9977\n",
      "VM6611                    | VM6611                    | 0.9995\n",
      "BNB93                     | BNB93                     | 0.9729\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 113 done in 1.9s | train_loss=0.0005  valid_loss=1.0927  valid_acc=58.73%\n",
      "\n",
      "no improvement for 51/100 epochs\n",
      "\n",
      "→ Starting epoch 114  (printing every 28 iters)\n",
      "[Epoch 114] iter 28/28, avg loss: 0.0005\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QCG650                    | QCG650                    | 0.9228\n",
      "WUG4754                   | WUG4754                   | 0.9947\n",
      "ANF8688                   | ANF8688                   | 0.9895\n",
      "AGX7136                   | AGX7136                   | 0.9785\n",
      "VML5392                   | VML5392                   | 0.9762\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 114 done in 1.9s | train_loss=0.0005  valid_loss=1.0971  valid_acc=59.52%\n",
      "\n",
      "no improvement for 52/100 epochs\n",
      "\n",
      "→ Starting epoch 115  (printing every 28 iters)\n",
      "[Epoch 115] iter 28/28, avg loss: 0.0005\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "T/JA6344                  | T/JA6344                  | 0.9766\n",
      "T/BB578                   | T/BB578                   | 0.9809\n",
      "VBV198                    | VBV198                    | 0.9876\n",
      "WUT2636                   | WUT2636                   | 0.9811\n",
      "MW2567                    | MW2567                    | 0.9917\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 115 done in 1.8s | train_loss=0.0005  valid_loss=1.0960  valid_acc=59.92%\n",
      "\n",
      "💾 New best model saved (epoch 115, val_acc=59.92%)\n",
      "\n",
      "→ Starting epoch 116  (printing every 28 iters)\n",
      "[Epoch 116] iter 28/28, avg loss: 0.0005\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "BMQ705                    | BMQ705                    | 0.9406\n",
      "PZ171M                    | PZ171M                    | 0.9823\n",
      "JXP8326                   | JXP8326                   | 0.9977\n",
      "WNH553                    | WNH553                    | 0.9980\n",
      "VJD5050                   | VJD5050                   | 0.9755\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 116 done in 1.9s | train_loss=0.0005  valid_loss=1.0972  valid_acc=59.52%\n",
      "\n",
      "no improvement for 1/100 epochs\n",
      "\n",
      "→ Starting epoch 117  (printing every 28 iters)\n",
      "[Epoch 117] iter 28/28, avg loss: 0.0005\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QKB1883                   | QKB1883                   | 0.9809\n",
      "VNF1215                   | VNF1215                   | 0.9809\n",
      "BNN2887                   | BNN2887                   | 0.9613\n",
      "QAB4250A                  | QAB4250A                  | 0.9363\n",
      "QAA7649N                  | QAA7649N                  | 0.9841\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 117 done in 2.0s | train_loss=0.0005  valid_loss=1.0949  valid_acc=58.73%\n",
      "\n",
      "no improvement for 2/100 epochs\n",
      "\n",
      "→ Starting epoch 118  (printing every 28 iters)\n",
      "[Epoch 118] iter 28/28, avg loss: 0.0005\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WUV9209                   | WUV9209                   | 0.9775\n",
      "PRH5551                   | PRH5551                   | 0.9990\n",
      "WXT2433                   | WXT2433                   | 0.9977\n",
      "VML5392                   | VML5392                   | 0.9799\n",
      "QA                        | QA                        | 0.9987\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 118 done in 1.9s | train_loss=0.0005  valid_loss=1.0982  valid_acc=59.13%\n",
      "\n",
      "no improvement for 3/100 epochs\n",
      "\n",
      "→ Starting epoch 119  (printing every 28 iters)\n",
      "[Epoch 119] iter 28/28, avg loss: 0.0005\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "T/M232                    | T/M232                    | 0.9947\n",
      "QKW3360                   | QKW3360                   | 0.9815\n",
      "RC9863                    | RC9863                    | 0.9883\n",
      "NBW7154                   | NBW7154                   | 0.9971\n",
      "QCQ3562                   | QCQ3562                   | 0.9934\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 119 done in 1.9s | train_loss=0.0005  valid_loss=1.1001  valid_acc=58.73%\n",
      "\n",
      "no improvement for 4/100 epochs\n",
      "\n",
      "→ Starting epoch 120  (printing every 28 iters)\n",
      "[Epoch 120] iter 28/28, avg loss: 0.0005\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QLB7733                   | QLB7733                   | 0.9852\n",
      "NEA3805                   | NEA3805                   | 0.9754\n",
      "QSV1707                   | QSV1707                   | 0.9861\n",
      "1M4U3172                  | 1M4U3172                  | 0.9930\n",
      "AFL6541                   | AFL6541                   | 0.9832\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 120 done in 2.0s | train_loss=0.0005  valid_loss=1.1010  valid_acc=59.52%\n",
      "\n",
      "no improvement for 5/100 epochs\n",
      "\n",
      "→ Starting epoch 121  (printing every 28 iters)\n",
      "[Epoch 121] iter 28/28, avg loss: 0.0005\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VND3893                   | VND3893                   | 0.9891\n",
      "WC3688R                   | WC3688R                   | 0.9882\n",
      "BHX5241                   | BHX5241                   | 0.9895\n",
      "ANQ3799                   | ANQ3799                   | 0.9765\n",
      "VNQ4338                   | VNQ4338                   | 0.9966\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 121 done in 1.9s | train_loss=0.0005  valid_loss=1.1037  valid_acc=59.52%\n",
      "\n",
      "no improvement for 6/100 epochs\n",
      "\n",
      "→ Starting epoch 122  (printing every 28 iters)\n",
      "[Epoch 122] iter 28/28, avg loss: 0.0005\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "PKS9266                   | PKS9266                   | 0.9792\n",
      "QAB4250A                  | QAB4250A                  | 0.9389\n",
      "WFK2926                   | WFK2926                   | 0.9883\n",
      "NDB8499                   | NDB8499                   | 0.9963\n",
      "VCQ7119                   | VCQ7119                   | 0.9900\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 122 done in 1.9s | train_loss=0.0005  valid_loss=1.1001  valid_acc=59.13%\n",
      "\n",
      "no improvement for 7/100 epochs\n",
      "\n",
      "→ Starting epoch 123  (printing every 28 iters)\n",
      "[Epoch 123] iter 28/28, avg loss: 0.0004\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAA5623H                  | QAA5623H                  | 0.9992\n",
      "AHU7727                   | AHU7727                   | 0.9987\n",
      "QAM1319                   | QAM1319                   | 0.9812\n",
      "MDT7793                   | MDT7793                   | 0.9704\n",
      "KFT4037                   | KFT4037                   | 0.9917\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 123 done in 1.9s | train_loss=0.0004  valid_loss=1.1031  valid_acc=59.13%\n",
      "\n",
      "no improvement for 8/100 epochs\n",
      "\n",
      "→ Starting epoch 124  (printing every 28 iters)\n",
      "[Epoch 124] iter 28/28, avg loss: 0.0004\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "B3106A                    | B3106A                    | 0.9639\n",
      "BQP5287                   | BQP5287                   | 0.9746\n",
      "TBE9333                   | TBE9333                   | 0.9804\n",
      "WLP6892                   | WLP6892                   | 0.9776\n",
      "DFC4000                   | DFC4000                   | 0.9975\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 124 done in 1.9s | train_loss=0.0004  valid_loss=1.1056  valid_acc=59.13%\n",
      "\n",
      "no improvement for 9/100 epochs\n",
      "\n",
      "→ Starting epoch 125  (printing every 28 iters)\n",
      "[Epoch 125] iter 28/28, avg loss: 0.0004\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "NAH1048                   | NAH1048                   | 0.9005\n",
      "SMC5054                   | SMC5054                   | 0.9769\n",
      "DBR9492                   | DBR9492                   | 0.9797\n",
      "QAA3323X                  | QAA3323X                  | 0.9840\n",
      "JVD7333                   | JVD7333                   | 0.9822\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 125 done in 1.9s | train_loss=0.0004  valid_loss=1.1075  valid_acc=59.52%\n",
      "\n",
      "no improvement for 10/100 epochs\n",
      "\n",
      "→ Starting epoch 126  (printing every 28 iters)\n",
      "[Epoch 126] iter 28/28, avg loss: 0.0004\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "PZ171M                    | PZ171M                    | 0.9466\n",
      "MCN7929                   | MCN7929                   | 0.9831\n",
      "WUS4781                   | WUS4781                   | 0.9968\n",
      "TV333                     | TV333                     | 0.9371\n",
      "NAP4617                   | NAP4617                   | 0.9957\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 126 done in 1.9s | train_loss=0.0004  valid_loss=1.1060  valid_acc=58.73%\n",
      "\n",
      "no improvement for 11/100 epochs\n",
      "\n",
      "→ Starting epoch 127  (printing every 28 iters)\n",
      "[Epoch 127] iter 28/28, avg loss: 0.0004\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QS9953S                   | QS9953S                   | 0.9704\n",
      "JWC6011                   | JWC6011                   | 0.9723\n",
      "DDM8378                   | DDM8378                   | 0.9864\n",
      "VNQ2521                   | VNQ2521                   | 0.9974\n",
      "NAD9748                   | NAD9748                   | 0.9730\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 127 done in 1.8s | train_loss=0.0004  valid_loss=1.1050  valid_acc=58.73%\n",
      "\n",
      "no improvement for 12/100 epochs\n",
      "\n",
      "→ Starting epoch 128  (printing every 28 iters)\n",
      "[Epoch 128] iter 28/28, avg loss: 0.0004\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "MADANI7776                | MADANI7776                | 0.9089\n",
      "JUA9705                   | JUA9705                   | 0.9833\n",
      "WQX3834                   | WQX3834                   | 0.9844\n",
      "MDC8333                   | MDC8333                   | 0.9692\n",
      "WEH8092                   | WEH8092                   | 0.9386\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 128 done in 1.9s | train_loss=0.0004  valid_loss=1.1086  valid_acc=59.52%\n",
      "\n",
      "no improvement for 13/100 epochs\n",
      "\n",
      "→ Starting epoch 129  (printing every 28 iters)\n",
      "[Epoch 129] iter 28/28, avg loss: 0.0004\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WHL8046                   | WHL8046                   | 0.9879\n",
      "QPC5351                   | QPC5351                   | 0.9777\n",
      "WB302Q                    | WB302Q                    | 0.9709\n",
      "PPD2622                   | PPD2622                   | 0.9974\n",
      "ACM5600                   | ACM5600                   | 0.9783\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 129 done in 1.9s | train_loss=0.0004  valid_loss=1.1086  valid_acc=58.73%\n",
      "\n",
      "no improvement for 14/100 epochs\n",
      "\n",
      "→ Starting epoch 130  (printing every 28 iters)\n",
      "[Epoch 130] iter 28/28, avg loss: 0.0004\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "AFL6541                   | AFL6541                   | 0.9852\n",
      "NCQ2205                   | NCQ2205                   | 0.9822\n",
      "QAB8977J                  | QAB8977J                  | 0.9779\n",
      "WNL3044                   | WNL3044                   | 0.9853\n",
      "WWM4401                   | WWM4401                   | 0.9958\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 130 done in 1.9s | train_loss=0.0004  valid_loss=1.1090  valid_acc=59.13%\n",
      "\n",
      "no improvement for 15/100 epochs\n",
      "\n",
      "→ Starting epoch 131  (printing every 28 iters)\n",
      "[Epoch 131] iter 28/28, avg loss: 0.0004\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "ACS237                    | ACS237                    | 0.9711\n",
      "ADM250                    | ADM250                    | 0.9962\n",
      "TCN8474                   | TCN8474                   | 0.9792\n",
      "TCJ8981                   | TCJ8981                   | 0.9977\n",
      "WMW7786                   | WMW7786                   | 0.9660\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 131 done in 1.9s | train_loss=0.0004  valid_loss=1.1087  valid_acc=59.13%\n",
      "\n",
      "no improvement for 16/100 epochs\n",
      "\n",
      "→ Starting epoch 132  (printing every 28 iters)\n",
      "[Epoch 132] iter 28/28, avg loss: 0.0004\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QS9917F                   | QS9917F                   | 0.9937\n",
      "BMG317                    | BMG317                    | 0.9199\n",
      "JVB5509                   | JVB5509                   | 0.9906\n",
      "AMT5830                   | AMT5830                   | 0.9870\n",
      "BDW7792                   | BDW7792                   | 0.9901\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 132 done in 1.8s | train_loss=0.0004  valid_loss=1.1125  valid_acc=59.52%\n",
      "\n",
      "no improvement for 17/100 epochs\n",
      "\n",
      "→ Starting epoch 133  (printing every 28 iters)\n",
      "[Epoch 133] iter 28/28, avg loss: 0.0004\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "JWA8158                   | JWA8158                   | 0.9850\n",
      "WD1915A                   | WD1915A                   | 0.9991\n",
      "BGW2901                   | BGW2901                   | 0.9712\n",
      "VDM8068                   | VDM8068                   | 0.9897\n",
      "WA1309F                   | WA1309F                   | 0.9733\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 133 done in 1.9s | train_loss=0.0004  valid_loss=1.1137  valid_acc=58.73%\n",
      "\n",
      "no improvement for 18/100 epochs\n",
      "\n",
      "→ Starting epoch 134  (printing every 28 iters)\n",
      "[Epoch 134] iter 28/28, avg loss: 0.0004\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "TCC1724                   | TCC1724                   | 0.9967\n",
      "VM6611                    | VM6611                    | 0.9996\n",
      "T/BE110                   | T/BE110                   | 0.9770\n",
      "JPV7715                   | JPV7715                   | 0.9961\n",
      "AM7017                    | AM7017                    | 0.9910\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 134 done in 1.9s | train_loss=0.0004  valid_loss=1.1158  valid_acc=59.13%\n",
      "\n",
      "no improvement for 19/100 epochs\n",
      "\n",
      "→ Starting epoch 135  (printing every 28 iters)\n",
      "[Epoch 135] iter 28/28, avg loss: 0.0004\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "T/JA383                   | T/JA383                   | 0.9877\n",
      "WLH6202                   | WLH6202                   | 0.9850\n",
      "SYU3073                   | SYU3073                   | 0.9568\n",
      "JCY7217                   | JCY7217                   | 0.9981\n",
      "W/TP3358                  | W/TP3358                  | 0.9754\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 135 done in 1.9s | train_loss=0.0004  valid_loss=1.1152  valid_acc=58.73%\n",
      "\n",
      "no improvement for 20/100 epochs\n",
      "\n",
      "→ Starting epoch 136  (printing every 28 iters)\n",
      "[Epoch 136] iter 28/28, avg loss: 0.0004\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "JAT2299                   | JAT2299                   | 0.9949\n",
      "QAB9886J                  | QAB9886J                  | 0.9517\n",
      "W3426P                    | W3426P                    | 0.9979\n",
      "AFL6541                   | AFL6541                   | 0.9836\n",
      "QLB7733                   | QLB7733                   | 0.9943\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 136 done in 1.9s | train_loss=0.0004  valid_loss=1.1162  valid_acc=58.33%\n",
      "\n",
      "no improvement for 21/100 epochs\n",
      "\n",
      "→ Starting epoch 137  (printing every 28 iters)\n",
      "[Epoch 137] iter 28/28, avg loss: 0.0004\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAB3330B                  | QAB3330B                  | 0.9789\n",
      "VAK1383                   | VAK1383                   | 0.9859\n",
      "WWN1840                   | WWN1840                   | 0.9937\n",
      "WYL2575                   | WYL2575                   | 0.9820\n",
      "437B                      | 437B                      | 0.9438\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 137 done in 2.0s | train_loss=0.0004  valid_loss=1.1186  valid_acc=58.73%\n",
      "\n",
      "no improvement for 22/100 epochs\n",
      "\n",
      "→ Starting epoch 138  (printing every 28 iters)\n",
      "[Epoch 138] iter 28/28, avg loss: 0.0004\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "TBT3323                   | TBT3323                   | 0.9892\n",
      "WD1915A                   | WD1915A                   | 0.9995\n",
      "QAA2269Y                  | QAA2269Y                  | 0.9981\n",
      "MCV1838                   | MCV1838                   | 0.9839\n",
      "NCQ2205                   | NCQ2205                   | 0.9852\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 138 done in 2.0s | train_loss=0.0004  valid_loss=1.1186  valid_acc=58.73%\n",
      "\n",
      "no improvement for 23/100 epochs\n",
      "\n",
      "→ Starting epoch 139  (printing every 28 iters)\n",
      "[Epoch 139] iter 28/28, avg loss: 0.0004\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "JRN7985                   | JRN7985                   | 0.9866\n",
      "FD10                      | FD10                      | 0.9191\n",
      "VFV2696                   | VFV2696                   | 0.9767\n",
      "JWQ5113                   | JWQ5113                   | 0.9775\n",
      "KDN1893                   | KDN1893                   | 0.9959\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 139 done in 1.9s | train_loss=0.0004  valid_loss=1.1211  valid_acc=59.13%\n",
      "\n",
      "no improvement for 24/100 epochs\n",
      "\n",
      "→ Starting epoch 140  (printing every 28 iters)\n",
      "[Epoch 140] iter 28/28, avg loss: 0.0004\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAB2899K                  | QAB2899K                  | 0.9993\n",
      "SMC3363                   | SMC3363                   | 0.9777\n",
      "VCQ7119                   | VCQ7119                   | 0.9551\n",
      "VEN9194                   | VEN9194                   | 0.9597\n",
      "QAL6939                   | QAL6939                   | 0.9784\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 140 done in 2.0s | train_loss=0.0004  valid_loss=1.1227  valid_acc=59.13%\n",
      "\n",
      "no improvement for 25/100 epochs\n",
      "\n",
      "→ Starting epoch 141  (printing every 28 iters)\n",
      "[Epoch 141] iter 28/28, avg loss: 0.0004\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "T/BB578                   | T/BB578                   | 0.9831\n",
      "QCA6734                   | QCA6734                   | 0.9915\n",
      "MAM6063                   | MAM6063                   | 0.9627\n",
      "JSL6628                   | JSL6628                   | 0.9851\n",
      "JNB388                    | JNB388                    | 0.9949\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 141 done in 1.9s | train_loss=0.0004  valid_loss=1.1196  valid_acc=59.52%\n",
      "\n",
      "no improvement for 26/100 epochs\n",
      "\n",
      "→ Starting epoch 142  (printing every 28 iters)\n",
      "[Epoch 142] iter 28/28, avg loss: 0.0004\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAA2662Q                  | QAA2662Q                  | 0.9947\n",
      "BDW7792                   | BDW7792                   | 0.9959\n",
      "SJG8699                   | SJG8699                   | 0.9966\n",
      "MCN7929                   | MCN7929                   | 0.9348\n",
      "BCU7612                   | BCU7612                   | 0.9690\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 142 done in 1.9s | train_loss=0.0004  valid_loss=1.1182  valid_acc=59.13%\n",
      "\n",
      "no improvement for 27/100 epochs\n",
      "\n",
      "→ Starting epoch 143  (printing every 28 iters)\n",
      "[Epoch 143] iter 28/28, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QCE9329                   | QCE9329                   | 0.9986\n",
      "BJR9891                   | BJR9891                   | 0.9836\n",
      "BNY4363                   | BNY4363                   | 0.9919\n",
      "KDS818                    | KDS818                    | 0.9785\n",
      "WLC9954                   | WLC9954                   | 0.9951\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 143 done in 1.9s | train_loss=0.0003  valid_loss=1.1216  valid_acc=59.52%\n",
      "\n",
      "no improvement for 28/100 epochs\n",
      "\n",
      "→ Starting epoch 144  (printing every 28 iters)\n",
      "[Epoch 144] iter 28/28, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAA8656V                  | QAA8656V                  | 0.9989\n",
      "ANU7888                   | ANU7888                   | 0.9981\n",
      "VET8129                   | VET8129                   | 0.9499\n",
      "PDP6868                   | PDP6868                   | 0.9723\n",
      "CEN2010                   | CEN2010                   | 0.9868\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 144 done in 1.9s | train_loss=0.0003  valid_loss=1.1257  valid_acc=59.52%\n",
      "\n",
      "no improvement for 29/100 epochs\n",
      "\n",
      "→ Starting epoch 145  (printing every 28 iters)\n",
      "[Epoch 145] iter 28/28, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "SJF5203                   | SJF5203                   | 0.9963\n",
      "NCB7903                   | NCB7903                   | 0.9888\n",
      "PDV5663                   | PDV5663                   | 0.9741\n",
      "ADY2688                   | ADY2688                   | 0.9942\n",
      "QAB751H                   | QAB751H                   | 0.9996\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 145 done in 1.9s | train_loss=0.0003  valid_loss=1.1229  valid_acc=59.52%\n",
      "\n",
      "no improvement for 30/100 epochs\n",
      "\n",
      "→ Starting epoch 146  (printing every 28 iters)\n",
      "[Epoch 146] iter 28/28, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VN815                     | VN815                     | 0.9908\n",
      "QAA3955H                  | QAA3955H                  | 0.9940\n",
      "MW2567                    | MW2567                    | 0.9971\n",
      "T/JA6344                  | T/JA6344                  | 0.9772\n",
      "KER3235                   | KER3235                   | 0.9916\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 146 done in 1.9s | train_loss=0.0003  valid_loss=1.1215  valid_acc=59.13%\n",
      "\n",
      "no improvement for 31/100 epochs\n",
      "\n",
      "→ Starting epoch 147  (printing every 28 iters)\n",
      "[Epoch 147] iter 28/28, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QA                        | QA                        | 0.9990\n",
      "AMR9464                   | AMR9464                   | 0.9844\n",
      "QAN3559                   | QAN3559                   | 0.9830\n",
      "QKT8216                   | QKT8216                   | 0.9831\n",
      "ANQ3799                   | ANQ3799                   | 0.9754\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 147 done in 1.9s | train_loss=0.0003  valid_loss=1.1275  valid_acc=59.13%\n",
      "\n",
      "no improvement for 32/100 epochs\n",
      "\n",
      "→ Starting epoch 148  (printing every 28 iters)\n",
      "[Epoch 148] iter 28/28, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "AMT5830                   | AMT5830                   | 0.9853\n",
      "QS9917F                   | QS9917F                   | 0.9931\n",
      "PDM2966                   | PDM2966                   | 0.9996\n",
      "AHA3878                   | AHA3878                   | 0.9892\n",
      "MM3966                    | MM3966                    | 0.9917\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 148 done in 1.8s | train_loss=0.0003  valid_loss=1.1277  valid_acc=59.52%\n",
      "\n",
      "no improvement for 33/100 epochs\n",
      "\n",
      "→ Starting epoch 149  (printing every 28 iters)\n",
      "[Epoch 149] iter 28/28, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "PEA1781                   | PEA1781                   | 0.9571\n",
      "PHX8121                   | PHX8121                   | 0.9989\n",
      "WVB5362                   | WVB5362                   | 0.9994\n",
      "JSD809                    | JSD809                    | 0.9980\n",
      "JTC5690                   | JTC5690                   | 0.9549\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 149 done in 1.8s | train_loss=0.0003  valid_loss=1.1295  valid_acc=59.52%\n",
      "\n",
      "no improvement for 34/100 epochs\n",
      "\n",
      "→ Starting epoch 150  (printing every 28 iters)\n",
      "[Epoch 150] iter 28/28, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "AMR1971                   | AMR1971                   | 0.9902\n",
      "MDN8761                   | MDN8761                   | 0.9561\n",
      "PEJ9595                   | PEJ9595                   | 0.9964\n",
      "WUV9209                   | WUV9209                   | 0.9852\n",
      "QAL6939                   | QAL6939                   | 0.9953\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 150 done in 1.8s | train_loss=0.0003  valid_loss=1.1275  valid_acc=59.13%\n",
      "\n",
      "no improvement for 35/100 epochs\n",
      "\n",
      "→ Starting epoch 151  (printing every 28 iters)\n",
      "[Epoch 151] iter 28/28, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VFN701                    | VFN701                    | 0.9884\n",
      "MDS7658                   | MDS7658                   | 0.9593\n",
      "TBT9322                   | TBT9322                   | 0.9818\n",
      "JLX6457                   | JLX6457                   | 0.9917\n",
      "QCG9631                   | QCG9631                   | 0.9883\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 151 done in 1.9s | train_loss=0.0003  valid_loss=1.1298  valid_acc=59.13%\n",
      "\n",
      "no improvement for 36/100 epochs\n",
      "\n",
      "→ Starting epoch 152  (printing every 28 iters)\n",
      "[Epoch 152] iter 28/28, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VML5392                   | VML5392                   | 0.9732\n",
      "VEN9194                   | VEN9194                   | 0.9545\n",
      "QAA4174                   | QAA4174                   | 0.9793\n",
      "T/JJ115                   | T/JJ115                   | 0.9587\n",
      "KEQ9236                   | KEQ9236                   | 0.9566\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 152 done in 1.9s | train_loss=0.0003  valid_loss=1.1326  valid_acc=59.52%\n",
      "\n",
      "no improvement for 37/100 epochs\n",
      "\n",
      "→ Starting epoch 153  (printing every 28 iters)\n",
      "[Epoch 153] iter 28/28, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WB8444L                   | WB8444L                   | 0.9945\n",
      "WXM1116                   | WXM1116                   | 0.9926\n",
      "QAM1319                   | QAM1319                   | 0.9814\n",
      "WB7028W                   | WB7028W                   | 0.9764\n",
      "VCG9239                   | VCG9239                   | 0.9987\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 153 done in 1.8s | train_loss=0.0003  valid_loss=1.1312  valid_acc=58.73%\n",
      "\n",
      "no improvement for 38/100 epochs\n",
      "\n",
      "→ Starting epoch 154  (printing every 28 iters)\n",
      "[Epoch 154] iter 28/28, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "TBE9333                   | TBE9333                   | 0.9763\n",
      "TBY9929                   | TBY9929                   | 0.9566\n",
      "VNN6819                   | VNN6819                   | 0.9959\n",
      "VBY8203                   | VBY8203                   | 0.9659\n",
      "JNW595                    | JNW595                    | 0.9790\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 154 done in 1.8s | train_loss=0.0003  valid_loss=1.1292  valid_acc=59.52%\n",
      "\n",
      "no improvement for 39/100 epochs\n",
      "\n",
      "→ Starting epoch 155  (printing every 28 iters)\n",
      "[Epoch 155] iter 28/28, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "PC8558A                   | PC8558A                   | 0.9967\n",
      "VFX447                    | VFX447                    | 0.9823\n",
      "TAM408                    | TAM408                    | 0.9713\n",
      "QS4848D                   | QS4848D                   | 0.9857\n",
      "BQX3898                   | BQX3898                   | 0.9416\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 155 done in 1.8s | train_loss=0.0003  valid_loss=1.1315  valid_acc=59.13%\n",
      "\n",
      "no improvement for 40/100 epochs\n",
      "\n",
      "→ Starting epoch 156  (printing every 28 iters)\n",
      "[Epoch 156] iter 28/28, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VEN6862                   | VEN6862                   | 0.9745\n",
      "GOLD5564                  | GOLD5564                  | 0.9794\n",
      "VCQ7119                   | VCQ7119                   | 0.9549\n",
      "VHR7459                   | VHR7459                   | 0.9788\n",
      "QTP5862                   | QTP5862                   | 0.9846\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 156 done in 1.9s | train_loss=0.0003  valid_loss=1.1346  valid_acc=59.52%\n",
      "\n",
      "no improvement for 41/100 epochs\n",
      "\n",
      "→ Starting epoch 157  (printing every 28 iters)\n",
      "[Epoch 157] iter 28/28, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "PPA4817                   | PPA4817                   | 0.9978\n",
      "PJN5826                   | PJN5826                   | 0.9569\n",
      "GOLD5564                  | GOLD5564                  | 0.9828\n",
      "QKA7085                   | QKA7085                   | 0.9973\n",
      "QAB7859A                  | QAB7859A                  | 0.9695\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 157 done in 2.0s | train_loss=0.0003  valid_loss=1.1358  valid_acc=59.52%\n",
      "\n",
      "no improvement for 42/100 epochs\n",
      "\n",
      "→ Starting epoch 158  (printing every 28 iters)\n",
      "[Epoch 158] iter 28/28, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WFK2926                   | WFK2926                   | 0.9873\n",
      "VKG5010                   | VKG5010                   | 0.9824\n",
      "NCU3622                   | NCU3622                   | 0.9857\n",
      "BQP5287                   | BQP5287                   | 0.9794\n",
      "JSH4299                   | JSH4299                   | 0.9409\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 158 done in 1.9s | train_loss=0.0003  valid_loss=1.1361  valid_acc=59.13%\n",
      "\n",
      "no improvement for 43/100 epochs\n",
      "\n",
      "→ Starting epoch 159  (printing every 28 iters)\n",
      "[Epoch 159] iter 28/28, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "KFW2299                   | KFW2299                   | 0.9993\n",
      "T/WC3                     | T/WC3                     | 0.9882\n",
      "WWM4401                   | WWM4401                   | 0.9945\n",
      "WB8444L                   | WB8444L                   | 0.9731\n",
      "SMK5                      | SMK5                      | 0.9580\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 159 done in 1.9s | train_loss=0.0003  valid_loss=1.1331  valid_acc=59.52%\n",
      "\n",
      "no improvement for 44/100 epochs\n",
      "\n",
      "→ Starting epoch 160  (printing every 28 iters)\n",
      "[Epoch 160] iter 28/28, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "BPT2823                   | BPT2823                   | 0.9809\n",
      "T/WB434                   | T/WB434                   | 0.9777\n",
      "VK1800                    | VK1800                    | 0.9995\n",
      "AKW716                    | AKW716                    | 0.9634\n",
      "ANB9161                   | ANB9161                   | 0.9460\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 160 done in 2.0s | train_loss=0.0003  valid_loss=1.1338  valid_acc=58.73%\n",
      "\n",
      "no improvement for 45/100 epochs\n",
      "\n",
      "→ Starting epoch 161  (printing every 28 iters)\n",
      "[Epoch 161] iter 28/28, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "ADM250                    | ADM250                    | 0.9958\n",
      "JCY7217                   | JCY7217                   | 0.9995\n",
      "JUH2988                   | JUH2988                   | 0.9892\n",
      "DCS8812                   | DCS8812                   | 0.9960\n",
      "VAA7076                   | VAA7076                   | 0.9987\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 161 done in 2.0s | train_loss=0.0003  valid_loss=1.1369  valid_acc=59.13%\n",
      "\n",
      "no improvement for 46/100 epochs\n",
      "\n",
      "→ Starting epoch 162  (printing every 28 iters)\n",
      "[Epoch 162] iter 28/28, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "MCR5505                   | MCR5505                   | 0.9870\n",
      "MBT7931                   | MBT7931                   | 0.9714\n",
      "BNB8655                   | BNB8655                   | 0.9562\n",
      "QKF9126                   | QKF9126                   | 0.9893\n",
      "UNIMAS6119                | UNIMAS6119                | 0.9752\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 162 done in 1.9s | train_loss=0.0003  valid_loss=1.1362  valid_acc=59.52%\n",
      "\n",
      "no improvement for 47/100 epochs\n",
      "\n",
      "→ Starting epoch 163  (printing every 28 iters)\n",
      "[Epoch 163] iter 28/28, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "KAK2779                   | KAK2779                   | 0.9984\n",
      "QAM1319                   | QAM1319                   | 0.9865\n",
      "TAM408                    | TAM408                    | 0.9774\n",
      "WJE4152                   | WJE4152                   | 0.9671\n",
      "QCG650                    | QCG650                    | 0.9912\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 163 done in 1.8s | train_loss=0.0003  valid_loss=1.1373  valid_acc=59.13%\n",
      "\n",
      "no improvement for 48/100 epochs\n",
      "\n",
      "→ Starting epoch 164  (printing every 28 iters)\n",
      "[Epoch 164] iter 28/28, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "BLR9830                   | BLR9830                   | 0.9639\n",
      "AKX8453                   | AKX8453                   | 0.9543\n",
      "JNB388                    | JNB388                    | 0.9922\n",
      "WC3399L                   | WC3399L                   | 0.9761\n",
      "WC178M                    | WC178M                    | 0.9909\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 164 done in 1.9s | train_loss=0.0003  valid_loss=1.1397  valid_acc=59.52%\n",
      "\n",
      "no improvement for 49/100 epochs\n",
      "\n",
      "→ Starting epoch 165  (printing every 28 iters)\n",
      "[Epoch 165] iter 28/28, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WWM4401                   | WWM4401                   | 0.9916\n",
      "PLS114                    | PLS114                    | 0.9795\n",
      "QTT7328                   | QTT7328                   | 0.9531\n",
      "WLH6202                   | WLH6202                   | 0.9941\n",
      "KDU3612                   | KDU3612                   | 0.9934\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 165 done in 1.9s | train_loss=0.0003  valid_loss=1.1363  valid_acc=58.73%\n",
      "\n",
      "no improvement for 50/100 epochs\n",
      "\n",
      "→ Starting epoch 166  (printing every 28 iters)\n",
      "[Epoch 166] iter 28/28, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAM1319                   | QAM1319                   | 0.9880\n",
      "BDW7792                   | BDW7792                   | 0.9968\n",
      "ADM250                    | ADM250                    | 0.9961\n",
      "VNQ2521                   | VNQ2521                   | 0.9977\n",
      "JWQ5113                   | JWQ5113                   | 0.9750\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 166 done in 1.8s | train_loss=0.0003  valid_loss=1.1408  valid_acc=59.52%\n",
      "\n",
      "no improvement for 51/100 epochs\n",
      "\n",
      "→ Starting epoch 167  (printing every 28 iters)\n",
      "[Epoch 167] iter 28/28, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WUV1028                   | WUV1028                   | 0.9813\n",
      "PGL2189                   | PGL2189                   | 0.9753\n",
      "WTK7060                   | WTK7060                   | 0.9837\n",
      "JJE2328                   | JJE2328                   | 0.9347\n",
      "T/BE110                   | T/BE110                   | 0.9742\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 167 done in 1.9s | train_loss=0.0003  valid_loss=1.1428  valid_acc=59.52%\n",
      "\n",
      "no improvement for 52/100 epochs\n",
      "\n",
      "→ Starting epoch 168  (printing every 28 iters)\n",
      "[Epoch 168] iter 28/28, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WXQ6691                   | WXQ6691                   | 0.9789\n",
      "VDM8068                   | VDM8068                   | 0.9909\n",
      "WJE4152                   | WJE4152                   | 0.9652\n",
      "QTY1471                   | QTY1471                   | 0.9981\n",
      "BPL7211                   | BPL7211                   | 0.9786\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 168 done in 1.9s | train_loss=0.0003  valid_loss=1.1447  valid_acc=59.13%\n",
      "\n",
      "no improvement for 53/100 epochs\n",
      "\n",
      "→ Starting epoch 169  (printing every 28 iters)\n",
      "[Epoch 169] iter 28/28, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "SMB5095                   | SMB5095                   | 0.9939\n",
      "QS5039N                   | QS5039N                   | 0.9856\n",
      "KDH2309                   | KDH2309                   | 0.9962\n",
      "RC9863                    | RC9863                    | 0.9793\n",
      "AKK4491                   | AKK4491                   | 0.9802\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 169 done in 1.9s | train_loss=0.0003  valid_loss=1.1431  valid_acc=59.13%\n",
      "\n",
      "no improvement for 54/100 epochs\n",
      "\n",
      "→ Starting epoch 170  (printing every 28 iters)\n",
      "[Epoch 170] iter 28/28, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QTA2566                   | QTA2566                   | 0.9892\n",
      "RC9863                    | RC9863                    | 0.9983\n",
      "VEN9194                   | VEN9194                   | 0.9664\n",
      "SMB5095                   | SMB5095                   | 0.9955\n",
      "BJF5469                   | BJF5469                   | 0.9830\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 170 done in 1.9s | train_loss=0.0003  valid_loss=1.1455  valid_acc=58.33%\n",
      "\n",
      "no improvement for 55/100 epochs\n",
      "\n",
      "→ Starting epoch 171  (printing every 28 iters)\n",
      "[Epoch 171] iter 28/28, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "UM2356                    | UM2356                    | 0.9978\n",
      "DAG309                    | DAG309                    | 0.9942\n",
      "QAA2269Y                  | QAA2269Y                  | 0.9987\n",
      "BKB9642                   | BKB9642                   | 0.9741\n",
      "NDM4685                   | NDM4685                   | 0.9986\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 171 done in 1.9s | train_loss=0.0003  valid_loss=1.1450  valid_acc=59.52%\n",
      "\n",
      "no improvement for 56/100 epochs\n",
      "\n",
      "→ Starting epoch 172  (printing every 28 iters)\n",
      "[Epoch 172] iter 28/28, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "JFR4363                   | JFR4363                   | 0.9874\n",
      "TBE9333                   | TBE9333                   | 0.9798\n",
      "QAA7135S                  | QAA7135S                  | 0.9757\n",
      "WJH663                    | WJH663                    | 0.9969\n",
      "QAX6845                   | QAX6845                   | 0.9981\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 172 done in 1.9s | train_loss=0.0003  valid_loss=1.1487  valid_acc=59.13%\n",
      "\n",
      "no improvement for 57/100 epochs\n",
      "\n",
      "→ Starting epoch 173  (printing every 28 iters)\n",
      "[Epoch 173] iter 28/28, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QMY4519                   | QMY4519                   | 0.9751\n",
      "SMP7647                   | SMP7647                   | 0.9901\n",
      "RR1776                    | RR1776                    | 0.9944\n",
      "QAN3559                   | QAN3559                   | 0.9879\n",
      "JUS8529                   | JUS8529                   | 0.9728\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 173 done in 1.9s | train_loss=0.0003  valid_loss=1.1452  valid_acc=59.52%\n",
      "\n",
      "no improvement for 58/100 epochs\n",
      "\n",
      "→ Starting epoch 174  (printing every 28 iters)\n",
      "[Epoch 174] iter 28/28, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "MAM6063                   | MAM6063                   | 0.9770\n",
      "PC1811P                   | PC1811P                   | 0.9869\n",
      "VDA4811                   | VDA4811                   | 0.9897\n",
      "QCP6838                   | QCP6838                   | 0.9789\n",
      "AMT5830                   | AMT5830                   | 0.9862\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 174 done in 1.9s | train_loss=0.0003  valid_loss=1.1465  valid_acc=59.52%\n",
      "\n",
      "no improvement for 59/100 epochs\n",
      "\n",
      "→ Starting epoch 175  (printing every 28 iters)\n",
      "[Epoch 175] iter 28/28, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "ALC3644                   | ALC3644                   | 0.9600\n",
      "VJA520                    | VJA520                    | 0.9978\n",
      "WTQ3638                   | WTQ3638                   | 0.9924\n",
      "JWY375                    | JWY375                    | 0.9919\n",
      "AMR1971                   | AMR1971                   | 0.9866\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 175 done in 1.9s | train_loss=0.0003  valid_loss=1.1481  valid_acc=59.52%\n",
      "\n",
      "no improvement for 60/100 epochs\n",
      "\n",
      "→ Starting epoch 176  (printing every 28 iters)\n",
      "[Epoch 176] iter 28/28, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAT2882                   | QAT2882                   | 0.9749\n",
      "PDG4307                   | PDG4307                   | 0.9978\n",
      "RT9009                    | RT9009                    | 0.9773\n",
      "PC8558A                   | PC8558A                   | 0.9967\n",
      "JTU3636                   | JTU3636                   | 0.9571\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 176 done in 1.9s | train_loss=0.0003  valid_loss=1.1490  valid_acc=59.52%\n",
      "\n",
      "no improvement for 61/100 epochs\n",
      "\n",
      "→ Starting epoch 177  (printing every 28 iters)\n",
      "[Epoch 177] iter 28/28, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "JTS9633                   | JTS9633                   | 0.9887\n",
      "JRP7041                   | JRP7041                   | 0.9846\n",
      "VGT9721                   | VGT9721                   | 0.9691\n",
      "VMN5788                   | VMN5788                   | 0.9837\n",
      "JVB5509                   | JVB5509                   | 0.9936\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 177 done in 1.9s | train_loss=0.0003  valid_loss=1.1463  valid_acc=59.13%\n",
      "\n",
      "no improvement for 62/100 epochs\n",
      "\n",
      "→ Starting epoch 178  (printing every 28 iters)\n",
      "[Epoch 178] iter 28/28, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VAS3035                   | VAS3035                   | 0.9986\n",
      "ADM250                    | ADM250                    | 0.9970\n",
      "QM4997P                   | QM4997P                   | 0.9842\n",
      "PHY2884                   | PHY2884                   | 0.9961\n",
      "QAA1918D                  | QAA1918D                  | 0.9998\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 178 done in 1.9s | train_loss=0.0003  valid_loss=1.1482  valid_acc=59.52%\n",
      "\n",
      "no improvement for 63/100 epochs\n",
      "\n",
      "→ Starting epoch 179  (printing every 28 iters)\n",
      "[Epoch 179] iter 28/28, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "W6916B                    | W6916B                    | 0.9651\n",
      "VDD4069                   | VDD4069                   | 0.9986\n",
      "PQS5137                   | PQS5137                   | 0.9973\n",
      "WTP2102                   | WTP2102                   | 0.9777\n",
      "QKL8220                   | QKL8220                   | 0.9906\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 179 done in 1.9s | train_loss=0.0003  valid_loss=1.1532  valid_acc=59.13%\n",
      "\n",
      "no improvement for 64/100 epochs\n",
      "\n",
      "→ Starting epoch 180  (printing every 28 iters)\n",
      "[Epoch 180] iter 28/28, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "JQP3182                   | JQP3182                   | 0.9707\n",
      "QCJ5838                   | QCJ5838                   | 0.9795\n",
      "QCH6121                   | QCH6121                   | 0.9970\n",
      "WYC8600                   | WYC8600                   | 0.9963\n",
      "QCB3923                   | QCB3923                   | 0.9904\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 180 done in 1.9s | train_loss=0.0003  valid_loss=1.1510  valid_acc=59.52%\n",
      "\n",
      "no improvement for 65/100 epochs\n",
      "\n",
      "→ Starting epoch 181  (printing every 28 iters)\n",
      "[Epoch 181] iter 28/28, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VMJ8336                   | VMJ8336                   | 0.9839\n",
      "QAB371C                   | QAB371C                   | 0.9997\n",
      "PC1811P                   | PC1811P                   | 0.9947\n",
      "QAL6939                   | QAL6939                   | 0.9866\n",
      "TBT3323                   | TBT3323                   | 0.9857\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 181 done in 1.9s | train_loss=0.0003  valid_loss=1.1524  valid_acc=59.13%\n",
      "\n",
      "no improvement for 66/100 epochs\n",
      "\n",
      "→ Starting epoch 182  (printing every 28 iters)\n",
      "[Epoch 182] iter 28/28, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "RT1911                    | RT1911                    | 0.9572\n",
      "CEN2010                   | CEN2010                   | 0.9907\n",
      "AMQ868                    | AMQ868                    | 0.9281\n",
      "SM2004                    | SM2004                    | 0.9892\n",
      "KDH2309                   | KDH2309                   | 0.9866\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 182 done in 1.9s | train_loss=0.0003  valid_loss=1.1523  valid_acc=59.13%\n",
      "\n",
      "no improvement for 67/100 epochs\n",
      "\n",
      "→ Starting epoch 183  (printing every 28 iters)\n",
      "[Epoch 183] iter 28/28, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "JSG1987                   | JSG1987                   | 0.9785\n",
      "QKT8216                   | QKT8216                   | 0.9952\n",
      "WWH9169                   | WWH9169                   | 0.9952\n",
      "WSJ8268                   | WSJ8268                   | 0.9934\n",
      "NBG6607                   | NBG6607                   | 0.9767\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 183 done in 1.9s | train_loss=0.0002  valid_loss=1.1534  valid_acc=59.13%\n",
      "\n",
      "no improvement for 68/100 epochs\n",
      "\n",
      "→ Starting epoch 184  (printing every 28 iters)\n",
      "[Epoch 184] iter 28/28, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QTH6633                   | QTH6633                   | 0.9974\n",
      "QM2377M                   | QM2377M                   | 0.9950\n",
      "BNB8655                   | BNB8655                   | 0.9638\n",
      "DBR9492                   | DBR9492                   | 0.9618\n",
      "JRN7985                   | JRN7985                   | 0.9805\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 184 done in 1.9s | train_loss=0.0002  valid_loss=1.1547  valid_acc=59.13%\n",
      "\n",
      "no improvement for 69/100 epochs\n",
      "\n",
      "→ Starting epoch 185  (printing every 28 iters)\n",
      "[Epoch 185] iter 28/28, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "TV333                     | TV333                     | 0.9652\n",
      "PHX8121                   | PHX8121                   | 0.9988\n",
      "WXQ6691                   | WXQ6691                   | 0.9834\n",
      "JSH4299                   | JSH4299                   | 0.9415\n",
      "QMB9780                   | QMB9780                   | 0.9387\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 185 done in 1.9s | train_loss=0.0002  valid_loss=1.1510  valid_acc=59.13%\n",
      "\n",
      "no improvement for 70/100 epochs\n",
      "\n",
      "→ Starting epoch 186  (printing every 28 iters)\n",
      "[Epoch 186] iter 28/28, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "NDM4685                   | NDM4685                   | 0.9989\n",
      "VJB1968                   | VJB1968                   | 0.9996\n",
      "WD1915A                   | WD1915A                   | 0.9995\n",
      "NAAM1997                  | NAAM1997                  | 0.9934\n",
      "W6916B                    | W6916B                    | 0.9483\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 186 done in 1.9s | train_loss=0.0002  valid_loss=1.1550  valid_acc=59.13%\n",
      "\n",
      "no improvement for 71/100 epochs\n",
      "\n",
      "→ Starting epoch 187  (printing every 28 iters)\n",
      "[Epoch 187] iter 28/28, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VCY1946                   | VCY1946                   | 0.9985\n",
      "PKA440                    | PKA440                    | 0.9607\n",
      "ANB9161                   | ANB9161                   | 0.9477\n",
      "NAH1048                   | NAH1048                   | 0.9742\n",
      "QAA3323X                  | QAA3323X                  | 0.9906\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 187 done in 1.9s | train_loss=0.0002  valid_loss=1.1527  valid_acc=59.13%\n",
      "\n",
      "no improvement for 72/100 epochs\n",
      "\n",
      "→ Starting epoch 188  (printing every 28 iters)\n",
      "[Epoch 188] iter 28/28, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAB8000C                  | QAB8000C                  | 0.9992\n",
      "QM3571G                   | QM3571G                   | 0.9660\n",
      "VKS4174                   | VKS4174                   | 0.9554\n",
      "JWY8676                   | JWY8676                   | 0.9936\n",
      "PPK9573                   | PPK9573                   | 0.9941\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 188 done in 1.9s | train_loss=0.0002  valid_loss=1.1577  valid_acc=59.13%\n",
      "\n",
      "no improvement for 73/100 epochs\n",
      "\n",
      "→ Starting epoch 189  (printing every 28 iters)\n",
      "[Epoch 189] iter 28/28, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "426                       | 426                       | 0.9638\n",
      "BCU7612                   | BCU7612                   | 0.9790\n",
      "MCY8232                   | MCY8232                   | 0.9848\n",
      "WUS4893                   | WUS4893                   | 0.9844\n",
      "1M4U3172                  | 1M4U3172                  | 0.9956\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 189 done in 2.0s | train_loss=0.0002  valid_loss=1.1581  valid_acc=59.13%\n",
      "\n",
      "no improvement for 74/100 epochs\n",
      "\n",
      "→ Starting epoch 190  (printing every 28 iters)\n",
      "[Epoch 190] iter 28/28, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QCJ9443                   | QCJ9443                   | 0.9940\n",
      "PCT6590                   | PCT6590                   | 0.9858\n",
      "KFW2299                   | KFW2299                   | 0.9993\n",
      "QCG9886                   | QCG9886                   | 0.9997\n",
      "WGS3960                   | WGS3960                   | 0.9990\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 190 done in 1.9s | train_loss=0.0002  valid_loss=1.1576  valid_acc=59.13%\n",
      "\n",
      "no improvement for 75/100 epochs\n",
      "\n",
      "→ Starting epoch 191  (printing every 28 iters)\n",
      "[Epoch 191] iter 28/28, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "TBE9333                   | TBE9333                   | 0.9806\n",
      "MW2567                    | MW2567                    | 0.9978\n",
      "MCN7929                   | MCN7929                   | 0.9813\n",
      "PJN5826                   | PJN5826                   | 0.9627\n",
      "BCU7612                   | BCU7612                   | 0.9872\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 191 done in 1.9s | train_loss=0.0002  valid_loss=1.1542  valid_acc=59.13%\n",
      "\n",
      "no improvement for 76/100 epochs\n",
      "\n",
      "→ Starting epoch 192  (printing every 28 iters)\n",
      "[Epoch 192] iter 28/28, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAE2205                   | QAE2205                   | 0.9944\n",
      "WPL3908                   | WPL3908                   | 0.9882\n",
      "QAB9766H                  | QAB9766H                  | 0.9849\n",
      "SJG8699                   | SJG8699                   | 0.9978\n",
      "QAB1040A                  | QAB1040A                  | 0.9982\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 192 done in 1.9s | train_loss=0.0002  valid_loss=1.1559  valid_acc=59.13%\n",
      "\n",
      "no improvement for 77/100 epochs\n",
      "\n",
      "→ Starting epoch 193  (printing every 28 iters)\n",
      "[Epoch 193] iter 28/28, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WB7028W                   | WB7028W                   | 0.9989\n",
      "AGC7322                   | AGC7322                   | 0.9690\n",
      "QAR9868                   | QAR9868                   | 0.9776\n",
      "NCU3622                   | NCU3622                   | 0.9922\n",
      "CEW485                    | CEW485                    | 0.9695\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 193 done in 1.9s | train_loss=0.0002  valid_loss=1.1574  valid_acc=59.13%\n",
      "\n",
      "no improvement for 78/100 epochs\n",
      "\n",
      "→ Starting epoch 194  (printing every 28 iters)\n",
      "[Epoch 194] iter 28/28, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "PDG4307                   | PDG4307                   | 0.9978\n",
      "AFB9825                   | AFB9825                   | 0.9800\n",
      "FFF1519                   | FFF1519                   | 0.9805\n",
      "QCH6121                   | QCH6121                   | 0.9962\n",
      "QAA7228U                  | QAA7228U                  | 0.9952\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 194 done in 1.9s | train_loss=0.0002  valid_loss=1.1565  valid_acc=58.73%\n",
      "\n",
      "no improvement for 79/100 epochs\n",
      "\n",
      "→ Starting epoch 195  (printing every 28 iters)\n",
      "[Epoch 195] iter 28/28, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "KDN1893                   | KDN1893                   | 0.9967\n",
      "QCA6734                   | QCA6734                   | 0.9957\n",
      "AGX7136                   | AGX7136                   | 0.9778\n",
      "BNW2744                   | BNW2744                   | 0.9733\n",
      "VFH2157                   | VFH2157                   | 0.9886\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 195 done in 1.9s | train_loss=0.0002  valid_loss=1.1607  valid_acc=59.13%\n",
      "\n",
      "no improvement for 80/100 epochs\n",
      "\n",
      "→ Starting epoch 196  (printing every 28 iters)\n",
      "[Epoch 196] iter 28/28, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAB751H                   | QAB751H                   | 0.9998\n",
      "PDG4307                   | PDG4307                   | 0.9982\n",
      "W5384D                    | W5384D                    | 0.9725\n",
      "VKG5010                   | VKG5010                   | 0.9879\n",
      "QAA2662Q                  | QAA2662Q                  | 0.9939\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 196 done in 1.9s | train_loss=0.0002  valid_loss=1.1593  valid_acc=59.52%\n",
      "\n",
      "no improvement for 81/100 epochs\n",
      "\n",
      "→ Starting epoch 197  (printing every 28 iters)\n",
      "[Epoch 197] iter 28/28, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QM2377M                   | QM2377M                   | 0.9933\n",
      "QAB8977J                  | QAB8977J                  | 0.9683\n",
      "WTP2102                   | WTP2102                   | 0.9812\n",
      "VFX447                    | VFX447                    | 0.9912\n",
      "W5870P                    | W5870P                    | 0.9463\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 197 done in 1.9s | train_loss=0.0002  valid_loss=1.1606  valid_acc=59.13%\n",
      "\n",
      "no improvement for 82/100 epochs\n",
      "\n",
      "→ Starting epoch 198  (printing every 28 iters)\n",
      "[Epoch 198] iter 28/28, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "PHA6245                   | PHA6245                   | 0.9954\n",
      "VNN6819                   | VNN6819                   | 0.9949\n",
      "JWC6011                   | JWC6011                   | 0.9771\n",
      "JDS809                    | JDS809                    | 0.9628\n",
      "KDH2309                   | KDH2309                   | 0.9944\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 198 done in 2.0s | train_loss=0.0002  valid_loss=1.1620  valid_acc=58.73%\n",
      "\n",
      "no improvement for 83/100 epochs\n",
      "\n",
      "→ Starting epoch 199  (printing every 28 iters)\n",
      "[Epoch 199] iter 28/28, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "NDB8499                   | NDB8499                   | 0.9967\n",
      "WNB2635                   | WNB2635                   | 0.9798\n",
      "WC8640J                   | WC8640J                   | 0.9981\n",
      "QAB437B                   | QAB437B                   | 0.9887\n",
      "WUT2636                   | WUT2636                   | 0.9900\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 199 done in 1.9s | train_loss=0.0002  valid_loss=1.1637  valid_acc=59.13%\n",
      "\n",
      "no improvement for 84/100 epochs\n",
      "\n",
      "→ Starting epoch 200  (printing every 28 iters)\n",
      "[Epoch 200] iter 28/28, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "JUV9528                   | JUV9528                   | 0.9411\n",
      "KFX7711                   | KFX7711                   | 0.9280\n",
      "FD10                      | FD10                      | 0.9767\n",
      "VHG1732                   | VHG1732                   | 0.9835\n",
      "QKA7085                   | QKA7085                   | 0.9984\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 200 done in 1.9s | train_loss=0.0002  valid_loss=1.1629  valid_acc=59.13%\n",
      "\n",
      "no improvement for 85/100 epochs\n",
      "\n",
      "→ Starting epoch 201  (printing every 28 iters)\n",
      "[Epoch 201] iter 28/28, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VNP3597                   | VNP3597                   | 0.9987\n",
      "BJF5469                   | BJF5469                   | 0.9846\n",
      "JRN7985                   | JRN7985                   | 0.9848\n",
      "QAA7647G                  | QAA7647G                  | 0.9968\n",
      "PPD2622                   | PPD2622                   | 0.9979\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 201 done in 1.9s | train_loss=0.0002  valid_loss=1.1635  valid_acc=58.73%\n",
      "\n",
      "no improvement for 86/100 epochs\n",
      "\n",
      "→ Starting epoch 202  (printing every 28 iters)\n",
      "[Epoch 202] iter 28/28, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAA9381W                  | QAA9381W                  | 0.9981\n",
      "CES4236                   | CES4236                   | 0.9572\n",
      "8559                      | 8559                      | 0.9562\n",
      "WXM1116                   | WXM1116                   | 0.9914\n",
      "JFR4363                   | JFR4363                   | 0.9933\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 202 done in 2.0s | train_loss=0.0002  valid_loss=1.1669  valid_acc=59.13%\n",
      "\n",
      "no improvement for 87/100 epochs\n",
      "\n",
      "→ Starting epoch 203  (printing every 28 iters)\n",
      "[Epoch 203] iter 28/28, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "SYU3073                   | SYU3073                   | 0.9635\n",
      "QCK8054                   | QCK8054                   | 0.9978\n",
      "NEA9731                   | NEA9731                   | 0.9877\n",
      "WQD6028                   | WQD6028                   | 0.9959\n",
      "QTV6692                   | QTV6692                   | 0.9884\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 203 done in 1.9s | train_loss=0.0002  valid_loss=1.1658  valid_acc=59.13%\n",
      "\n",
      "no improvement for 88/100 epochs\n",
      "\n",
      "→ Starting epoch 204  (printing every 28 iters)\n",
      "[Epoch 204] iter 28/28, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "MCV1838                   | MCV1838                   | 0.9848\n",
      "NAAM1997                  | NAAM1997                  | 0.9921\n",
      "JRG2793                   | JRG2793                   | 0.9929\n",
      "AMV2374                   | AMV2374                   | 0.9826\n",
      "AM7017                    | AM7017                    | 0.9923\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 204 done in 2.0s | train_loss=0.0002  valid_loss=1.1673  valid_acc=59.13%\n",
      "\n",
      "no improvement for 89/100 epochs\n",
      "\n",
      "→ Starting epoch 205  (printing every 28 iters)\n",
      "[Epoch 205] iter 28/28, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "BLR9830                   | BLR9830                   | 0.9651\n",
      "QCJ6565                   | QCJ6565                   | 0.9953\n",
      "MDL1672                   | MDL1672                   | 0.9750\n",
      "WLP6892                   | WLP6892                   | 0.9798\n",
      "MCT8738                   | MCT8738                   | 0.9955\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 205 done in 1.9s | train_loss=0.0002  valid_loss=1.1649  valid_acc=59.13%\n",
      "\n",
      "no improvement for 90/100 epochs\n",
      "\n",
      "→ Starting epoch 206  (printing every 28 iters)\n",
      "[Epoch 206] iter 28/28, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "MAG7025                   | MAG7025                   | 0.9743\n",
      "BGW2901                   | BGW2901                   | 0.9988\n",
      "JWY8676                   | JWY8676                   | 0.9952\n",
      "VHR7459                   | VHR7459                   | 0.9783\n",
      "WXQ9376                   | WXQ9376                   | 0.9997\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 206 done in 1.9s | train_loss=0.0002  valid_loss=1.1652  valid_acc=59.13%\n",
      "\n",
      "no improvement for 91/100 epochs\n",
      "\n",
      "→ Starting epoch 207  (printing every 28 iters)\n",
      "[Epoch 207] iter 28/28, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QCR2878                   | QCR2878                   | 0.9826\n",
      "T/M3041                   | T/M3041                   | 0.9903\n",
      "MAG7025                   | MAG7025                   | 0.9616\n",
      "QS1016K                   | QS1016K                   | 0.9878\n",
      "JPA501                    | JPA501                    | 0.9756\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 207 done in 1.9s | train_loss=0.0002  valid_loss=1.1676  valid_acc=58.73%\n",
      "\n",
      "no improvement for 92/100 epochs\n",
      "\n",
      "→ Starting epoch 208  (printing every 28 iters)\n",
      "[Epoch 208] iter 28/28, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VFX8581                   | VFX8581                   | 0.9996\n",
      "MDH7007                   | MDH7007                   | 0.9888\n",
      "JVD4749                   | JVD4749                   | 0.9725\n",
      "TAM408                    | TAM408                    | 0.9685\n",
      "VMH942                    | VMH942                    | 0.9745\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 208 done in 2.0s | train_loss=0.0002  valid_loss=1.1669  valid_acc=59.13%\n",
      "\n",
      "no improvement for 93/100 epochs\n",
      "\n",
      "→ Starting epoch 209  (printing every 28 iters)\n",
      "[Epoch 209] iter 28/28, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "W6916B                    | W6916B                    | 0.9432\n",
      "JVY1699                   | JVY1699                   | 0.9667\n",
      "VBV198                    | VBV198                    | 0.9811\n",
      "AMY5489                   | AMY5489                   | 0.9981\n",
      "SMC3363                   | SMC3363                   | 0.9924\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 209 done in 1.9s | train_loss=0.0002  valid_loss=1.1707  valid_acc=58.73%\n",
      "\n",
      "no improvement for 94/100 epochs\n",
      "\n",
      "→ Starting epoch 210  (printing every 28 iters)\n",
      "[Epoch 210] iter 28/28, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "KDS818                    | KDS818                    | 0.9957\n",
      "JUA9705                   | JUA9705                   | 0.9752\n",
      "QAB437B                   | QAB437B                   | 0.9800\n",
      "SK5285B                   | SK5285B                   | 0.9916\n",
      "VCY1946                   | VCY1946                   | 0.9932\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 210 done in 1.9s | train_loss=0.0002  valid_loss=1.1672  valid_acc=59.13%\n",
      "\n",
      "no improvement for 95/100 epochs\n",
      "\n",
      "→ Starting epoch 211  (printing every 28 iters)\n",
      "[Epoch 211] iter 28/28, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WB6629Q                   | WB6629Q                   | 0.9812\n",
      "TTB1838                   | TTB1838                   | 0.9749\n",
      "BJM9030                   | BJM9030                   | 0.9879\n",
      "RK3002                    | RK3002                    | 0.9904\n",
      "WUS4893                   | WUS4893                   | 0.9847\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 211 done in 1.9s | train_loss=0.0002  valid_loss=1.1682  valid_acc=59.13%\n",
      "\n",
      "no improvement for 96/100 epochs\n",
      "\n",
      "→ Starting epoch 212  (printing every 28 iters)\n",
      "[Epoch 212] iter 28/28, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QKY2146                   | QKY2146                   | 0.9797\n",
      "AHA7775                   | AHA7775                   | 0.9780\n",
      "JNB9682                   | JNB9682                   | 0.9958\n",
      "BHP7067                   | BHP7067                   | 0.9953\n",
      "JUJ7630                   | JUJ7630                   | 0.9966\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 212 done in 1.9s | train_loss=0.0002  valid_loss=1.1685  valid_acc=59.13%\n",
      "\n",
      "no improvement for 97/100 epochs\n",
      "\n",
      "→ Starting epoch 213  (printing every 28 iters)\n",
      "[Epoch 213] iter 28/28, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAB1040A                  | QAB1040A                  | 0.9982\n",
      "QS9953S                   | QS9953S                   | 0.9806\n",
      "AKF4463                   | AKF4463                   | 0.9836\n",
      "VDM8068                   | VDM8068                   | 0.9852\n",
      "VN815                     | VN815                     | 0.9762\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 213 done in 1.9s | train_loss=0.0002  valid_loss=1.1660  valid_acc=59.13%\n",
      "\n",
      "no improvement for 98/100 epochs\n",
      "\n",
      "→ Starting epoch 214  (printing every 28 iters)\n",
      "[Epoch 214] iter 28/28, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "JFR4363                   | JFR4363                   | 0.9939\n",
      "W763L                     | W763L                     | 0.9463\n",
      "PMQ2551                   | PMQ2551                   | 0.9800\n",
      "VDD4069                   | VDD4069                   | 0.9991\n",
      "QTD33                     | QTD33                     | 0.9946\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 214 done in 1.9s | train_loss=0.0002  valid_loss=1.1674  valid_acc=59.13%\n",
      "\n",
      "no improvement for 99/100 epochs\n",
      "\n",
      "→ Starting epoch 215  (printing every 28 iters)\n",
      "[Epoch 215] iter 28/28, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "NDL7330                   | NDL7330                   | 0.9841\n",
      "QRT99                     | QRT99                     | 0.9479\n",
      "QBB7772                   | QBB7772                   | 0.9989\n",
      "MCT8738                   | MCT8738                   | 0.9962\n",
      "JWY375                    | JWY375                    | 0.9975\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 215 done in 1.9s | train_loss=0.0002  valid_loss=1.1697  valid_acc=59.13%\n",
      "\n",
      "no improvement for 100/100 epochs\n",
      "\n",
      "🔚 Early stopping: val_acc hasn't improved for 100 epochs.\n"
     ]
    }
   ],
   "source": [
    "# ─── Cell 6: training w/ history, best‐model saving + EARLY STOPPING ───\n",
    "\n",
    "# hyper‑params\n",
    "best_val_acc   = 0.0\n",
    "history        = {'epoch': [], 'train_loss': [], 'val_loss': [], 'val_acc': []}\n",
    "\n",
    "patience_cnt   = 0           # how many epochs since last improvement\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    print(f\"→ Starting epoch {epoch}  (printing every {PRINT_EVERY} iters)\")\n",
    "    model.train()\n",
    "    epoch_loss = Averager()\n",
    "    start = time.time()\n",
    "\n",
    "    # ─── training ──────────────────────────────────────────────────────────\n",
    "    for i, (images, texts) in enumerate(train_loader, 1):\n",
    "        images = images.to(device)\n",
    "\n",
    "        text, length   = converter.encode(texts, batch_max_length=MAX_LABEL_LENGTH)\n",
    "        text_input     = text[:, :-1].to(device)\n",
    "        text_target    = text[:,  1:].to(device)\n",
    "\n",
    "        preds = model(\n",
    "            images,\n",
    "            text=text_input,\n",
    "            is_train=True,\n",
    "            batch_max_length=MAX_LABEL_LENGTH\n",
    "        )  # [B, S, C]\n",
    "        B, S, C = preds.size()\n",
    "        loss = criterion(\n",
    "            preds.view(B * S, C),\n",
    "            text_target.contiguous().view(B * S)\n",
    "        )\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "        optimizer.step()\n",
    "        epoch_loss.add(loss)\n",
    "\n",
    "        # mini‐table prints\n",
    "        if i % PRINT_EVERY == 0:\n",
    "            print(f\"[Epoch {epoch}] iter {i}/{len(train_loader)}, avg loss: {epoch_loss.val():.4f}\", flush=True)\n",
    "            with torch.no_grad():\n",
    "                probs     = preds.softmax(2)\n",
    "                max_vals, max_inds = probs.max(2)\n",
    "                pred_strs = converter.decode(max_inds, length)\n",
    "                pred_strs = [s.split('[s]')[0] for s in pred_strs]\n",
    "\n",
    "            print(\"-\" * 80)\n",
    "            print(f\"{'Ground Truth':25s} | {'Prediction':25s} | AvgConfidence\")\n",
    "            print(\"-\" * 80)\n",
    "            for gt, pr, conf_seq in zip(texts[:5], pred_strs[:5], max_vals[:5]):\n",
    "                conf = conf_seq.mean().item()\n",
    "                print(f\"{gt:25s} | {pr:25s} | {conf_seq.mean().item():.4f}\")\n",
    "            print(\"-\" * 80)\n",
    "\n",
    "    # ─── validation ────────────────────────────────────────────────────────\n",
    "    val_loss, val_acc = validate(model, val_loader)\n",
    "    elapsed   = time.time() - start\n",
    "    train_l   = epoch_loss.val()\n",
    "    print(f\"==> Epoch {epoch} done in {elapsed:.1f}s | \"\n",
    "          f\"train_loss={train_l:.4f}  valid_loss={val_loss:.4f}  valid_acc={val_acc:.2f}%\\n\")\n",
    "\n",
    "    # ─── record history ───────────────────────────────────────────────────\n",
    "    history['epoch'].append(epoch)\n",
    "    history['train_loss'].append(train_l)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "\n",
    "    # ─── best‑model tracking & early‑stopping logic ───────────────────────\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"best_attention_crnn_no_!.pth\")\n",
    "        print(f\"💾 New best model saved (epoch {epoch}, val_acc={val_acc:.2f}%)\\n\")\n",
    "        patience_cnt = 0                          # reset counter\n",
    "    else:\n",
    "        patience_cnt += 1\n",
    "        print(f\"no improvement for {patience_cnt}/{PATIENCE} epochs\\n\")\n",
    "        if patience_cnt >= PATIENCE:\n",
    "            print(f\"🔚 Early stopping: val_acc hasn't improved for {PATIENCE} epochs.\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b49a536f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3.229325</td>\n",
       "      <td>2.996068</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.791204</td>\n",
       "      <td>2.903309</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2.489336</td>\n",
       "      <td>2.327604</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2.247780</td>\n",
       "      <td>2.387741</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2.086516</td>\n",
       "      <td>1.994244</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>211</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>1.168220</td>\n",
       "      <td>59.126984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>212</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>1.168521</td>\n",
       "      <td>59.126984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>213</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>1.165975</td>\n",
       "      <td>59.126984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>214</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.167375</td>\n",
       "      <td>59.126984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>215</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>1.169746</td>\n",
       "      <td>59.126984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>215 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     epoch  train_loss  val_loss    val_acc\n",
       "0        1    3.229325  2.996068   0.000000\n",
       "1        2    2.791204  2.903309   0.000000\n",
       "2        3    2.489336  2.327604   0.000000\n",
       "3        4    2.247780  2.387741   0.000000\n",
       "4        5    2.086516  1.994244   0.000000\n",
       "..     ...         ...       ...        ...\n",
       "210    211    0.000208  1.168220  59.126984\n",
       "211    212    0.000206  1.168521  59.126984\n",
       "212    213    0.000206  1.165975  59.126984\n",
       "213    214    0.000200  1.167375  59.126984\n",
       "214    215    0.000203  1.169746  59.126984\n",
       "\n",
       "[215 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clean_history = {\n",
    "  'epoch':      history['epoch'],\n",
    "  'train_loss': [x.cpu().item() if hasattr(x, 'cpu') else x for x in history['train_loss']],\n",
    "  'val_loss':   [x.cpu().item() if hasattr(x, 'cpu') else x for x in history['val_loss']],\n",
    "  'val_acc':    [x.cpu().item() if hasattr(x, 'cpu') else x for x in history['val_acc']],\n",
    "}\n",
    "df = pd.DataFrame(clean_history)\n",
    "display(df)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(df['epoch'], df['train_loss'], label='Train Loss')\n",
    "plt.plot(df['epoch'], df['val_loss'],   label='Val Loss')\n",
    "plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.legend()\n",
    "plt.title('Loss over Epochs')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(df['epoch'], df['val_acc'],   label='Val Accuracy')\n",
    "plt.xlabel('Epoch'); plt.ylabel('Accuracy (%)'); plt.legend()\n",
    "plt.title('Val Accuracy over Epochs')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe117ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ─── Cell 9: ONNX export via isolated inference head ─────────────────────────\n",
    "# import torch\n",
    "\n",
    "# class CRNNInference(torch.nn.Module):\n",
    "#     def __init__(self, crnn, max_len):\n",
    "#         super().__init__()\n",
    "#         # use exactly the names printed out by your inspection\n",
    "#         self.Transformation     = crnn.Transformation\n",
    "#         self.FeatureExtraction = crnn.FeatureExtraction\n",
    "#         self.AdaptiveAvgPool    = crnn.AdaptiveAvgPool\n",
    "#         self.SequenceModeling   = crnn.SequenceModeling\n",
    "#         self.Prediction         = crnn.Prediction\n",
    "#         self.max_len           = max_len\n",
    "#         # adjust this if your converter stores start-token under a different key\n",
    "#         self.start_id          = crnn.converter.dict['[GO]']\n",
    "\n",
    "#     def forward(self, image):\n",
    "#         # 1) Spatial‐transformer + feature CNN\n",
    "#         x = self.Transformation(image)                     # [B, C, H, W]\n",
    "#         x = self.FeatureExtraction(x)                      # [B, C, H, W]\n",
    "\n",
    "#         # 2) Pool down height to 1\n",
    "#         x = self.AdaptiveAvgPool(x)                        # [B, C, 1, W]\n",
    "#         x = x.squeeze(2)                                   # [B, C, W]\n",
    "#         x = x.permute(0, 2, 1)                             # [B, W, C]\n",
    "\n",
    "#         # 3) 2‐layer BiLSTM\n",
    "#         contextual = self.SequenceModeling(x)              # [B, W, hidden]\n",
    "\n",
    "#         # 4) Dummy “[GO]” token vector\n",
    "#         B = contextual.size(0)\n",
    "#         dummy_text = torch.full(\n",
    "#             (B,),\n",
    "#             self.start_id,\n",
    "#             dtype=torch.long,\n",
    "#             device=image.device\n",
    "#         )  # shape [B]\n",
    "\n",
    "#         # 5) Attention decoder (inference path)\n",
    "#         return self.Prediction(\n",
    "#             batch_H           = contextual,\n",
    "#             text              = dummy_text,\n",
    "#             is_train          = False,\n",
    "#             batch_max_length  = self.max_len\n",
    "#         )\n",
    "\n",
    "# # Wrap and export\n",
    "# inference_model = CRNNInference(model, BATCH_MAX_LENGTH).eval()\n",
    "# dummy_img       = torch.randn(1, INPUT_CHANNEL, IMG_HEIGHT, IMG_WIDTH, device=device)\n",
    "\n",
    "# torch.onnx.export(\n",
    "#     inference_model,\n",
    "#     dummy_img,\n",
    "#     \"best_attention_crnn.onnx\",\n",
    "#     input_names   = ['image'],\n",
    "#     output_names  = ['logits'],\n",
    "#     dynamic_axes  = {\n",
    "#         'image':  {0: 'batch'},\n",
    "#         'logits': {0: 'batch', 1: 'time'}\n",
    "#     },\n",
    "#     opset_version = 13,\n",
    "# )\n",
    "\n",
    "# print(\"✅ Exported best_attention_crnn.onnx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9587a5dc",
   "metadata": {},
   "source": [
    "# DUMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99a300a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ─── cell 6: attention‐based training loop ──────────────────────────────────────\n",
    "# for epoch in range(1, NUM_EPOCHS+1):\n",
    "#     print(f\"→ Starting epoch {epoch}  (printing every {PRINT_EVERY} iters)\")\n",
    "#     model.train()\n",
    "#     epoch_loss = Averager()\n",
    "#     start      = time.time()\n",
    "\n",
    "#     for i, (images, texts) in enumerate(train_loader, 1):\n",
    "#         images = images.to(device)\n",
    "\n",
    "#         # encode with [GO] & [s]; also get lengths\n",
    "#         text, length = converter.encode(texts, batch_max_length=BATCH_MAX_LENGTH)\n",
    "#         text_input  = text[:, :-1].to(device)   # drop final [s]\n",
    "#         text_target = text[:,  1:].to(device)   # everything after [GO]\n",
    "\n",
    "#         # forward + loss\n",
    "#         preds = model(images,\n",
    "#                       text=text_input,\n",
    "#                       is_train=True,\n",
    "#                       batch_max_length=BATCH_MAX_LENGTH)  # [B, S, C]\n",
    "#         B, S, C = preds.size()\n",
    "#         loss = criterion(\n",
    "#             preds.view(B * S, C),\n",
    "#             text_target.contiguous().view(B * S)\n",
    "#         )\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "#         optimizer.step()\n",
    "#         epoch_loss.add(loss)\n",
    "\n",
    "#         if i % PRINT_EVERY == 0 or i == 1:\n",
    "#             print(f\"[Epoch {epoch}] iter {i}/{len(train_loader)}, avg loss: {epoch_loss.val():.4f}\", flush=True)\n",
    "\n",
    "#             # quick greedy‐decode\n",
    "#             with torch.no_grad():\n",
    "#                 probs        = preds.softmax(2)           # [B, S, C]\n",
    "#                 max_vals, max_inds = probs.max(2)         # [B, S]\n",
    "#                 pred_strs    = converter.decode(max_inds, length)\n",
    "#                 pred_strs    = [s.split('[s]')[0] for s in pred_strs]\n",
    "\n",
    "#             # print a mini‐table\n",
    "#             print(\"-\" * 80)\n",
    "#             print(f\"{'Ground Truth':25s} | {'Prediction':25s} | AvgConfidence\")\n",
    "#             print(\"-\" * 80)\n",
    "#             for gt, pr, conf_seq in zip(texts[:5], pred_strs[:5], max_vals[:5]):\n",
    "#                 conf = conf_seq.mean().item()\n",
    "#                 print(f\"{gt:25s} | {pr:25s} | {conf:0.4f}\")\n",
    "#             print(\"-\" * 80)\n",
    "\n",
    "#     # end‐of‐epoch validation\n",
    "#     val_loss, val_acc = validate(model, val_loader)\n",
    "#     elapsed = time.time() - start\n",
    "#     print(f\"==> Epoch {epoch} done in {elapsed:.1f}s | \"\n",
    "#           f\"train_loss={epoch_loss.val():.4f}\"\n",
    "#           f\"  valid_loss={val_loss:.4f}  valid_acc={val_acc:.2f}%\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
