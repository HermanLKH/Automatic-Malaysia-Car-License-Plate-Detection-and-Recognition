{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "493b766c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cuda\n"
     ]
    }
   ],
   "source": [
    "# cell 1\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from config import (IMG_HEIGHT, IMG_WIDTH, NUM_FIDUCIAL,\n",
    "                    INPUT_CHANNEL, OUTPUT_CHANNEL, HIDDEN_SIZE,\n",
    "                    CHARACTERS, MAX_LABEL_LENGTH)\n",
    "from dataset import LmdbDataset, AlignCollate\n",
    "# from utils import CTCLabelConverter, Averager\n",
    "from utils import AttnLabelConverter, Averager\n",
    "from model import CRNN\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Running on\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2c361de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All seeds set to 300188, cudnn.deterministic=True\n"
     ]
    }
   ],
   "source": [
    "# ─── cell 0: reproducibility ────────────────────────────────────────────────\n",
    "SEED = 300188\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# Make cuDNN deterministic (slower but reproducible)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "print(f\"All seeds set to {SEED}, cudnn.deterministic={torch.backends.cudnn.deterministic}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ba8277",
   "metadata": {},
   "source": [
    "------ Added Augmentation ------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ab90a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_pipeline = T.Compose([\n",
    "    # rotate up to ±15°\n",
    "    T.RandomRotation(15, expand=False, fill=255),\n",
    "\n",
    "    # flip left ↔ right with 50% probability\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "\n",
    "    # shear by up to ±10°\n",
    "    T.RandomAffine(degrees=0, shear=10, fill=255),\n",
    "\n",
    "    # slight brightness jitter\n",
    "    T.ColorJitter(brightness=0.2),\n",
    "\n",
    "    # add gaussian noise in [0,1], then back to uint8\n",
    "    T.Lambda(lambda img: (\n",
    "        Image.fromarray(\n",
    "            (\n",
    "                np.clip(\n",
    "                    np.array(img).astype(np.float32) / 255.0\n",
    "                    + np.random.normal(0, 0.02, img.size[::-1]),\n",
    "                    0.0, 1.0\n",
    "                ) * 255.0\n",
    "            ).astype(np.uint8)\n",
    "        )\n",
    "    )),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4817455",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AugmentedLmdbDataset(Dataset):\n",
    "    def __init__(self, base_dataset, augment, num_aug):\n",
    "        self.base     = base_dataset\n",
    "        self.augment  = augment\n",
    "        self.num_aug  = num_aug\n",
    "        self.orig_len = len(base_dataset)\n",
    "\n",
    "    def __len__(self):\n",
    "        # each original plus `num_aug` variants\n",
    "        return self.orig_len * (1 + self.num_aug)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx < self.orig_len:\n",
    "            # raw sample\n",
    "            return self.base[idx]\n",
    "        # augmented sample\n",
    "        base_idx = idx % self.orig_len\n",
    "        img, label = self.base[base_idx]\n",
    "        return self.augment(img), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46c92ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1372 valid samples from v4_lmdb_data_!/train\n",
      "Loaded 343 valid samples from v4_lmdb_data_!/val\n",
      "Original train images: 1372\n",
      "After augmentation:    5488  (×4 total samples)\n",
      "5488 train / 343 val samples\n"
     ]
    }
   ],
   "source": [
    "# cell 2\n",
    "# paths to your LMDBs\n",
    "train_lmdb = \"v4_lmdb_data_!/train\"\n",
    "val_lmdb   = \"v4_lmdb_data_!/val\"\n",
    "\n",
    "# instantiate datasets\n",
    "train_dataset = LmdbDataset(train_lmdb)\n",
    "val_dataset   = LmdbDataset(val_lmdb)\n",
    "\n",
    "# augmentations\n",
    "NUM_AUG = 3   # → total factor = 1 (orig) + 2 aug = ×3\n",
    "aug_train_dataset = AugmentedLmdbDataset(train_dataset, augment_pipeline, num_aug=NUM_AUG)\n",
    "print(f\"Original train images: {len(train_dataset)}\")\n",
    "print(f\"After augmentation:    {len(aug_train_dataset)}  (×{1+NUM_AUG} total samples)\")\n",
    "\n",
    "# collate_fn resizes + normalizes\n",
    "collate_fn = AlignCollate(\n",
    "    imgH=IMG_HEIGHT, imgW=IMG_WIDTH, keep_ratio_with_pad=False\n",
    ")\n",
    "\n",
    "# loaders\n",
    "BATCH_SIZE = 32\n",
    "train_loader = DataLoader(\n",
    "    aug_train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "    num_workers=0, collate_fn=collate_fn, pin_memory=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "    num_workers=0, collate_fn=collate_fn, pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"{len(aug_train_dataset)} train / {len(val_dataset)} val samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e3d612b",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter   = AttnLabelConverter(CHARACTERS)\n",
    "num_classes = len(converter.character)   # includes [GO] and [s]\n",
    "\n",
    "model = CRNN(\n",
    "    IMG_HEIGHT,      # imgH\n",
    "    IMG_WIDTH,       # imgW\n",
    "    INPUT_CHANNEL,   # input_channel\n",
    "    OUTPUT_CHANNEL,  # output_channel\n",
    "    HIDDEN_SIZE,     # hidden_size\n",
    "    num_classes,     # num_classes (with GO/s)\n",
    "    True,            # use_attention\n",
    "    NUM_FIDUCIAL     # num_fiducial\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0).to(device)\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=1.0)\n",
    "\n",
    "model.Transformation = nn.Identity() # <-- no transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a80e2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── cell 4: validate (Attention) ─────────────────────────────────────────────\n",
    "NUM_EPOCHS       = 500\n",
    "PRINT_EVERY      = len(aug_train_dataset) // BATCH_SIZE + 1\n",
    "PATIENCE       = 100          # stop if no val_acc ↑ for 50 epochs\n",
    "\n",
    "def validate(model, loader):\n",
    "    model.eval()\n",
    "    avg_loss = Averager()\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, texts in loader:\n",
    "            images = images.to(device)\n",
    "\n",
    "            # encode full text → shape [B, L+1], plus lengths\n",
    "            text, length = converter.encode(texts, batch_max_length=MAX_LABEL_LENGTH)\n",
    "            text_input  = text[:, :-1].to(device)  # drop final [s]\n",
    "            text_target = text[:,  1:].to(device)  # everything after [GO]\n",
    "\n",
    "            # forward\n",
    "            preds = model(images, text_input, is_train=False,\n",
    "                          batch_max_length=MAX_LABEL_LENGTH)\n",
    "            B, S, C = preds.size()\n",
    "\n",
    "            # cross‐entropy over (B×S) predictions\n",
    "            loss = criterion(\n",
    "                preds.view(B * S, C),\n",
    "                text_target.contiguous().view(B * S)\n",
    "            )\n",
    "            avg_loss.add(loss)\n",
    "\n",
    "            # greedy decode\n",
    "            _, pred_inds = preds.max(2)                   # [B, S]\n",
    "            pred_strs = converter.decode(pred_inds, length)  # pass length\n",
    "\n",
    "            # strip off anything after the \"[s]\" token\n",
    "            pred_strs = [s.split('[s]')[0] for s in pred_strs]\n",
    "\n",
    "            total += len(texts)\n",
    "            correct += sum(p == g for p, g in zip(pred_strs, texts))\n",
    "\n",
    "    acc = correct / total * 100\n",
    "    return avg_loss.val(), acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36d430a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded pretrained Attn weights\n"
     ]
    }
   ],
   "source": [
    "# ─── cell 5: load pretrained CTC weights (skip old Prediction head) ────────────\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "orig      = torch.load(\"pretrained_model/TPS-ResNet-BiLSTM-Attn.pth\", map_location=device)\n",
    "# strip off the \"module.\" prefix if you wrapped in DataParallel\n",
    "stripped  = OrderedDict((k[len(\"module.\"):], v)\n",
    "                        for k, v in orig.items()\n",
    "                        if k.startswith(\"module.\"))\n",
    "\n",
    "own = model.state_dict()\n",
    "for k, v in stripped.items():\n",
    "    # skip the old attention head entirely\n",
    "    if k.startswith(\"Prediction.\") or k.startswith(\"Transformation.\"):\n",
    "        continue\n",
    "    # only overwrite if shapes match\n",
    "    if k in own and v.size() == own[k].size():\n",
    "        own[k] = v\n",
    "\n",
    "model.load_state_dict(own)\n",
    "print(\"✅ Loaded pretrained Attn weights\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b9e6646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Starting epoch 1  (printing every 172 iters)\n",
      "[Epoch 1] iter 172/172, avg loss: 2.6143\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "BLY5998                   | VVN99999                  | 0.3573\n",
      "JSG1987                   | QAB9918                   | 0.3382\n",
      "QCR271                    | QQC2200                   | 0.3291\n",
      "JRW5859                   | QVN5555                   | 0.2890\n",
      "BJF5469                   | QAA4444                   | 0.3209\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 1 done in 11.7s | train_loss=2.6143  valid_loss=2.4099  valid_acc=0.00%\n",
      "\n",
      "no improvement for 1/100 epochs\n",
      "\n",
      "→ Starting epoch 2  (printing every 172 iters)\n",
      "[Epoch 2] iter 172/172, avg loss: 1.6658\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WTP2102                   | WTP2102                   | 0.7211\n",
      "MDS7658                   | MC27658                   | 0.6329\n",
      "JRG!3303                  | WCE!3333                  | 0.4934\n",
      "QAA377P                   | QAA3377                   | 0.7249\n",
      "JCY7217                   | JCY7217                   | 0.6841\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 2 done in 11.2s | train_loss=1.6658  valid_loss=1.1578  valid_acc=6.12%\n",
      "\n",
      "💾 New best model saved (epoch 2, val_acc=6.12%)\n",
      "\n",
      "→ Starting epoch 3  (printing every 172 iters)\n",
      "[Epoch 3] iter 172/172, avg loss: 0.9066\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VNH9099                   | VNH9099                   | 0.8607\n",
      "WTL9654                   | WTL9644                   | 0.8403\n",
      "BAK!5940                  | VKP5597                   | 0.6325\n",
      "VK1800                    | VK8100                    | 0.6002\n",
      "JXL9880                   | JXL9880                   | 0.8421\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 3 done in 11.3s | train_loss=0.9066  valid_loss=0.7540  valid_acc=46.06%\n",
      "\n",
      "💾 New best model saved (epoch 3, val_acc=46.06%)\n",
      "\n",
      "→ Starting epoch 4  (printing every 172 iters)\n",
      "[Epoch 4] iter 172/172, avg loss: 0.6238\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QSU9715                   | QSU9715                   | 0.9034\n",
      "MDJ5126                   | MDJ5126                   | 0.9468\n",
      "ZC!3873                   | BCC!3813                  | 0.6458\n",
      "VJE3434                   | VJE6434                   | 0.8542\n",
      "QBF7591                   | QBF7591                   | 0.9682\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 4 done in 11.3s | train_loss=0.6238  valid_loss=0.5466  valid_acc=59.48%\n",
      "\n",
      "💾 New best model saved (epoch 4, val_acc=59.48%)\n",
      "\n",
      "→ Starting epoch 5  (printing every 172 iters)\n",
      "[Epoch 5] iter 172/172, avg loss: 0.4141\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "TCA7789                   | TCA7789                   | 0.9063\n",
      "PNB6727                   | PNB6727                   | 0.9576\n",
      "MBX7368                   | WBX7368                   | 0.9518\n",
      "RAJ519                    | RAJ519                    | 0.9240\n",
      "WYJ7760                   | WYJ7760                   | 0.9453\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 5 done in 11.2s | train_loss=0.4141  valid_loss=0.5108  valid_acc=49.85%\n",
      "\n",
      "no improvement for 1/100 epochs\n",
      "\n",
      "→ Starting epoch 6  (printing every 172 iters)\n",
      "[Epoch 6] iter 172/172, avg loss: 0.3338\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QCQ9249                   | QCR9249                   | 0.9079\n",
      "JWW9278                   | JWW9278                   | 0.9717\n",
      "VHA6835                   | VHA6835                   | 0.9069\n",
      "QS2878F                   | QS2878E                   | 0.9358\n",
      "QBF!2288                  | QBB!2288                  | 0.8499\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 6 done in 11.3s | train_loss=0.3338  valid_loss=0.6768  valid_acc=39.07%\n",
      "\n",
      "no improvement for 2/100 epochs\n",
      "\n",
      "→ Starting epoch 7  (printing every 172 iters)\n",
      "[Epoch 7] iter 172/172, avg loss: 0.2396\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "MDV!8552                  | MDV!8552                  | 0.9344\n",
      "SK3694F                   | SK3694F                   | 0.9670\n",
      "WMW7786                   | WMW7786                   | 0.9583\n",
      "TAE2798                   | TAE2798                   | 0.9419\n",
      "W!2547C                   | W!2547                    | 0.8423\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 7 done in 11.5s | train_loss=0.2396  valid_loss=0.4562  valid_acc=69.10%\n",
      "\n",
      "💾 New best model saved (epoch 7, val_acc=69.10%)\n",
      "\n",
      "→ Starting epoch 8  (printing every 172 iters)\n",
      "[Epoch 8] iter 172/172, avg loss: 0.2511\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAB3330B                  | QAB3330B                  | 0.9837\n",
      "ALC!3644                  | ALC!3644                  | 0.9627\n",
      "ALW!4851                  | AJW!4851                  | 0.8220\n",
      "T/D1673                   | TTD1673                   | 0.9110\n",
      "WWN1840                   | WWN1840                   | 0.9568\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 8 done in 11.5s | train_loss=0.2511  valid_loss=0.3993  valid_acc=65.89%\n",
      "\n",
      "no improvement for 1/100 epochs\n",
      "\n",
      "→ Starting epoch 9  (printing every 172 iters)\n",
      "[Epoch 9] iter 172/172, avg loss: 0.1867\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "BLJ6613                   | BLJ8613                   | 0.9234\n",
      "JNA3294                   | JNA3294                   | 0.9662\n",
      "QKC1927                   | QKC1927                   | 0.9852\n",
      "JXP!4469                  | LCP!4469                  | 0.8550\n",
      "PKV4279                   | PKV4279                   | 0.9706\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 9 done in 11.3s | train_loss=0.1867  valid_loss=0.4477  valid_acc=60.35%\n",
      "\n",
      "no improvement for 2/100 epochs\n",
      "\n",
      "→ Starting epoch 10  (printing every 172 iters)\n",
      "[Epoch 10] iter 172/172, avg loss: 0.1564\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "CEG8119                   | CEG8119                   | 0.9905\n",
      "QAA7388S                  | QAA7388S                  | 0.9894\n",
      "VLD745                    | WJT745                    | 0.8568\n",
      "VLM6493                   | VLM6493                   | 0.9756\n",
      "QBC5425                   | QBC5425                   | 0.9758\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 10 done in 11.1s | train_loss=0.1564  valid_loss=0.4371  valid_acc=64.72%\n",
      "\n",
      "no improvement for 3/100 epochs\n",
      "\n",
      "→ Starting epoch 11  (printing every 172 iters)\n",
      "[Epoch 11] iter 172/172, avg loss: 0.1404\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "SD5508L                   | SD5508L                   | 0.7841\n",
      "PRF!6163                  | PRF!6163                  | 0.8745\n",
      "MY!3045                   | WA!3042                   | 0.8025\n",
      "VK2618                    | VK26666                   | 0.9085\n",
      "PZ171M                    | QSY71MM                   | 0.6829\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 11 done in 11.7s | train_loss=0.1404  valid_loss=0.5602  valid_acc=46.65%\n",
      "\n",
      "no improvement for 4/100 epochs\n",
      "\n",
      "→ Starting epoch 12  (printing every 172 iters)\n",
      "[Epoch 12] iter 172/172, avg loss: 0.1205\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QTP9129                   | QTP9129                   | 0.9745\n",
      "AND!897                   | AND!897                   | 0.9539\n",
      "PNV!4846                  | PNV!4846                  | 0.9813\n",
      "QCE1128                   | QCE1128                   | 0.9939\n",
      "BHF2928                   | BHF2928                   | 0.9952\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 12 done in 11.4s | train_loss=0.1205  valid_loss=0.3278  valid_acc=76.97%\n",
      "\n",
      "💾 New best model saved (epoch 12, val_acc=76.97%)\n",
      "\n",
      "→ Starting epoch 13  (printing every 172 iters)\n",
      "[Epoch 13] iter 172/172, avg loss: 0.1135\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QCJ!9999                  | QCJ!9599                  | 0.9320\n",
      "NDL4631                   | NDL4631                   | 0.9970\n",
      "AML!6313                  | AML!8133                  | 0.8489\n",
      "AMC6830                   | AMC6830                   | 0.9808\n",
      "WA!7920W                  | WU!7901W                  | 0.7136\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 13 done in 11.2s | train_loss=0.1135  valid_loss=0.3515  valid_acc=70.85%\n",
      "\n",
      "no improvement for 1/100 epochs\n",
      "\n",
      "→ Starting epoch 14  (printing every 172 iters)\n",
      "[Epoch 14] iter 172/172, avg loss: 0.0900\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WB!302Q                   | WB!302Q                   | 0.8987\n",
      "WYC8600                   | WYC8600                   | 0.9730\n",
      "QAN!23                    | QAN!23                    | 0.9062\n",
      "PKV4279                   | PKV4279                   | 0.9708\n",
      "WQC4674                   | WQC4674                   | 0.9979\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 14 done in 13.8s | train_loss=0.0900  valid_loss=0.3596  valid_acc=76.97%\n",
      "\n",
      "no improvement for 2/100 epochs\n",
      "\n",
      "→ Starting epoch 15  (printing every 172 iters)\n",
      "[Epoch 15] iter 172/172, avg loss: 0.1001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "AMC6830                   | AMC6830                   | 0.9974\n",
      "JUS8529                   | JUS8529                   | 0.9744\n",
      "VET612                    | VET612                    | 0.9549\n",
      "PLE8999                   | PLE8819                   | 0.8950\n",
      "VLM6493                   | VLM6493                   | 0.9774\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 15 done in 13.7s | train_loss=0.1001  valid_loss=0.4083  valid_acc=70.55%\n",
      "\n",
      "no improvement for 3/100 epochs\n",
      "\n",
      "→ Starting epoch 16  (printing every 172 iters)\n",
      "[Epoch 16] iter 172/172, avg loss: 0.0826\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "T/WC3                     | T/WC3                     | 0.9100\n",
      "VGF!4942                  | VGF!4942                  | 0.9519\n",
      "QCN8327                   | QCN8327                   | 0.9903\n",
      "MDV!8552                  | MDV!8552                  | 0.9565\n",
      "QAA8127S                  | QAA8127S                  | 0.9886\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 16 done in 13.7s | train_loss=0.0826  valid_loss=0.4295  valid_acc=74.34%\n",
      "\n",
      "no improvement for 4/100 epochs\n",
      "\n",
      "→ Starting epoch 17  (printing every 172 iters)\n",
      "[Epoch 17] iter 172/172, avg loss: 0.0558\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "SJF!5203                  | BJF!9203                  | 0.9157\n",
      "SYX3611                   | SYX3611                   | 0.9958\n",
      "WXJ911                    | WXJ9118                   | 0.9612\n",
      "PRM41                     | PRM41                     | 0.9764\n",
      "QSP!5188                  | QSP!5188                  | 0.9439\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 17 done in 15.0s | train_loss=0.0558  valid_loss=0.3984  valid_acc=74.64%\n",
      "\n",
      "no improvement for 5/100 epochs\n",
      "\n",
      "→ Starting epoch 18  (printing every 172 iters)\n",
      "[Epoch 18] iter 172/172, avg loss: 0.0854\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAA2809X                  | QAA2809X                  | 0.9768\n",
      "QKB1883                   | QKB1883                   | 0.9426\n",
      "VNQ4338                   | VNQ4338                   | 0.9004\n",
      "QTQ1531                   | QTQ1531                   | 0.9777\n",
      "QBE!2772                  | QBE!2772                  | 0.9325\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 18 done in 13.5s | train_loss=0.0854  valid_loss=0.3983  valid_acc=72.01%\n",
      "\n",
      "no improvement for 6/100 epochs\n",
      "\n",
      "→ Starting epoch 19  (printing every 172 iters)\n",
      "[Epoch 19] iter 172/172, avg loss: 0.0836\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "NCM!9145                  | MCM!9145                  | 0.9243\n",
      "SWH1319                   | SWH1319                   | 0.9845\n",
      "SD2901V                   | SD2901V                   | 0.9358\n",
      "QCK8417                   | QCK8417                   | 0.9891\n",
      "T/AA823                   | T/AA823                   | 0.9842\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 19 done in 13.1s | train_loss=0.0836  valid_loss=0.3232  valid_acc=74.64%\n",
      "\n",
      "no improvement for 7/100 epochs\n",
      "\n",
      "→ Starting epoch 20  (printing every 172 iters)\n",
      "[Epoch 20] iter 172/172, avg loss: 0.0455\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VKP!3405                  | VKP!3405                  | 0.9907\n",
      "JXN7492                   | JXN7492                   | 0.9711\n",
      "W8631X                    | W8631X                    | 0.9653\n",
      "QS5119P                   | QS5119P                   | 0.9787\n",
      "TDB7888                   | TDB7888                   | 0.9951\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 20 done in 14.3s | train_loss=0.0455  valid_loss=0.3293  valid_acc=76.68%\n",
      "\n",
      "no improvement for 8/100 epochs\n",
      "\n",
      "→ Starting epoch 21  (printing every 172 iters)\n",
      "[Epoch 21] iter 172/172, avg loss: 0.0381\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "HWE8782                   | HWE8782                   | 0.9856\n",
      "BNF8126                   | BNF8126                   | 0.9849\n",
      "WUV!7830                  | WUV!7830                  | 0.9832\n",
      "QS1595E                   | QS1595E                   | 0.9849\n",
      "BLG7607                   | BJG7507                   | 0.9435\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 21 done in 14.3s | train_loss=0.0381  valid_loss=0.3263  valid_acc=79.01%\n",
      "\n",
      "💾 New best model saved (epoch 21, val_acc=79.01%)\n",
      "\n",
      "→ Starting epoch 22  (printing every 172 iters)\n",
      "[Epoch 22] iter 172/172, avg loss: 0.0559\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "AHU!7727                  | AHU!7727                  | 0.9777\n",
      "TDB7888                   | TDB7888                   | 0.9976\n",
      "QCJ!6565                  | QCL!5545                  | 0.9350\n",
      "VFH!2157                  | VFH!2157                  | 0.9759\n",
      "TTB1838                   | TTB1838                   | 0.9940\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 22 done in 13.5s | train_loss=0.0559  valid_loss=0.3026  valid_acc=77.26%\n",
      "\n",
      "no improvement for 1/100 epochs\n",
      "\n",
      "→ Starting epoch 23  (printing every 172 iters)\n",
      "[Epoch 23] iter 172/172, avg loss: 0.0451\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "AM7017                    | AM7017                    | 0.9755\n",
      "QKU7812                   | QKU7812                   | 0.9808\n",
      "QSX2233                   | QSY2233                   | 0.9598\n",
      "QAR6858                   | QAR6858                   | 0.9923\n",
      "PZ171M                    | PZ171M                    | 0.9224\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 23 done in 14.3s | train_loss=0.0451  valid_loss=0.3181  valid_acc=74.05%\n",
      "\n",
      "no improvement for 2/100 epochs\n",
      "\n",
      "→ Starting epoch 24  (printing every 172 iters)\n",
      "[Epoch 24] iter 172/172, avg loss: 0.0409\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QTQ1531                   | QTQ1531                   | 0.9928\n",
      "JV271                     | JV271                     | 0.9698\n",
      "KBJ5226                   | KBJ5226                   | 0.9908\n",
      "QAB9731D                  | QAB9731D                  | 0.9730\n",
      "KAX1199                   | KAX1199                   | 0.9985\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 24 done in 12.2s | train_loss=0.0409  valid_loss=0.3088  valid_acc=77.55%\n",
      "\n",
      "no improvement for 3/100 epochs\n",
      "\n",
      "→ Starting epoch 25  (printing every 172 iters)\n",
      "[Epoch 25] iter 172/172, avg loss: 0.0322\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "T/WC3                     | T/WC3                     | 0.9805\n",
      "QAB!8936                  | QAB!8936                  | 0.9931\n",
      "QBF!2288                  | QBF!2288                  | 0.9784\n",
      "QAW2391                   | QAW2391                   | 0.9825\n",
      "QAA!4174                  | QAA!4174                  | 0.9469\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 25 done in 11.0s | train_loss=0.0322  valid_loss=0.2950  valid_acc=76.68%\n",
      "\n",
      "no improvement for 4/100 epochs\n",
      "\n",
      "→ Starting epoch 26  (printing every 172 iters)\n",
      "[Epoch 26] iter 172/172, avg loss: 0.0283\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "T/JA213                   | T/JA213                   | 0.9830\n",
      "QMU595                    | QMU595                    | 0.9857\n",
      "QAB9766H                  | QAB9766H                  | 0.9757\n",
      "TCN!8474                  | TCN!8474                  | 0.9910\n",
      "QS1595E                   | QS1595E                   | 0.9904\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 26 done in 11.2s | train_loss=0.0283  valid_loss=0.3807  valid_acc=77.84%\n",
      "\n",
      "no improvement for 5/100 epochs\n",
      "\n",
      "→ Starting epoch 27  (printing every 172 iters)\n",
      "[Epoch 27] iter 172/172, avg loss: 0.0256\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WVB5362                   | WVB5362                   | 0.9829\n",
      "QMB!9780                  | QMB!9780                  | 0.9874\n",
      "QAA6595Q                  | QAA6595Q                  | 0.9783\n",
      "NCH9890                   | NCH9890                   | 0.9752\n",
      "QSU9715                   | QSU9715                   | 0.9731\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 27 done in 10.9s | train_loss=0.0256  valid_loss=0.3239  valid_acc=76.09%\n",
      "\n",
      "no improvement for 6/100 epochs\n",
      "\n",
      "→ Starting epoch 28  (printing every 172 iters)\n",
      "[Epoch 28] iter 172/172, avg loss: 0.0284\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "TAM!408                   | TAM!422                   | 0.8654\n",
      "TAE2798                   | TAE2798                   | 0.9790\n",
      "RT1911                    | RT1911                    | 0.9511\n",
      "MDS7934                   | MDS7934                   | 0.9993\n",
      "JWC6011                   | JWC6011                   | 0.9972\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 28 done in 11.8s | train_loss=0.0284  valid_loss=0.3290  valid_acc=77.84%\n",
      "\n",
      "no improvement for 7/100 epochs\n",
      "\n",
      "→ Starting epoch 29  (printing every 172 iters)\n",
      "[Epoch 29] iter 172/172, avg loss: 0.0593\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WYJ7760                   | WYJ7760                   | 0.9608\n",
      "JTW!5239                  | JTW!5339                  | 0.9452\n",
      "QAA8823M                  | QAA8833M                  | 0.9585\n",
      "QM2377M                   | QM2377                    | 0.8107\n",
      "BDR!2148                  | BDR!2148                  | 0.9934\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 29 done in 11.3s | train_loss=0.0593  valid_loss=0.6582  valid_acc=54.81%\n",
      "\n",
      "no improvement for 8/100 epochs\n",
      "\n",
      "→ Starting epoch 30  (printing every 172 iters)\n",
      "[Epoch 30] iter 172/172, avg loss: 0.0547\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QCB!1921                  | QCB!1921                  | 0.9679\n",
      "QTS6613                   | QTS6613                   | 0.9932\n",
      "SML6789                   | SMG6789                   | 0.9524\n",
      "MDN!8761                  | MDN!8761                  | 0.9945\n",
      "QCF847                    | QCF847                    | 0.9082\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 30 done in 10.7s | train_loss=0.0547  valid_loss=0.3779  valid_acc=72.89%\n",
      "\n",
      "no improvement for 9/100 epochs\n",
      "\n",
      "→ Starting epoch 31  (printing every 172 iters)\n",
      "[Epoch 31] iter 172/172, avg loss: 0.0494\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAB2477H                  | QAB2477H                  | 0.9459\n",
      "VAJ!4559                  | VAJ!4559                  | 0.9939\n",
      "JTU3636                   | JTU3636                   | 0.9971\n",
      "VDL7317                   | VDL7317                   | 0.9959\n",
      "VE9696                    | VE9696                    | 0.9626\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 31 done in 11.4s | train_loss=0.0494  valid_loss=0.3540  valid_acc=73.18%\n",
      "\n",
      "no improvement for 10/100 epochs\n",
      "\n",
      "→ Starting epoch 32  (printing every 172 iters)\n",
      "[Epoch 32] iter 172/172, avg loss: 0.0581\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QCR6004                   | QCR6004                   | 0.9963\n",
      "JSD3681                   | JSD3681                   | 0.9929\n",
      "VET612                    | VET612                    | 0.9749\n",
      "QAR53                     | QAR53                     | 0.9764\n",
      "WB6577N                   | WB6577N                   | 0.9907\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 32 done in 11.5s | train_loss=0.0581  valid_loss=0.3499  valid_acc=74.93%\n",
      "\n",
      "no improvement for 11/100 epochs\n",
      "\n",
      "→ Starting epoch 33  (printing every 172 iters)\n",
      "[Epoch 33] iter 172/172, avg loss: 0.0362\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VFX447                    | VFX447                    | 0.9617\n",
      "PGL2189                   | PGL2189                   | 0.9964\n",
      "QCP8767                   | QCP8767                   | 0.9970\n",
      "PDP6868                   | PDP6868                   | 0.9688\n",
      "ANK!8132                  | ANK!8132                  | 0.9862\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 33 done in 11.5s | train_loss=0.0362  valid_loss=0.3909  valid_acc=74.34%\n",
      "\n",
      "no improvement for 12/100 epochs\n",
      "\n",
      "→ Starting epoch 34  (printing every 172 iters)\n",
      "[Epoch 34] iter 172/172, avg loss: 0.0352\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "JNA3294                   | JNA3294                   | 0.9705\n",
      "SD2901V                   | SD2901V                   | 0.9977\n",
      "JVB6226                   | JVB6226                   | 0.9731\n",
      "KP3300Q                   | KP3300Q                   | 0.9821\n",
      "VJR!1999                  | VJR!1999                  | 0.9729\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 34 done in 11.8s | train_loss=0.0352  valid_loss=0.3849  valid_acc=76.97%\n",
      "\n",
      "no improvement for 13/100 epochs\n",
      "\n",
      "→ Starting epoch 35  (printing every 172 iters)\n",
      "[Epoch 35] iter 172/172, avg loss: 0.0313\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "BDP4954                   | BDP4954                   | 0.9823\n",
      "QP4444                    | QP4444                    | 0.9914\n",
      "QPA3382                   | QPA3382                   | 0.9880\n",
      "PMU!3220                  | QMU!3220                  | 0.9385\n",
      "AMV2374                   | AMV2374                   | 0.9961\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 35 done in 11.7s | train_loss=0.0313  valid_loss=0.3830  valid_acc=74.93%\n",
      "\n",
      "no improvement for 14/100 epochs\n",
      "\n",
      "→ Starting epoch 36  (printing every 172 iters)\n",
      "[Epoch 36] iter 172/172, avg loss: 0.0213\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAA2454X                  | QAA2454X                  | 0.9955\n",
      "QAX!2076                  | QAX!2076                  | 0.9978\n",
      "TBH1267                   | TBH1267                   | 0.9724\n",
      "W8631X                    | W8631X                    | 0.9729\n",
      "VAW4421                   | VAW4421                   | 0.9980\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 36 done in 12.0s | train_loss=0.0213  valid_loss=0.3606  valid_acc=76.97%\n",
      "\n",
      "no improvement for 15/100 epochs\n",
      "\n",
      "→ Starting epoch 37  (printing every 172 iters)\n",
      "[Epoch 37] iter 172/172, avg loss: 0.0367\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VX2808                    | VX2808                    | 0.9483\n",
      "SD9913R                   | SD9913R                   | 0.9678\n",
      "JSG1987                   | JSG1967                   | 0.9415\n",
      "WYL2575                   | WYL2575                   | 0.9884\n",
      "VEH!6204                  | VEH!6204                  | 0.9909\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 37 done in 12.5s | train_loss=0.0367  valid_loss=0.3920  valid_acc=74.93%\n",
      "\n",
      "no improvement for 16/100 epochs\n",
      "\n",
      "→ Starting epoch 38  (printing every 172 iters)\n",
      "[Epoch 38] iter 172/172, avg loss: 0.0367\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WUH!8857                  | WUH!8857                  | 0.9583\n",
      "QM2377M                   | QM2377M                   | 0.9810\n",
      "QKM5112                   | QKM5112                   | 0.9762\n",
      "WTW6533                   | WTW6533                   | 0.9910\n",
      "SD9913R                   | SD9913R                   | 0.9510\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 38 done in 12.0s | train_loss=0.0367  valid_loss=0.3258  valid_acc=80.47%\n",
      "\n",
      "💾 New best model saved (epoch 38, val_acc=80.47%)\n",
      "\n",
      "→ Starting epoch 39  (printing every 172 iters)\n",
      "[Epoch 39] iter 172/172, avg loss: 0.0336\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QS8591M                   | QS8591M                   | 0.9390\n",
      "VKD9603                   | VKD9603                   | 0.9487\n",
      "QS2025K                   | QS2025K                   | 0.9773\n",
      "QAR2857                   | QAR2857                   | 0.9790\n",
      "WC4922X                   | WC4922X                   | 0.9847\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 39 done in 12.2s | train_loss=0.0336  valid_loss=0.3793  valid_acc=76.97%\n",
      "\n",
      "no improvement for 1/100 epochs\n",
      "\n",
      "→ Starting epoch 40  (printing every 172 iters)\n",
      "[Epoch 40] iter 172/172, avg loss: 0.0241\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAA377P                   | QAA377P                   | 0.9638\n",
      "MCV1838                   | MCV1838                   | 0.9853\n",
      "MDV1999                   | MDV1999                   | 0.9544\n",
      "QCH9191                   | QCH9191                   | 0.9858\n",
      "QAN7517                   | QAN7517                   | 0.9874\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 40 done in 11.9s | train_loss=0.0241  valid_loss=0.3347  valid_acc=77.55%\n",
      "\n",
      "no improvement for 2/100 epochs\n",
      "\n",
      "→ Starting epoch 41  (printing every 172 iters)\n",
      "[Epoch 41] iter 172/172, avg loss: 0.0265\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "BKL9211                   | BKL9211                   | 0.9832\n",
      "PGL!2189                  | PGL!218                   | 0.9817\n",
      "VJY4021                   | VJY4021                   | 0.9741\n",
      "CCW!3760                  | CCW!3760                  | 0.9607\n",
      "VCQ7119                   | VCQ7119                   | 0.9934\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 41 done in 12.0s | train_loss=0.0265  valid_loss=0.4904  valid_acc=67.06%\n",
      "\n",
      "no improvement for 3/100 epochs\n",
      "\n",
      "→ Starting epoch 42  (printing every 172 iters)\n",
      "[Epoch 42] iter 172/172, avg loss: 0.0286\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "SA1408K                   | SA1408K                   | 0.9685\n",
      "QAB373                    | QAB373                    | 0.9401\n",
      "QAB3330B                  | QAB3330B                  | 0.9722\n",
      "JHC!8095                  | JHJ!8095                  | 0.9146\n",
      "JSF2692                   | JSF2692                   | 0.9902\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 42 done in 12.1s | train_loss=0.0286  valid_loss=0.3448  valid_acc=76.97%\n",
      "\n",
      "no improvement for 4/100 epochs\n",
      "\n",
      "→ Starting epoch 43  (printing every 172 iters)\n",
      "[Epoch 43] iter 172/172, avg loss: 0.0422\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAA3323X                  | QAA3323X                  | 0.9778\n",
      "FE3433                    | FE3433                    | 0.9618\n",
      "AHU!7727                  | AHU!7727                  | 0.9523\n",
      "QS2582P                   | QS2582P                   | 0.9767\n",
      "RW9634                    | RW9634                    | 0.9674\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 43 done in 11.9s | train_loss=0.0422  valid_loss=0.3308  valid_acc=76.97%\n",
      "\n",
      "no improvement for 5/100 epochs\n",
      "\n",
      "→ Starting epoch 44  (printing every 172 iters)\n",
      "[Epoch 44] iter 172/172, avg loss: 0.0231\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WXJ9118                   | WXJ9118                   | 0.9411\n",
      "WXT!2433                  | WXT!2433                  | 0.9961\n",
      "BQX!3898                  | BQX!3898                  | 0.9853\n",
      "VKR!5274                  | VKR!5274                  | 0.9771\n",
      "JKC7100                   | JKC7100                   | 0.9588\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 44 done in 12.0s | train_loss=0.0231  valid_loss=0.3770  valid_acc=71.72%\n",
      "\n",
      "no improvement for 6/100 epochs\n",
      "\n",
      "→ Starting epoch 45  (printing every 172 iters)\n",
      "[Epoch 45] iter 172/172, avg loss: 0.0224\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VEQ6291                   | VEQ6291                   | 0.9701\n",
      "QCT7867                   | QCT7867                   | 0.9967\n",
      "NAN6440                   | NAN6440                   | 0.9832\n",
      "QAA3986N                  | QAA3986N                  | 0.9946\n",
      "WTE!2868                  | WTE!2868                  | 0.9540\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 45 done in 12.4s | train_loss=0.0224  valid_loss=0.3870  valid_acc=76.38%\n",
      "\n",
      "no improvement for 7/100 epochs\n",
      "\n",
      "→ Starting epoch 46  (printing every 172 iters)\n",
      "[Epoch 46] iter 172/172, avg loss: 0.0176\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "SYQ9881                   | SYQ9881                   | 0.9814\n",
      "QTY9455                   | QTY9455                   | 0.9473\n",
      "JTE!2309                  | JTE!2309                  | 0.9745\n",
      "T/JA213                   | T/JA213                   | 0.9538\n",
      "VGN2263                   | VGN2263                   | 0.9765\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 46 done in 12.1s | train_loss=0.0176  valid_loss=0.4042  valid_acc=69.10%\n",
      "\n",
      "no improvement for 8/100 epochs\n",
      "\n",
      "→ Starting epoch 47  (printing every 172 iters)\n",
      "[Epoch 47] iter 172/172, avg loss: 0.0109\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "JNB388                    | JNB388                    | 0.9850\n",
      "NDL4631                   | NDL4631                   | 0.9775\n",
      "NH2225                    | NH2225                    | 0.9983\n",
      "WQC4674                   | WQC4674                   | 0.9871\n",
      "QAV8900                   | QAV8900                   | 0.9920\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 47 done in 12.2s | train_loss=0.0109  valid_loss=0.4319  valid_acc=69.10%\n",
      "\n",
      "no improvement for 9/100 epochs\n",
      "\n",
      "→ Starting epoch 48  (printing every 172 iters)\n",
      "[Epoch 48] iter 172/172, avg loss: 0.0195\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "BLR!9830                  | BLR!9830                  | 0.9975\n",
      "AKF!4463                  | AKF!4463                  | 0.9770\n",
      "BKV1970                   | BKV1970                   | 0.9939\n",
      "VMY!9477                  | VMY!9477                  | 0.9581\n",
      "QM4997P                   | QM4997P                   | 0.9913\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 48 done in 11.9s | train_loss=0.0195  valid_loss=0.3580  valid_acc=75.80%\n",
      "\n",
      "no improvement for 10/100 epochs\n",
      "\n",
      "→ Starting epoch 49  (printing every 172 iters)\n",
      "[Epoch 49] iter 172/172, avg loss: 0.0156\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "TCN!8474                  | TCN!8474                  | 0.9874\n",
      "WTW6533                   | WTW6533                   | 0.9858\n",
      "QAA6411                   | QAA6411                   | 0.9793\n",
      "T/D1673                   | T/D1673                   | 0.9823\n",
      "QS9953S                   | QS9953S                   | 0.9530\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 49 done in 11.4s | train_loss=0.0156  valid_loss=0.3722  valid_acc=76.97%\n",
      "\n",
      "no improvement for 11/100 epochs\n",
      "\n",
      "→ Starting epoch 50  (printing every 172 iters)\n",
      "[Epoch 50] iter 172/172, avg loss: 0.0218\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAA!4174                  | QAA!4174                  | 0.9846\n",
      "WXJ9118                   | WXJ9118                   | 0.9526\n",
      "PEA!1781                  | PEA!1791                  | 0.8602\n",
      "TCA7789                   | TCA7789                   | 0.9707\n",
      "WKX!6755                  | WKX!6555                  | 0.9505\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 50 done in 11.3s | train_loss=0.0218  valid_loss=0.3863  valid_acc=68.51%\n",
      "\n",
      "no improvement for 12/100 epochs\n",
      "\n",
      "→ Starting epoch 51  (printing every 172 iters)\n",
      "[Epoch 51] iter 172/172, avg loss: 0.0193\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "T/BB2347                  | T/BB2347                  | 0.9784\n",
      "TBH1267                   | TBH1267                   | 0.9962\n",
      "SMH9778                   | SMH9778                   | 0.9990\n",
      "QAB3641H                  | QAB3641H                  | 0.9673\n",
      "QCB3330                   | QCB3330                   | 0.9934\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 51 done in 10.9s | train_loss=0.0193  valid_loss=0.3538  valid_acc=74.93%\n",
      "\n",
      "no improvement for 13/100 epochs\n",
      "\n",
      "→ Starting epoch 52  (printing every 172 iters)\n",
      "[Epoch 52] iter 172/172, avg loss: 0.0122\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "ANT8883                   | ANT8883                   | 0.9908\n",
      "RT9009                    | RT9009                    | 0.9610\n",
      "PZ171M                    | PZ171M                    | 0.9624\n",
      "QCJ5838                   | QCJ5838                   | 0.9988\n",
      "QTW!7053                  | QTW!7053                  | 0.9924\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 52 done in 11.3s | train_loss=0.0122  valid_loss=0.3796  valid_acc=77.55%\n",
      "\n",
      "no improvement for 14/100 epochs\n",
      "\n",
      "→ Starting epoch 53  (printing every 172 iters)\n",
      "[Epoch 53] iter 172/172, avg loss: 0.0115\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "PNV!4846                  | PNV!4846                  | 0.9962\n",
      "UMK!8883                  | UMK!8883                  | 0.9224\n",
      "WCR4455                   | WCR4455                   | 0.9992\n",
      "JTU3636                   | JTU3636                   | 0.9959\n",
      "MBP5604                   | MBP5604                   | 0.9914\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 53 done in 11.3s | train_loss=0.0115  valid_loss=0.4116  valid_acc=74.64%\n",
      "\n",
      "no improvement for 15/100 epochs\n",
      "\n",
      "→ Starting epoch 54  (printing every 172 iters)\n",
      "[Epoch 54] iter 172/172, avg loss: 0.0117\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VKP!3405                  | VKP!3405                  | 0.9695\n",
      "T/BD!1513                 | T/BD!1513                 | 0.9736\n",
      "TCN!8474                  | TCN!8474                  | 0.9652\n",
      "WA1309F                   | WA1309F                   | 0.9718\n",
      "PPR3334                   | PPR3334                   | 0.9781\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 54 done in 11.2s | train_loss=0.0117  valid_loss=0.3663  valid_acc=76.68%\n",
      "\n",
      "no improvement for 16/100 epochs\n",
      "\n",
      "→ Starting epoch 55  (printing every 172 iters)\n",
      "[Epoch 55] iter 172/172, avg loss: 0.0170\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAA8951J                  | QAA8951J                  | 0.9623\n",
      "T/N4541                   | T/N4541                   | 0.9883\n",
      "VLD745                    | VLD745                    | 0.9927\n",
      "QAA6615Q                  | QAA6615Q                  | 0.9962\n",
      "VJA520                    | VJA520                    | 0.9953\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 55 done in 11.6s | train_loss=0.0170  valid_loss=0.3468  valid_acc=75.51%\n",
      "\n",
      "no improvement for 17/100 epochs\n",
      "\n",
      "→ Starting epoch 56  (printing every 172 iters)\n",
      "[Epoch 56] iter 172/172, avg loss: 0.0155\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WGC!5600                  | WGC!5600                  | 0.9955\n",
      "SD288V                    | SD288V                    | 0.9854\n",
      "WQD6028                   | WQD6028                   | 0.9995\n",
      "QAQ1011                   | QAQ1011                   | 0.9876\n",
      "JLX!6457                  | JLX!6457                  | 0.9639\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 56 done in 11.6s | train_loss=0.0155  valid_loss=0.3980  valid_acc=77.84%\n",
      "\n",
      "no improvement for 18/100 epochs\n",
      "\n",
      "→ Starting epoch 57  (printing every 172 iters)\n",
      "[Epoch 57] iter 172/172, avg loss: 0.0096\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VHG1732                   | VHG1732                   | 0.9643\n",
      "QAL8533                   | QAL8533                   | 0.9899\n",
      "VHB3371                   | VHB3371                   | 0.9894\n",
      "1M4U3172                  | 1M4U3772                  | 0.9413\n",
      "QM6676C                   | QM6676C                   | 0.9411\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 57 done in 11.4s | train_loss=0.0096  valid_loss=0.3388  valid_acc=77.26%\n",
      "\n",
      "no improvement for 19/100 epochs\n",
      "\n",
      "→ Starting epoch 58  (printing every 172 iters)\n",
      "[Epoch 58] iter 172/172, avg loss: 0.0088\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WTW6533                   | WTW6533                   | 0.9943\n",
      "JSD809                    | JSD809                    | 0.9866\n",
      "JCY7217                   | JCY7217                   | 0.9977\n",
      "VHG1732                   | VHG1732                   | 0.9891\n",
      "JNE6460                   | JNE6460                   | 0.9956\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 58 done in 11.3s | train_loss=0.0088  valid_loss=0.3722  valid_acc=76.68%\n",
      "\n",
      "no improvement for 20/100 epochs\n",
      "\n",
      "→ Starting epoch 59  (printing every 172 iters)\n",
      "[Epoch 59] iter 172/172, avg loss: 0.0071\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WDJ9407                   | WDJ9407                   | 0.9997\n",
      "QSW!8828                  | QSW!8828                  | 0.9718\n",
      "QD1811                    | QD1811                    | 0.9947\n",
      "DCS!3819                  | DCS!3819                  | 0.9683\n",
      "JSY!1378                  | JSY!1378                  | 0.9889\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 59 done in 11.1s | train_loss=0.0071  valid_loss=0.3633  valid_acc=77.84%\n",
      "\n",
      "no improvement for 21/100 epochs\n",
      "\n",
      "→ Starting epoch 60  (printing every 172 iters)\n",
      "[Epoch 60] iter 172/172, avg loss: 0.0070\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "MAV!2430                  | MAV!2430                  | 0.9547\n",
      "JRN!7985                  | JRN!7985                  | 0.9715\n",
      "WA1309F                   | WA1309F                   | 0.9694\n",
      "BGW2901                   | BGW2901                   | 0.9797\n",
      "WUV9209                   | WUV9209                   | 0.9766\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 60 done in 11.2s | train_loss=0.0070  valid_loss=0.3638  valid_acc=77.55%\n",
      "\n",
      "no improvement for 22/100 epochs\n",
      "\n",
      "→ Starting epoch 61  (printing every 172 iters)\n",
      "[Epoch 61] iter 172/172, avg loss: 0.0088\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "PPT549                    | PPT549                    | 0.9941\n",
      "JXP!4469                  | JXP!4469                  | 0.9733\n",
      "QAB373                    | QAB373                    | 0.9583\n",
      "WSM1382                   | WSM1382                   | 0.9967\n",
      "SYP9169                   | SYP9169                   | 0.9973\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 61 done in 11.3s | train_loss=0.0088  valid_loss=0.3757  valid_acc=76.09%\n",
      "\n",
      "no improvement for 23/100 epochs\n",
      "\n",
      "→ Starting epoch 62  (printing every 172 iters)\n",
      "[Epoch 62] iter 172/172, avg loss: 0.0116\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VLB768                    | VLB768                    | 0.9941\n",
      "QAR53                     | QAR53                     | 0.9824\n",
      "QB97                      | QB97                      | 0.9862\n",
      "ALC!3644                  | ALC!3644                  | 0.9950\n",
      "QAB3170J                  | QAB3170J                  | 0.9640\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 62 done in 11.2s | train_loss=0.0116  valid_loss=0.3200  valid_acc=79.59%\n",
      "\n",
      "no improvement for 24/100 epochs\n",
      "\n",
      "→ Starting epoch 63  (printing every 172 iters)\n",
      "[Epoch 63] iter 172/172, avg loss: 0.0062\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WB7028W                   | WB7028W                   | 0.9732\n",
      "PPD2622                   | PPD2622                   | 0.9988\n",
      "DBR9492                   | DBR9492                   | 0.9844\n",
      "TCN!8474                  | TCN!8474                  | 0.9853\n",
      "MDJ!6389                  | MDJ!6389                  | 0.9676\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 63 done in 11.2s | train_loss=0.0062  valid_loss=0.3277  valid_acc=77.26%\n",
      "\n",
      "no improvement for 25/100 epochs\n",
      "\n",
      "→ Starting epoch 64  (printing every 172 iters)\n",
      "[Epoch 64] iter 172/172, avg loss: 0.0103\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "NEA5163                   | NEA5163                   | 0.9890\n",
      "QS2025K                   | QS2025K                   | 0.9805\n",
      "QTJ4515                   | QTJ4515                   | 0.9428\n",
      "MD3426Q                   | MD3426Q                   | 0.9869\n",
      "VEN6862                   | VEN6862                   | 0.9877\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 64 done in 11.4s | train_loss=0.0103  valid_loss=0.3631  valid_acc=74.05%\n",
      "\n",
      "no improvement for 26/100 epochs\n",
      "\n",
      "→ Starting epoch 65  (printing every 172 iters)\n",
      "[Epoch 65] iter 172/172, avg loss: 0.0133\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "PRF!6163                  | PRF!6163                  | 0.9746\n",
      "FC9447                    | FC9447                    | 0.9652\n",
      "TCJ!8981                  | TCJ!8981                  | 0.9818\n",
      "BEP3409                   | BEP3409                   | 0.9969\n",
      "AJH9714                   | AJH9714                   | 0.9985\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 65 done in 11.7s | train_loss=0.0133  valid_loss=0.3611  valid_acc=76.38%\n",
      "\n",
      "no improvement for 27/100 epochs\n",
      "\n",
      "→ Starting epoch 66  (printing every 172 iters)\n",
      "[Epoch 66] iter 172/172, avg loss: 0.0213\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "PMV4916                   | PMV4916                   | 0.9977\n",
      "QS6811S                   | QS6811S                   | 0.9627\n",
      "WXT!2433                  | WXT!2433                  | 0.9687\n",
      "PLS!114                   | PLS!114                   | 0.9848\n",
      "JMY!6993                  | JMY!6993                  | 0.9888\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 66 done in 11.5s | train_loss=0.0213  valid_loss=0.3693  valid_acc=75.80%\n",
      "\n",
      "no improvement for 28/100 epochs\n",
      "\n",
      "→ Starting epoch 67  (printing every 172 iters)\n",
      "[Epoch 67] iter 172/172, avg loss: 0.0183\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "SD2367N                   | SD2367N                   | 0.9649\n",
      "JUJ!7630                  | JUJ!7630                  | 0.9685\n",
      "SWH1319                   | SWH1319                   | 0.9985\n",
      "QAA3618X                  | QAA3618X                  | 0.9603\n",
      "VGH!8312                  | VGH!8312                  | 0.9851\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 67 done in 11.4s | train_loss=0.0183  valid_loss=0.3729  valid_acc=80.17%\n",
      "\n",
      "no improvement for 29/100 epochs\n",
      "\n",
      "→ Starting epoch 68  (printing every 172 iters)\n",
      "[Epoch 68] iter 172/172, avg loss: 0.0093\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "AMT5830                   | AMT5830                   | 0.9761\n",
      "WSJ8268                   | WSJ8268                   | 0.9693\n",
      "PLX8764                   | PLX8764                   | 0.9907\n",
      "MCD9708                   | MCD9708                   | 0.9866\n",
      "QCA2869                   | QCA2869                   | 0.9992\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 68 done in 10.9s | train_loss=0.0093  valid_loss=0.3204  valid_acc=76.09%\n",
      "\n",
      "no improvement for 30/100 epochs\n",
      "\n",
      "→ Starting epoch 69  (printing every 172 iters)\n",
      "[Epoch 69] iter 172/172, avg loss: 0.0079\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "BGD7950                   | BGD7950                   | 0.9966\n",
      "WFB!6925                  | WFB!6925                  | 0.9851\n",
      "BPT2823                   | BPT2823                   | 0.9841\n",
      "PJN!538                   | PJN!538                   | 0.9970\n",
      "QCN!313                   | QCN!313                   | 0.9729\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 69 done in 11.0s | train_loss=0.0079  valid_loss=0.3630  valid_acc=77.55%\n",
      "\n",
      "no improvement for 31/100 epochs\n",
      "\n",
      "→ Starting epoch 70  (printing every 172 iters)\n",
      "[Epoch 70] iter 172/172, avg loss: 0.0107\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WVB5362                   | WVB5362                   | 0.9973\n",
      "VKL!3928                  | VKL!3928                  | 0.9904\n",
      "QM!9337Q                  | QM!9337Q                  | 0.9337\n",
      "CCM9955                   | CCM8955                   | 0.9775\n",
      "PPD2622                   | PPD2622                   | 0.9969\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 70 done in 11.0s | train_loss=0.0107  valid_loss=0.4115  valid_acc=73.18%\n",
      "\n",
      "no improvement for 32/100 epochs\n",
      "\n",
      "→ Starting epoch 71  (printing every 172 iters)\n",
      "[Epoch 71] iter 172/172, avg loss: 0.0096\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VLL7887                   | VLL7887                   | 0.9886\n",
      "TBB4878                   | TBB4878                   | 0.9953\n",
      "VBH6554                   | VBH6554                   | 0.9936\n",
      "QMV!5505                  | QMV!5505                  | 0.9982\n",
      "QCS7968                   | QCS7968                   | 0.9715\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 71 done in 10.8s | train_loss=0.0096  valid_loss=0.3557  valid_acc=78.72%\n",
      "\n",
      "no improvement for 33/100 epochs\n",
      "\n",
      "→ Starting epoch 72  (printing every 172 iters)\n",
      "[Epoch 72] iter 172/172, avg loss: 0.0064\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "MCV1838                   | MCV1838                   | 0.9853\n",
      "WA1309F                   | WA1309F                   | 0.9594\n",
      "MDS7934                   | MDS7934                   | 0.9962\n",
      "RX8899                    | RX8899                    | 0.9544\n",
      "QM9779R                   | QM9779R                   | 0.9938\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 72 done in 11.1s | train_loss=0.0064  valid_loss=0.3697  valid_acc=79.88%\n",
      "\n",
      "no improvement for 34/100 epochs\n",
      "\n",
      "→ Starting epoch 73  (printing every 172 iters)\n",
      "[Epoch 73] iter 172/172, avg loss: 0.0154\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VBQ!7144                  | VBQ!7144                  | 0.9215\n",
      "QM3245P                   | QM3245P                   | 0.9925\n",
      "QBB9955                   | QBB9955                   | 0.9765\n",
      "B3106A                    | B3106A                    | 0.9554\n",
      "JQL3221                   | JQL3221                   | 0.9981\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 73 done in 10.8s | train_loss=0.0154  valid_loss=0.3747  valid_acc=79.59%\n",
      "\n",
      "no improvement for 35/100 epochs\n",
      "\n",
      "→ Starting epoch 74  (printing every 172 iters)\n",
      "[Epoch 74] iter 172/172, avg loss: 0.0126\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "RAY!5050                  | RAY!5050                  | 0.9990\n",
      "VHA6835                   | VHA6835                   | 0.9523\n",
      "SD3933P                   | SD3933P                   | 0.9758\n",
      "QTJ4515                   | QTJ4515                   | 0.9964\n",
      "MAM!6063                  | MAM!6063                  | 0.9778\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 74 done in 11.5s | train_loss=0.0126  valid_loss=0.3846  valid_acc=76.38%\n",
      "\n",
      "no improvement for 36/100 epochs\n",
      "\n",
      "→ Starting epoch 75  (printing every 172 iters)\n",
      "[Epoch 75] iter 172/172, avg loss: 0.0088\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "KDB9833                   | KDB9833                   | 0.9917\n",
      "QKV465                    | QKV465                    | 0.9940\n",
      "VFN!701                   | VFN!701                   | 0.9687\n",
      "WCG!7220                  | WCG!7220                  | 0.9524\n",
      "JMY!6993                  | JMY!6993                  | 0.9779\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 75 done in 11.3s | train_loss=0.0088  valid_loss=0.3677  valid_acc=77.84%\n",
      "\n",
      "no improvement for 37/100 epochs\n",
      "\n",
      "→ Starting epoch 76  (printing every 172 iters)\n",
      "[Epoch 76] iter 172/172, avg loss: 0.0094\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VLM3621                   | VLM3621                   | 0.9719\n",
      "VFC!331                   | VFC!331                   | 0.9525\n",
      "JRK1292                   | JRK1292                   | 0.9950\n",
      "QAA3858U                  | QAA3858U                  | 0.9626\n",
      "VP!7674                   | VP!7674                   | 0.9830\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 76 done in 11.1s | train_loss=0.0094  valid_loss=0.4127  valid_acc=75.22%\n",
      "\n",
      "no improvement for 38/100 epochs\n",
      "\n",
      "→ Starting epoch 77  (printing every 172 iters)\n",
      "[Epoch 77] iter 172/172, avg loss: 0.0075\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAA3440                   | QAA3440                   | 0.9938\n",
      "QCB3330                   | QCB3330                   | 0.9972\n",
      "TCN!8474                  | TCN!8476                  | 0.9549\n",
      "ALN8722                   | ALN8722                   | 0.9760\n",
      "PQS5137                   | PQS5137                   | 0.9961\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 77 done in 11.0s | train_loss=0.0075  valid_loss=0.3628  valid_acc=78.43%\n",
      "\n",
      "no improvement for 39/100 epochs\n",
      "\n",
      "→ Starting epoch 78  (printing every 172 iters)\n",
      "[Epoch 78] iter 172/172, avg loss: 0.0082\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "KW!655                    | KW!655                    | 0.9621\n",
      "QCE40                     | QCE40                     | 0.9566\n",
      "WDJ9407                   | WDJ9407                   | 0.9969\n",
      "VCW2744                   | VCW2744                   | 0.9943\n",
      "BDR!2148                  | BDR!2148                  | 0.9596\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 78 done in 11.0s | train_loss=0.0082  valid_loss=0.3893  valid_acc=80.76%\n",
      "\n",
      "💾 New best model saved (epoch 78, val_acc=80.76%)\n",
      "\n",
      "→ Starting epoch 79  (printing every 172 iters)\n",
      "[Epoch 79] iter 172/172, avg loss: 0.0049\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "JSB1749                   | JSB1749                   | 0.9957\n",
      "NCQ2205                   | NCQ2205                   | 0.9782\n",
      "WCG!7220                  | WCG!7220                  | 0.9544\n",
      "JHN6661                   | JHN6661                   | 0.9989\n",
      "PGL!2189                  | PGL!2189                  | 0.9801\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 79 done in 11.0s | train_loss=0.0049  valid_loss=0.3999  valid_acc=80.17%\n",
      "\n",
      "no improvement for 1/100 epochs\n",
      "\n",
      "→ Starting epoch 80  (printing every 172 iters)\n",
      "[Epoch 80] iter 172/172, avg loss: 0.0044\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WRX3310                   | WRX3310                   | 0.9955\n",
      "QRB8366                   | QRB8366                   | 0.9969\n",
      "JSH!4299                  | JSH!4299                  | 0.9732\n",
      "WTM!3755                  | WTM!3755                  | 0.9973\n",
      "ACM!5600                  | ACM!5600                  | 0.9826\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 80 done in 11.1s | train_loss=0.0044  valid_loss=0.4004  valid_acc=79.01%\n",
      "\n",
      "no improvement for 2/100 epochs\n",
      "\n",
      "→ Starting epoch 81  (printing every 172 iters)\n",
      "[Epoch 81] iter 172/172, avg loss: 0.0062\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAB!8977J                 | QAB!8977J                 | 0.9467\n",
      "NEE5358                   | NEE5358                   | 0.9773\n",
      "WFR9497                   | WFR9497                   | 0.9930\n",
      "VFT8338                   | VFT8338                   | 0.9944\n",
      "QAA!4714P                 | QAA!4714P                 | 0.9702\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 81 done in 11.4s | train_loss=0.0062  valid_loss=0.4075  valid_acc=76.38%\n",
      "\n",
      "no improvement for 3/100 epochs\n",
      "\n",
      "→ Starting epoch 82  (printing every 172 iters)\n",
      "[Epoch 82] iter 172/172, avg loss: 0.0092\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QS4332S                   | QS4332S                   | 0.9785\n",
      "QAK!8791                  | QAK!8791                  | 0.9988\n",
      "PPH8262                   | PPH8262                   | 0.9909\n",
      "SB!6436D                  | SB!6436D                  | 0.9823\n",
      "BJF5469                   | BJF5469                   | 0.9950\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 82 done in 11.4s | train_loss=0.0092  valid_loss=0.3890  valid_acc=77.55%\n",
      "\n",
      "no improvement for 4/100 epochs\n",
      "\n",
      "→ Starting epoch 83  (printing every 172 iters)\n",
      "[Epoch 83] iter 172/172, avg loss: 0.0088\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WWN1840                   | WWN1840                   | 0.9915\n",
      "QCN1432                   | QCN1432                   | 0.9818\n",
      "WPH!317                   | WPH!317                   | 0.9762\n",
      "QAA8530N                  | QAA8530N                  | 0.9754\n",
      "QPC7622                   | QPC7622                   | 0.9857\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 83 done in 11.1s | train_loss=0.0088  valid_loss=0.3652  valid_acc=79.01%\n",
      "\n",
      "no improvement for 5/100 epochs\n",
      "\n",
      "→ Starting epoch 84  (printing every 172 iters)\n",
      "[Epoch 84] iter 172/172, avg loss: 0.0068\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QPA3382                   | QPA3382                   | 0.9997\n",
      "QSV1707                   | QSV1707                   | 0.9834\n",
      "WSM1382                   | WSM1382                   | 0.9692\n",
      "NBW7154                   | NBW7154                   | 0.9961\n",
      "QSY!27                    | QSY!27                    | 0.9666\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 84 done in 11.2s | train_loss=0.0068  valid_loss=0.3742  valid_acc=78.72%\n",
      "\n",
      "no improvement for 6/100 epochs\n",
      "\n",
      "→ Starting epoch 85  (printing every 172 iters)\n",
      "[Epoch 85] iter 172/172, avg loss: 0.0060\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAX!2076                  | QAX!2076                  | 0.9914\n",
      "WFK2926                   | WFK2926                   | 0.9991\n",
      "JKN8193                   | JKN8193                   | 0.9904\n",
      "QAA!9328G                 | QAA!9328G                 | 0.9677\n",
      "MDH7007                   | MDH7007                   | 0.9808\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 85 done in 11.2s | train_loss=0.0060  valid_loss=0.3552  valid_acc=78.72%\n",
      "\n",
      "no improvement for 7/100 epochs\n",
      "\n",
      "→ Starting epoch 86  (printing every 172 iters)\n",
      "[Epoch 86] iter 172/172, avg loss: 0.0103\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAA5191E                  | QAA5191E                  | 0.9958\n",
      "KEG!9999                  | KEG!9999                  | 0.9873\n",
      "QAA8801X                  | QAA8801X                  | 0.9580\n",
      "QCD!2889                  | QCD!2889                  | 0.9943\n",
      "QM1252K                   | QM1252K                   | 0.9561\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 86 done in 11.2s | train_loss=0.0103  valid_loss=0.4206  valid_acc=79.30%\n",
      "\n",
      "no improvement for 8/100 epochs\n",
      "\n",
      "→ Starting epoch 87  (printing every 172 iters)\n",
      "[Epoch 87] iter 172/172, avg loss: 0.0083\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WDK4927                   | WDL4927                   | 0.9690\n",
      "QCN8327                   | QCN8327                   | 0.9978\n",
      "SWK426                    | SWK426                    | 0.9910\n",
      "W3426P                    | W3426P                    | 0.9950\n",
      "MW2567                    | MW2567                    | 0.9798\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 87 done in 11.1s | train_loss=0.0083  valid_loss=0.3219  valid_acc=80.76%\n",
      "\n",
      "no improvement for 9/100 epochs\n",
      "\n",
      "→ Starting epoch 88  (printing every 172 iters)\n",
      "[Epoch 88] iter 172/172, avg loss: 0.0041\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VGF!2972                  | VGF!2972                  | 0.9685\n",
      "VJG3205                   | VJG3205                   | 0.9872\n",
      "WTB6269                   | WTB6269                   | 0.9931\n",
      "AKF!4463                  | AKF!4463                  | 0.9936\n",
      "AMQ!868                   | AMQ!868                   | 0.9769\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 88 done in 11.1s | train_loss=0.0041  valid_loss=0.3662  valid_acc=79.88%\n",
      "\n",
      "no improvement for 10/100 epochs\n",
      "\n",
      "→ Starting epoch 89  (printing every 172 iters)\n",
      "[Epoch 89] iter 172/172, avg loss: 0.0043\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAD6086                   | QAD6086                   | 0.9843\n",
      "QMW!65                    | QMW!65                    | 0.9943\n",
      "VBY8203                   | VBY8203                   | 0.9766\n",
      "QKP3696                   | QKP3696                   | 0.9912\n",
      "JLX!6457                  | JLX!6457                  | 0.9920\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 89 done in 11.1s | train_loss=0.0043  valid_loss=0.3266  valid_acc=80.47%\n",
      "\n",
      "no improvement for 11/100 epochs\n",
      "\n",
      "→ Starting epoch 90  (printing every 172 iters)\n",
      "[Epoch 90] iter 172/172, avg loss: 0.0053\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "AKK!4491                  | AKK!4491                  | 0.9909\n",
      "VX2808                    | VX2808                    | 0.9833\n",
      "BQL!4682                  | BQL!4682                  | 0.9690\n",
      "ANU7888                   | ANU7888                   | 0.9922\n",
      "NDN4403                   | NDN4403                   | 0.9922\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 90 done in 11.1s | train_loss=0.0053  valid_loss=0.3552  valid_acc=79.88%\n",
      "\n",
      "no improvement for 12/100 epochs\n",
      "\n",
      "→ Starting epoch 91  (printing every 172 iters)\n",
      "[Epoch 91] iter 172/172, avg loss: 0.0040\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QM9779R                   | QM9779R                   | 0.9976\n",
      "MBP8122                   | MBP8122                   | 0.9923\n",
      "ADU7533                   | ADU7533                   | 0.9760\n",
      "W8723V                    | W8723V                    | 0.9783\n",
      "QCE3983                   | QCE3983                   | 0.9836\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 91 done in 11.3s | train_loss=0.0040  valid_loss=0.3813  valid_acc=79.59%\n",
      "\n",
      "no improvement for 13/100 epochs\n",
      "\n",
      "→ Starting epoch 92  (printing every 172 iters)\n",
      "[Epoch 92] iter 172/172, avg loss: 0.0035\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "AMR1971                   | AMR1971                   | 0.9783\n",
      "MAG!7025                  | MAG!7025                  | 0.9727\n",
      "BSE!6665                  | BSE!6665                  | 0.9943\n",
      "PGL2189                   | PGL2189                   | 0.9762\n",
      "JLC!8890                  | JLC!8890                  | 0.9569\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 92 done in 11.3s | train_loss=0.0035  valid_loss=0.3377  valid_acc=80.76%\n",
      "\n",
      "no improvement for 14/100 epochs\n",
      "\n",
      "→ Starting epoch 93  (printing every 172 iters)\n",
      "[Epoch 93] iter 172/172, avg loss: 0.0041\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QCJ5838                   | QCJ5838                   | 0.9905\n",
      "QBC!4734                  | QBC!4734                  | 0.9669\n",
      "KDC!4153                  | KDC!4153                  | 0.9812\n",
      "SJG7119                   | SJG7119                   | 0.9812\n",
      "JVH9798                   | JVH9798                   | 0.9975\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 93 done in 11.2s | train_loss=0.0041  valid_loss=0.3113  valid_acc=81.63%\n",
      "\n",
      "💾 New best model saved (epoch 93, val_acc=81.63%)\n",
      "\n",
      "→ Starting epoch 94  (printing every 172 iters)\n",
      "[Epoch 94] iter 172/172, avg loss: 0.0051\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "DFC7000                   | DFC7000                   | 0.9952\n",
      "WNH553                    | WNH553                    | 0.9680\n",
      "PLT2670                   | PLT2670                   | 0.9871\n",
      "PDT3803                   | PDT3803                   | 0.9978\n",
      "QAT!6517                  | QAT!6517                  | 0.9991\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 94 done in 11.2s | train_loss=0.0051  valid_loss=0.3207  valid_acc=83.09%\n",
      "\n",
      "💾 New best model saved (epoch 94, val_acc=83.09%)\n",
      "\n",
      "→ Starting epoch 95  (printing every 172 iters)\n",
      "[Epoch 95] iter 172/172, avg loss: 0.0047\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAB9668H                  | QAB9668H                  | 0.9940\n",
      "DFD3000                   | DFD3000                   | 0.9773\n",
      "QB97                      | QB97                      | 0.9746\n",
      "WMX9993                   | WMX9993                   | 0.9801\n",
      "QRT!9620                  | QRT!9620                  | 0.9829\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 95 done in 11.4s | train_loss=0.0047  valid_loss=0.3269  valid_acc=80.47%\n",
      "\n",
      "no improvement for 1/100 epochs\n",
      "\n",
      "→ Starting epoch 96  (printing every 172 iters)\n",
      "[Epoch 96] iter 172/172, avg loss: 0.0027\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "TCJ!8981                  | TCJ!8981                  | 0.9764\n",
      "QS110D                    | QS110D                    | 0.9827\n",
      "PMV4916                   | PMV4916                   | 0.9844\n",
      "BRK!9118                  | BRK!9118                  | 0.9382\n",
      "QAA514K                   | QAA514K                   | 0.9687\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 96 done in 11.2s | train_loss=0.0027  valid_loss=0.3453  valid_acc=79.59%\n",
      "\n",
      "no improvement for 2/100 epochs\n",
      "\n",
      "→ Starting epoch 97  (printing every 172 iters)\n",
      "[Epoch 97] iter 172/172, avg loss: 0.0023\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QCN1432                   | QCN1432                   | 0.9913\n",
      "WYL2575                   | WYL2575                   | 0.9878\n",
      "VK1800                    | VK1800                    | 0.9643\n",
      "VFS9098                   | VFS9098                   | 0.9818\n",
      "RS6069                    | RS6069                    | 0.9797\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 97 done in 10.8s | train_loss=0.0023  valid_loss=0.3419  valid_acc=81.05%\n",
      "\n",
      "no improvement for 3/100 epochs\n",
      "\n",
      "→ Starting epoch 98  (printing every 172 iters)\n",
      "[Epoch 98] iter 172/172, avg loss: 0.0030\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAA1918D                  | QAA1918D                  | 0.9910\n",
      "QKM5112                   | QKM5112                   | 0.9962\n",
      "VAV2292                   | VAV2292                   | 0.9766\n",
      "QAB!2874D                 | QAB!2874D                 | 0.9858\n",
      "KD!6868Q                  | KD!6868Q                  | 0.9551\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 98 done in 10.8s | train_loss=0.0030  valid_loss=0.3395  valid_acc=79.88%\n",
      "\n",
      "no improvement for 4/100 epochs\n",
      "\n",
      "→ Starting epoch 99  (printing every 172 iters)\n",
      "[Epoch 99] iter 172/172, avg loss: 0.0053\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "BNW5508                   | BNW5508                   | 0.9955\n",
      "VJ5725                    | VJ5725                    | 0.9919\n",
      "QKF!8656                  | QKF!8656                  | 0.9531\n",
      "VET8129                   | VET8129                   | 0.9995\n",
      "QKT8216                   | QKT8216                   | 0.9924\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 99 done in 10.5s | train_loss=0.0053  valid_loss=0.3484  valid_acc=80.17%\n",
      "\n",
      "no improvement for 5/100 epochs\n",
      "\n",
      "→ Starting epoch 100  (printing every 172 iters)\n",
      "[Epoch 100] iter 172/172, avg loss: 0.0065\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WUW1704                   | WUW1704                   | 0.9872\n",
      "QBC!666                   | QBC!666                   | 0.9883\n",
      "UMT6556                   | UMT6556                   | 0.9950\n",
      "VNN!4620                  | VNN!4620                  | 0.9755\n",
      "SD288V                    | SD288V                    | 0.9771\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 100 done in 10.6s | train_loss=0.0065  valid_loss=0.3458  valid_acc=79.88%\n",
      "\n",
      "no improvement for 6/100 epochs\n",
      "\n",
      "→ Starting epoch 101  (printing every 172 iters)\n",
      "[Epoch 101] iter 172/172, avg loss: 0.0048\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "BRT6112                   | BRT6112                   | 0.9957\n",
      "VFN!701                   | VFN!701                   | 0.9324\n",
      "SD2367N                   | SD2367N                   | 0.9924\n",
      "JUJ!7630                  | JUJ!7630                  | 0.9982\n",
      "VGT9721                   | VGT9721                   | 0.9940\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 101 done in 11.0s | train_loss=0.0048  valid_loss=0.3623  valid_acc=78.72%\n",
      "\n",
      "no improvement for 7/100 epochs\n",
      "\n",
      "→ Starting epoch 102  (printing every 172 iters)\n",
      "[Epoch 102] iter 172/172, avg loss: 0.0031\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VCG8451                   | VCG8451                   | 0.9995\n",
      "JVB!7580                  | JVB!7580                  | 0.9785\n",
      "QRB8366                   | QRB8366                   | 0.9967\n",
      "ALN!8722                  | ALN!8722                  | 0.9597\n",
      "RAQ!7877                  | RAQ!7877                  | 0.9706\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 102 done in 10.9s | train_loss=0.0031  valid_loss=0.4011  valid_acc=78.43%\n",
      "\n",
      "no improvement for 8/100 epochs\n",
      "\n",
      "→ Starting epoch 103  (printing every 172 iters)\n",
      "[Epoch 103] iter 172/172, avg loss: 0.0048\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "9222H                     | 9222H                     | 0.9936\n",
      "ADU7533                   | ADU7533                   | 0.9929\n",
      "WLC9954                   | WLC9954                   | 0.9910\n",
      "PQS5137                   | PQS5137                   | 0.9776\n",
      "QS5039N                   | QS5039N                   | 0.9750\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 103 done in 10.9s | train_loss=0.0048  valid_loss=0.3646  valid_acc=78.43%\n",
      "\n",
      "no improvement for 9/100 epochs\n",
      "\n",
      "→ Starting epoch 104  (printing every 172 iters)\n",
      "[Epoch 104] iter 172/172, avg loss: 0.0082\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "JXP!4469                  | JXP!4469                  | 0.9871\n",
      "VGX!8413                  | VGX!8413                  | 0.9585\n",
      "KFW2299                   | KFW2299                   | 0.9967\n",
      "VJE3434                   | VJE3434                   | 0.9826\n",
      "QBA6681                   | QBA6681                   | 0.9867\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 104 done in 11.3s | train_loss=0.0082  valid_loss=0.3940  valid_acc=76.09%\n",
      "\n",
      "no improvement for 10/100 epochs\n",
      "\n",
      "→ Starting epoch 105  (printing every 172 iters)\n",
      "[Epoch 105] iter 172/172, avg loss: 0.0091\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WUS4781                   | WUS4781                   | 0.9996\n",
      "T/BD!8333                 | T/BD!8333                 | 0.9759\n",
      "MAL!2861                  | MAL!2861                  | 0.9987\n",
      "VEN634                    | VEN634                    | 0.9837\n",
      "QAB1879C                  | QAB1879C                  | 0.9740\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 105 done in 11.1s | train_loss=0.0091  valid_loss=0.3483  valid_acc=78.43%\n",
      "\n",
      "no improvement for 11/100 epochs\n",
      "\n",
      "→ Starting epoch 106  (printing every 172 iters)\n",
      "[Epoch 106] iter 172/172, avg loss: 0.0042\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "HQ2186                    | HQ2186                    | 0.9821\n",
      "JQL3221                   | JQL3221                   | 0.9978\n",
      "RU8892                    | RU8892                    | 0.9995\n",
      "WC4922X                   | WC4922X                   | 0.9715\n",
      "SJG7119                   | SJG7119                   | 0.9984\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 106 done in 11.1s | train_loss=0.0042  valid_loss=0.3707  valid_acc=79.88%\n",
      "\n",
      "no improvement for 12/100 epochs\n",
      "\n",
      "→ Starting epoch 107  (printing every 172 iters)\n",
      "[Epoch 107] iter 172/172, avg loss: 0.0039\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WWL9209                   | WWL9209                   | 0.9925\n",
      "RW9634                    | RW9634                    | 0.9942\n",
      "JUK!276                   | JUK!276                   | 0.9812\n",
      "TCC!1724                  | TCC!1724                  | 0.9849\n",
      "QAM1008                   | QAM1008                   | 0.9943\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 107 done in 11.3s | train_loss=0.0039  valid_loss=0.3406  valid_acc=80.76%\n",
      "\n",
      "no improvement for 13/100 epochs\n",
      "\n",
      "→ Starting epoch 108  (printing every 172 iters)\n",
      "[Epoch 108] iter 172/172, avg loss: 0.0036\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "JFR4363                   | JFR4363                   | 0.9906\n",
      "JKC7100                   | JKC7100                   | 0.9988\n",
      "JWW9278                   | JWW9278                   | 0.9921\n",
      "QM!5826G                  | QM!5826G                  | 0.9709\n",
      "QLD2696                   | QLD2696                   | 0.9789\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 108 done in 11.4s | train_loss=0.0036  valid_loss=0.3660  valid_acc=82.80%\n",
      "\n",
      "no improvement for 14/100 epochs\n",
      "\n",
      "→ Starting epoch 109  (printing every 172 iters)\n",
      "[Epoch 109] iter 172/172, avg loss: 0.0059\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "JMW!7452                  | JMW!7452                  | 0.9732\n",
      "KFW2299                   | KFW2299                   | 0.9855\n",
      "QMR!7691                  | QMR!7691                  | 0.9994\n",
      "VKD9603                   | VKD9603                   | 0.9969\n",
      "KED9988                   | KED9988                   | 0.9993\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 109 done in 11.3s | train_loss=0.0059  valid_loss=0.3216  valid_acc=80.47%\n",
      "\n",
      "no improvement for 15/100 epochs\n",
      "\n",
      "→ Starting epoch 110  (printing every 172 iters)\n",
      "[Epoch 110] iter 172/172, avg loss: 0.0057\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WFS7393                   | WFS7393                   | 0.9986\n",
      "NDD6299                   | NDD6299                   | 0.9851\n",
      "JJT5762                   | JJT5762                   | 0.9831\n",
      "BML1717                   | BML1717                   | 0.9967\n",
      "W763L                     | W763L                     | 0.9691\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 110 done in 11.4s | train_loss=0.0057  valid_loss=0.3426  valid_acc=80.47%\n",
      "\n",
      "no improvement for 16/100 epochs\n",
      "\n",
      "→ Starting epoch 111  (printing every 172 iters)\n",
      "[Epoch 111] iter 172/172, avg loss: 0.0031\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "TBE9333                   | TBE9333                   | 0.9966\n",
      "JSF2692                   | JSF2692                   | 0.9990\n",
      "QM2377M                   | QM2377M                   | 0.9825\n",
      "QCH2778                   | QCH2778                   | 0.9829\n",
      "QAA7943Q                  | QAA7943Q                  | 0.9858\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 111 done in 11.4s | train_loss=0.0031  valid_loss=0.3444  valid_acc=80.17%\n",
      "\n",
      "no improvement for 17/100 epochs\n",
      "\n",
      "→ Starting epoch 112  (printing every 172 iters)\n",
      "[Epoch 112] iter 172/172, avg loss: 0.0026\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "PKA!440                   | PKA!440                   | 0.9481\n",
      "AKK!4491                  | AKK!4491                  | 0.9924\n",
      "QS!6618B                  | QS!6618B                  | 0.9474\n",
      "LH9996                    | LH9996                    | 0.9831\n",
      "QAB371C                   | QAB371C                   | 0.9815\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 112 done in 11.3s | train_loss=0.0026  valid_loss=0.3657  valid_acc=82.80%\n",
      "\n",
      "no improvement for 18/100 epochs\n",
      "\n",
      "→ Starting epoch 113  (printing every 172 iters)\n",
      "[Epoch 113] iter 172/172, avg loss: 0.0023\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "AHY9330                   | AHY9330                   | 0.9948\n",
      "AMR9464                   | AMR9464                   | 0.9887\n",
      "VKS9371                   | VKS9371                   | 0.9796\n",
      "QBD9519                   | QBD9519                   | 0.9840\n",
      "VNG!8061                  | VNG!8061                  | 0.9944\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 113 done in 11.1s | train_loss=0.0023  valid_loss=0.4049  valid_acc=81.05%\n",
      "\n",
      "no improvement for 19/100 epochs\n",
      "\n",
      "→ Starting epoch 114  (printing every 172 iters)\n",
      "[Epoch 114] iter 172/172, avg loss: 0.0032\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "NBV6243                   | NBV6243                   | 0.9996\n",
      "WXA7223                   | WXA7223                   | 0.9882\n",
      "QMY4519                   | QMY4519                   | 0.9833\n",
      "SYX3611                   | SYX3611                   | 0.9999\n",
      "VBQ!7144                  | VBQ!7144                  | 0.9533\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 114 done in 11.4s | train_loss=0.0032  valid_loss=0.4022  valid_acc=80.47%\n",
      "\n",
      "no improvement for 20/100 epochs\n",
      "\n",
      "→ Starting epoch 115  (printing every 172 iters)\n",
      "[Epoch 115] iter 172/172, avg loss: 0.0048\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "AMT5830                   | AMT5830                   | 0.9884\n",
      "WAW8593                   | WAW8593                   | 0.9761\n",
      "1M4U3172                  | 1M4U3172                  | 0.9618\n",
      "MDJ50                     | MDJ50                     | 0.9997\n",
      "WFR9497                   | WFR9497                   | 0.9975\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 115 done in 11.1s | train_loss=0.0048  valid_loss=0.4268  valid_acc=81.34%\n",
      "\n",
      "no improvement for 21/100 epochs\n",
      "\n",
      "→ Starting epoch 116  (printing every 172 iters)\n",
      "[Epoch 116] iter 172/172, avg loss: 0.0027\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "TCF8978                   | TCF8978                   | 0.9992\n",
      "T/JA7639                  | T/JA7639                  | 0.9934\n",
      "QAP6228                   | QAP6228                   | 0.9968\n",
      "CAW!3857                  | CAW!3857                  | 0.9763\n",
      "KAX1199                   | KAX1199                   | 0.9825\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 116 done in 11.4s | train_loss=0.0027  valid_loss=0.3757  valid_acc=81.34%\n",
      "\n",
      "no improvement for 22/100 epochs\n",
      "\n",
      "→ Starting epoch 117  (printing every 172 iters)\n",
      "[Epoch 117] iter 172/172, avg loss: 0.0031\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QA                        | QA                        | 0.9996\n",
      "WB6577N                   | WB6577N                   | 0.9795\n",
      "QLE5536                   | QLE5536                   | 0.9940\n",
      "MDP!3394                  | MDP!3394                  | 0.9999\n",
      "PNU58                     | PNU58                     | 0.9998\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 117 done in 11.3s | train_loss=0.0031  valid_loss=0.3634  valid_acc=81.05%\n",
      "\n",
      "no improvement for 23/100 epochs\n",
      "\n",
      "→ Starting epoch 118  (printing every 172 iters)\n",
      "[Epoch 118] iter 172/172, avg loss: 0.0086\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WNC8559                   | WNC8559                   | 0.9947\n",
      "QS3284P                   | QS3284P                   | 0.9421\n",
      "T/D1673                   | T/D1673                   | 0.9982\n",
      "WTQ3638                   | WTQ3638                   | 0.9967\n",
      "AHU7727                   | AHU7727                   | 0.9827\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 118 done in 11.8s | train_loss=0.0086  valid_loss=0.4345  valid_acc=80.17%\n",
      "\n",
      "no improvement for 24/100 epochs\n",
      "\n",
      "→ Starting epoch 119  (printing every 172 iters)\n",
      "[Epoch 119] iter 172/172, avg loss: 0.0114\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WWM4401                   | WWM4401                   | 0.9936\n",
      "QS8621R                   | QS8621R                   | 0.9788\n",
      "QAB7401J                  | QAB7401J                  | 0.9922\n",
      "PZ171M                    | PZ171M                    | 0.9981\n",
      "BLG7607                   | BLG7607                   | 0.9982\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 119 done in 12.0s | train_loss=0.0114  valid_loss=0.4694  valid_acc=76.38%\n",
      "\n",
      "no improvement for 25/100 epochs\n",
      "\n",
      "→ Starting epoch 120  (printing every 172 iters)\n",
      "[Epoch 120] iter 172/172, avg loss: 0.0092\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QM9779R                   | QM9779R                   | 0.9979\n",
      "QLD2696                   | QLD2696                   | 0.9994\n",
      "WB!302Q                   | WB!302Q                   | 0.9592\n",
      "QMR!7691                  | QMR!7691                  | 0.9981\n",
      "QS1016K                   | QS1016K                   | 0.9912\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 120 done in 10.8s | train_loss=0.0092  valid_loss=0.4305  valid_acc=76.97%\n",
      "\n",
      "no improvement for 26/100 epochs\n",
      "\n",
      "→ Starting epoch 121  (printing every 172 iters)\n",
      "[Epoch 121] iter 172/172, avg loss: 0.0071\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "KAK2779                   | KAK2779                   | 0.9933\n",
      "VAQ2618                   | VAQ2618                   | 0.9955\n",
      "DCS8812                   | DCS8812                   | 0.9923\n",
      "AMX9168                   | AMX9168                   | 0.9996\n",
      "AKK!4491                  | AKK!4491                  | 0.9640\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 121 done in 10.8s | train_loss=0.0071  valid_loss=0.3423  valid_acc=79.88%\n",
      "\n",
      "no improvement for 27/100 epochs\n",
      "\n",
      "→ Starting epoch 122  (printing every 172 iters)\n",
      "[Epoch 122] iter 172/172, avg loss: 0.0143\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "PLM!1311                  | PLM!1311                  | 0.9630\n",
      "QS!8781R                  | QS!8781R                  | 0.9453\n",
      "VJA1759                   | VJA1759                   | 0.9780\n",
      "QSP!5188                  | QSP!5188                  | 0.9802\n",
      "QS6811S                   | QS6811S                   | 0.9961\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 122 done in 11.1s | train_loss=0.0143  valid_loss=0.3926  valid_acc=76.09%\n",
      "\n",
      "no improvement for 28/100 epochs\n",
      "\n",
      "→ Starting epoch 123  (printing every 172 iters)\n",
      "[Epoch 123] iter 172/172, avg loss: 0.0073\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "PPS3833                   | PPS3833                   | 0.9923\n",
      "BNG!7865                  | BNG!7865                  | 0.9926\n",
      "TTB1838                   | TTB1838                   | 0.9711\n",
      "WYV3365                   | WYV3365                   | 0.9772\n",
      "FE3433                    | FE3433                    | 0.9937\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 123 done in 11.0s | train_loss=0.0073  valid_loss=0.3850  valid_acc=77.26%\n",
      "\n",
      "no improvement for 29/100 epochs\n",
      "\n",
      "→ Starting epoch 124  (printing every 172 iters)\n",
      "[Epoch 124] iter 172/172, avg loss: 0.0062\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QTU!5007                  | QTU!5007                  | 0.9981\n",
      "QAA9552A                  | QAA9552A                  | 0.9734\n",
      "WDJ9407                   | WDJ9407                   | 0.9873\n",
      "QAA8801X                  | QAA8801X                  | 0.9982\n",
      "QS110D                    | QS110D                    | 0.9925\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 124 done in 10.8s | train_loss=0.0062  valid_loss=0.3564  valid_acc=79.30%\n",
      "\n",
      "no improvement for 30/100 epochs\n",
      "\n",
      "→ Starting epoch 125  (printing every 172 iters)\n",
      "[Epoch 125] iter 172/172, avg loss: 0.0043\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAP6228                   | QAP6228                   | 0.9864\n",
      "QAW2391                   | QAW2391                   | 0.9992\n",
      "BRK!9118                  | BRK!9118                  | 0.9626\n",
      "NCD8456                   | NCD8456                   | 0.9882\n",
      "QCP9736                   | QCP9736                   | 0.9989\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 125 done in 11.1s | train_loss=0.0043  valid_loss=0.3658  valid_acc=76.97%\n",
      "\n",
      "no improvement for 31/100 epochs\n",
      "\n",
      "→ Starting epoch 126  (printing every 172 iters)\n",
      "[Epoch 126] iter 172/172, avg loss: 0.0033\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WB!302Q                   | WB!302Q                   | 0.9273\n",
      "QKU7969                   | QKU7969                   | 0.9941\n",
      "QAA8598S                  | QAA8598S                  | 0.9806\n",
      "PMT5916                   | PMT5916                   | 0.9932\n",
      "W3328Q                    | W3328Q                    | 0.9799\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 126 done in 11.0s | train_loss=0.0033  valid_loss=0.4426  valid_acc=77.55%\n",
      "\n",
      "no improvement for 32/100 epochs\n",
      "\n",
      "→ Starting epoch 127  (printing every 172 iters)\n",
      "[Epoch 127] iter 172/172, avg loss: 0.0040\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QTN3878                   | QTN3878                   | 0.9937\n",
      "ANU7888                   | ANU7888                   | 0.9864\n",
      "DR4467                    | DR4467                    | 0.9800\n",
      "WB!8444L                  | WB!8444L                  | 0.9695\n",
      "W3328Q                    | W3328Q                    | 0.9935\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 127 done in 10.7s | train_loss=0.0040  valid_loss=0.3527  valid_acc=78.72%\n",
      "\n",
      "no improvement for 33/100 epochs\n",
      "\n",
      "→ Starting epoch 128  (printing every 172 iters)\n",
      "[Epoch 128] iter 172/172, avg loss: 0.0054\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QCH9191                   | QCH9191                   | 0.9766\n",
      "PNU58                     | PNU58                     | 0.9963\n",
      "VMP2929                   | VMP2929                   | 0.9677\n",
      "VJE3434                   | VJE3434                   | 0.9881\n",
      "VEH!6204                  | VEH!6204                  | 0.9491\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 128 done in 11.0s | train_loss=0.0054  valid_loss=0.3419  valid_acc=79.01%\n",
      "\n",
      "no improvement for 34/100 epochs\n",
      "\n",
      "→ Starting epoch 129  (printing every 172 iters)\n",
      "[Epoch 129] iter 172/172, avg loss: 0.0106\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VDL7317                   | VDL7317                   | 0.9812\n",
      "NBW7154                   | NBW7154                   | 0.9948\n",
      "BRA2127                   | BRA2127                   | 0.9850\n",
      "ALC!3644                  | ALC!3644                  | 0.9970\n",
      "AHA3878                   | AHA3878                   | 0.9947\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 129 done in 11.0s | train_loss=0.0106  valid_loss=0.3775  valid_acc=79.01%\n",
      "\n",
      "no improvement for 35/100 epochs\n",
      "\n",
      "→ Starting epoch 130  (printing every 172 iters)\n",
      "[Epoch 130] iter 172/172, avg loss: 0.0135\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QKW3360                   | QKW3360                   | 0.9780\n",
      "BHS5465                   | BHS5465                   | 0.9922\n",
      "BJF5469                   | BJF5469                   | 0.9996\n",
      "JWW9278                   | JWW9278                   | 0.9991\n",
      "BNW!2744                  | BNW!2744                  | 0.9735\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 130 done in 10.7s | train_loss=0.0135  valid_loss=0.3716  valid_acc=77.26%\n",
      "\n",
      "no improvement for 36/100 epochs\n",
      "\n",
      "→ Starting epoch 131  (printing every 172 iters)\n",
      "[Epoch 131] iter 172/172, avg loss: 0.0050\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "BLR!9830                  | BLR!9830                  | 0.9665\n",
      "QD1811                    | QD1811                    | 0.9947\n",
      "KW!655                    | KW!655                    | 0.9415\n",
      "QKU7969                   | QKU7969                   | 0.9989\n",
      "QLB8533                   | QLB8533                   | 0.9977\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 131 done in 11.1s | train_loss=0.0050  valid_loss=0.3753  valid_acc=78.72%\n",
      "\n",
      "no improvement for 37/100 epochs\n",
      "\n",
      "→ Starting epoch 132  (printing every 172 iters)\n",
      "[Epoch 132] iter 172/172, avg loss: 0.0049\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "BMQ705                    | BMQ705                    | 0.9736\n",
      "QCS8636                   | QCS8636                   | 0.9838\n",
      "QKT8216                   | QKT8811                   | 0.9363\n",
      "JSD809                    | JSD809                    | 0.9888\n",
      "BMU7190                   | BMU7190                   | 0.9882\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 132 done in 10.8s | train_loss=0.0049  valid_loss=0.3741  valid_acc=79.30%\n",
      "\n",
      "no improvement for 38/100 epochs\n",
      "\n",
      "→ Starting epoch 133  (printing every 172 iters)\n",
      "[Epoch 133] iter 172/172, avg loss: 0.0061\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "PJS1739                   | PJS1739                   | 0.9967\n",
      "VMP2929                   | VMP2929                   | 0.9831\n",
      "SAC!8630E                 | SAC!8630E                 | 0.9612\n",
      "QS4332S                   | QS4332S                   | 0.9783\n",
      "JVH9798                   | JVH9798                   | 0.9822\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 133 done in 10.7s | train_loss=0.0061  valid_loss=0.3414  valid_acc=79.88%\n",
      "\n",
      "no improvement for 39/100 epochs\n",
      "\n",
      "→ Starting epoch 134  (printing every 172 iters)\n",
      "[Epoch 134] iter 172/172, avg loss: 0.0047\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "JLY2201                   | JLY2201                   | 0.9984\n",
      "QKV465                    | QKV465                    | 0.9964\n",
      "QAN7517                   | QAN7517                   | 0.9952\n",
      "VAH!7666                  | VAH!7666                  | 0.9895\n",
      "BNY!4363                  | BNY!4363                  | 0.9974\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 134 done in 11.0s | train_loss=0.0047  valid_loss=0.3643  valid_acc=79.30%\n",
      "\n",
      "no improvement for 40/100 epochs\n",
      "\n",
      "→ Starting epoch 135  (printing every 172 iters)\n",
      "[Epoch 135] iter 172/172, avg loss: 0.0034\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VCV3619                   | VCV3619                   | 0.9985\n",
      "VGF!2972                  | VGF!2972                  | 0.9831\n",
      "QCM2915                   | QCM2915                   | 0.9985\n",
      "NDL7330                   | NDL7330                   | 0.9968\n",
      "CEW!485                   | CEW!485                   | 0.9991\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 135 done in 10.9s | train_loss=0.0034  valid_loss=0.3384  valid_acc=80.47%\n",
      "\n",
      "no improvement for 41/100 epochs\n",
      "\n",
      "→ Starting epoch 136  (printing every 172 iters)\n",
      "[Epoch 136] iter 172/172, avg loss: 0.0027\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WNH553                    | WNH553                    | 0.9869\n",
      "PPK9573                   | PPK9573                   | 0.9945\n",
      "T/BB2347                  | T/BB2347                  | 0.9998\n",
      "QAA6780D                  | QAA6780D                  | 0.9789\n",
      "VGL5629                   | VGL5629                   | 0.9893\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 136 done in 10.7s | train_loss=0.0027  valid_loss=0.3220  valid_acc=81.05%\n",
      "\n",
      "no improvement for 42/100 epochs\n",
      "\n",
      "→ Starting epoch 137  (printing every 172 iters)\n",
      "[Epoch 137] iter 172/172, avg loss: 0.0029\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAB859J                   | QAB859J                   | 0.9816\n",
      "QBC!666                   | QBC!666                   | 0.9887\n",
      "T/BF!6897                 | T/BF!6897                 | 0.9772\n",
      "JWJ!7952                  | JWJ!7952                  | 0.9921\n",
      "QAB401E                   | QAB401E                   | 0.9760\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 137 done in 10.9s | train_loss=0.0029  valid_loss=0.3743  valid_acc=80.17%\n",
      "\n",
      "no improvement for 43/100 epochs\n",
      "\n",
      "→ Starting epoch 138  (printing every 172 iters)\n",
      "[Epoch 138] iter 172/172, avg loss: 0.0018\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "MDV1999                   | MDV1999                   | 0.9530\n",
      "QAD!5337                  | QAD!5337                  | 0.9820\n",
      "JRG2793                   | JRG2793                   | 0.9974\n",
      "T/M3041                   | T/M3041                   | 0.9945\n",
      "QAA8598S                  | QAA8598S                  | 0.9682\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 138 done in 11.0s | train_loss=0.0018  valid_loss=0.3374  valid_acc=81.05%\n",
      "\n",
      "no improvement for 44/100 epochs\n",
      "\n",
      "→ Starting epoch 139  (printing every 172 iters)\n",
      "[Epoch 139] iter 172/172, avg loss: 0.0088\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "MCR5505                   | MCR5505                   | 0.9964\n",
      "QLC5323                   | QLC5323                   | 0.9832\n",
      "W!2547C                   | W!2547C                   | 0.8973\n",
      "PC1811P                   | PC1811P                   | 0.9751\n",
      "QAM6622                   | QAM6622                   | 0.9932\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 139 done in 10.8s | train_loss=0.0088  valid_loss=0.3732  valid_acc=77.26%\n",
      "\n",
      "no improvement for 45/100 epochs\n",
      "\n",
      "→ Starting epoch 140  (printing every 172 iters)\n",
      "[Epoch 140] iter 172/172, avg loss: 0.0056\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "DFC7000                   | DFC7000                   | 0.9934\n",
      "QAA2660J                  | QAA2660J                  | 0.9939\n",
      "QAQ1011                   | QAQ1011                   | 0.9868\n",
      "SA24M                     | SA24M                     | 0.9926\n",
      "KDH!2309                  | KDH!2309                  | 0.9985\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 140 done in 10.8s | train_loss=0.0056  valid_loss=0.3787  valid_acc=79.30%\n",
      "\n",
      "no improvement for 46/100 epochs\n",
      "\n",
      "→ Starting epoch 141  (printing every 172 iters)\n",
      "[Epoch 141] iter 172/172, avg loss: 0.0023\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QKM70                     | QKM70                     | 0.9986\n",
      "JPA!501                   | JPA!501                   | 0.9914\n",
      "TCN!8474                  | TCN!8474                  | 0.9629\n",
      "VKS!4174                  | VKS!4174                  | 0.9988\n",
      "QSP!5188                  | QSP!5188                  | 0.9988\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 141 done in 10.9s | train_loss=0.0023  valid_loss=0.3655  valid_acc=82.22%\n",
      "\n",
      "no improvement for 47/100 epochs\n",
      "\n",
      "→ Starting epoch 142  (printing every 172 iters)\n",
      "[Epoch 142] iter 172/172, avg loss: 0.0022\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QMS9397                   | QMS9397                   | 0.9988\n",
      "QCR2338                   | QCR2338                   | 0.9997\n",
      "PMU3220                   | PMU3220                   | 0.9989\n",
      "JKN8193                   | JKN8193                   | 0.9997\n",
      "BNG7883                   | BNG7883                   | 0.9625\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 142 done in 10.8s | train_loss=0.0022  valid_loss=0.3611  valid_acc=81.92%\n",
      "\n",
      "no improvement for 48/100 epochs\n",
      "\n",
      "→ Starting epoch 143  (printing every 172 iters)\n",
      "[Epoch 143] iter 172/172, avg loss: 0.0026\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QMW7697                   | QMW7697                   | 0.9989\n",
      "VAW4421                   | VAW4421                   | 0.9887\n",
      "VEN634                    | VEN634                    | 0.9981\n",
      "RAJ8251                   | RAJ8251                   | 0.9765\n",
      "BEP3409                   | BEP3409                   | 0.9801\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 143 done in 10.7s | train_loss=0.0026  valid_loss=0.3563  valid_acc=80.76%\n",
      "\n",
      "no improvement for 49/100 epochs\n",
      "\n",
      "→ Starting epoch 144  (printing every 172 iters)\n",
      "[Epoch 144] iter 172/172, avg loss: 0.0079\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QTV6692                   | QTV6692                   | 0.9777\n",
      "VET2003                   | VET2003                   | 0.9981\n",
      "QRN8870                   | QRN8870                   | 0.9962\n",
      "CCM9955                   | CCM9955                   | 0.9863\n",
      "WXT2433                   | WXT2433                   | 0.9797\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 144 done in 11.2s | train_loss=0.0079  valid_loss=0.3132  valid_acc=80.76%\n",
      "\n",
      "no improvement for 50/100 epochs\n",
      "\n",
      "→ Starting epoch 145  (printing every 172 iters)\n",
      "[Epoch 145] iter 172/172, avg loss: 0.0023\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WCG!7220                  | WCG!7220                  | 0.9953\n",
      "AGC!7322                  | AGC!7322                  | 0.9931\n",
      "QCG9886                   | QCG9886                   | 0.9984\n",
      "QAA8951J                  | QAA8951J                  | 0.9933\n",
      "QS!6618B                  | QS!6618B                  | 0.9770\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 145 done in 10.9s | train_loss=0.0023  valid_loss=0.3254  valid_acc=80.17%\n",
      "\n",
      "no improvement for 51/100 epochs\n",
      "\n",
      "→ Starting epoch 146  (printing every 172 iters)\n",
      "[Epoch 146] iter 172/172, avg loss: 0.0066\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "BQE4320                   | BQE4320                   | 0.9996\n",
      "QAQ1011                   | QAQ1011                   | 0.9768\n",
      "VHB3371                   | VHB3371                   | 0.9429\n",
      "VGX!8413                  | VGX!8413                  | 0.9895\n",
      "QDB!448                   | QDB!448                   | 0.9586\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 146 done in 10.8s | train_loss=0.0066  valid_loss=0.3539  valid_acc=78.72%\n",
      "\n",
      "no improvement for 52/100 epochs\n",
      "\n",
      "→ Starting epoch 147  (printing every 172 iters)\n",
      "[Epoch 147] iter 172/172, avg loss: 0.0020\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "BGD7950                   | BGD7950                   | 0.9945\n",
      "JWW9278                   | JWW9278                   | 0.9910\n",
      "QMW7697                   | QMW7697                   | 0.9934\n",
      "QBC5425                   | QBC5425                   | 0.9876\n",
      "QKS8556                   | QKS8556                   | 0.9956\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 147 done in 11.0s | train_loss=0.0020  valid_loss=0.3569  valid_acc=80.47%\n",
      "\n",
      "no improvement for 53/100 epochs\n",
      "\n",
      "→ Starting epoch 148  (printing every 172 iters)\n",
      "[Epoch 148] iter 172/172, avg loss: 0.0018\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "T/JJ115                   | T/JJ115                   | 0.9937\n",
      "VLD745                    | VLD745                    | 0.9451\n",
      "TBH1267                   | TBH1267                   | 0.9981\n",
      "BDP4954                   | BDP4954                   | 0.9965\n",
      "QCT7867                   | QCT7867                   | 0.9941\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 148 done in 10.9s | train_loss=0.0018  valid_loss=0.3704  valid_acc=79.30%\n",
      "\n",
      "no improvement for 54/100 epochs\n",
      "\n",
      "→ Starting epoch 149  (printing every 172 iters)\n",
      "[Epoch 149] iter 172/172, avg loss: 0.0067\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WEH8092                   | WEH8092                   | 0.9996\n",
      "VMP2929                   | VMP2929                   | 0.9952\n",
      "BJM9030                   | BJM9030                   | 0.9926\n",
      "VCG9239                   | VCG9239                   | 0.9972\n",
      "TBC28                     | TBC28                     | 0.9713\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 149 done in 10.6s | train_loss=0.0067  valid_loss=0.3864  valid_acc=78.72%\n",
      "\n",
      "no improvement for 55/100 epochs\n",
      "\n",
      "→ Starting epoch 150  (printing every 172 iters)\n",
      "[Epoch 150] iter 172/172, avg loss: 0.0047\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WXA7223                   | WXA7223                   | 0.9843\n",
      "QPA3382                   | QPA3382                   | 0.9971\n",
      "QAB2288F                  | QAB2288F                  | 0.9601\n",
      "AMB!1960                  | AMB!1960                  | 0.9670\n",
      "JLY2201                   | JLY2201                   | 0.9819\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 150 done in 11.0s | train_loss=0.0047  valid_loss=0.4016  valid_acc=77.55%\n",
      "\n",
      "no improvement for 56/100 epochs\n",
      "\n",
      "→ Starting epoch 151  (printing every 172 iters)\n",
      "[Epoch 151] iter 172/172, avg loss: 0.0032\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "ZC!3873                   | ZC!3873                   | 0.9775\n",
      "WNH553                    | WNH553                    | 0.9987\n",
      "QAA6493D                  | QAA6493D                  | 0.9874\n",
      "QKH4199                   | QKH4199                   | 0.9981\n",
      "PQP3331                   | PQP3331                   | 0.9885\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 151 done in 10.8s | train_loss=0.0032  valid_loss=0.3946  valid_acc=79.88%\n",
      "\n",
      "no improvement for 57/100 epochs\n",
      "\n",
      "→ Starting epoch 152  (printing every 172 iters)\n",
      "[Epoch 152] iter 172/172, avg loss: 0.0033\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WNB6877                   | WNB6877                   | 0.9807\n",
      "MU!6275                   | MU!6275                   | 0.9607\n",
      "QAA4058P                  | QAA4058P                  | 0.9776\n",
      "QKC1927                   | QKC1927                   | 0.9977\n",
      "VAX9343                   | VAX9343                   | 0.9754\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 152 done in 11.3s | train_loss=0.0033  valid_loss=0.3908  valid_acc=79.30%\n",
      "\n",
      "no improvement for 58/100 epochs\n",
      "\n",
      "→ Starting epoch 153  (printing every 172 iters)\n",
      "[Epoch 153] iter 172/172, avg loss: 0.0023\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VAH!7666                  | VAH!7666                  | 0.9839\n",
      "QS9698N                   | QS9698N                   | 0.9816\n",
      "WPL!3908                  | WPL!3908                  | 0.9599\n",
      "WXA7223                   | WXA7223                   | 0.9900\n",
      "WB6577N                   | WB6577N                   | 0.9695\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 153 done in 11.2s | train_loss=0.0023  valid_loss=0.3876  valid_acc=78.13%\n",
      "\n",
      "no improvement for 59/100 epochs\n",
      "\n",
      "→ Starting epoch 154  (printing every 172 iters)\n",
      "[Epoch 154] iter 172/172, avg loss: 0.0024\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "PMF!2507                  | PMF!2507                  | 0.9959\n",
      "JVB!7580                  | JVB!7580                  | 0.9533\n",
      "QAA2660J                  | QAA2660J                  | 0.9992\n",
      "ADU7533                   | ADU7533                   | 0.9872\n",
      "WA8029J                   | WA8029J                   | 0.9946\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 154 done in 10.9s | train_loss=0.0024  valid_loss=0.3737  valid_acc=76.97%\n",
      "\n",
      "no improvement for 60/100 epochs\n",
      "\n",
      "→ Starting epoch 155  (printing every 172 iters)\n",
      "[Epoch 155] iter 172/172, avg loss: 0.0012\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QCG7936                   | QCG7936                   | 0.9830\n",
      "QTJ4515                   | QTJ4515                   | 0.9978\n",
      "VBU6599                   | VBU6599                   | 0.9913\n",
      "QMU969                    | QMU969                    | 0.9983\n",
      "TV333                     | TV333                     | 0.9474\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 155 done in 10.7s | train_loss=0.0012  valid_loss=0.3684  valid_acc=79.88%\n",
      "\n",
      "no improvement for 61/100 epochs\n",
      "\n",
      "→ Starting epoch 156  (printing every 172 iters)\n",
      "[Epoch 156] iter 172/172, avg loss: 0.0012\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QS5007G                   | QS5007G                   | 0.9993\n",
      "VKP                       | VKP                       | 0.9908\n",
      "JSF2692                   | JSF2692                   | 0.9757\n",
      "VKA!3464                  | VKA!3464                  | 0.9999\n",
      "QAA3955H                  | QAA3955H                  | 0.9838\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 156 done in 10.9s | train_loss=0.0012  valid_loss=0.3717  valid_acc=80.17%\n",
      "\n",
      "no improvement for 62/100 epochs\n",
      "\n",
      "→ Starting epoch 157  (printing every 172 iters)\n",
      "[Epoch 157] iter 172/172, avg loss: 0.0028\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QCM5317                   | QCM5317                   | 1.0000\n",
      "QDB9286                   | QDB9286                   | 0.9875\n",
      "VAP!5570                  | VAP!5570                  | 0.9951\n",
      "WSA!5116                  | WSA!5116                  | 0.9374\n",
      "VMN5788                   | VMN5788                   | 0.9869\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 157 done in 10.8s | train_loss=0.0028  valid_loss=0.4297  valid_acc=77.84%\n",
      "\n",
      "no improvement for 63/100 epochs\n",
      "\n",
      "→ Starting epoch 158  (printing every 172 iters)\n",
      "[Epoch 158] iter 172/172, avg loss: 0.0064\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAB7672J                  | QAB7672J                  | 0.9926\n",
      "VKR!5274                  | VKR!5274                  | 0.9978\n",
      "NCY8966                   | NCY8966                   | 0.9822\n",
      "QCH9191                   | QCH9191                   | 0.9991\n",
      "QCN8327                   | QCN8327                   | 0.9913\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 158 done in 10.7s | train_loss=0.0064  valid_loss=0.3274  valid_acc=78.72%\n",
      "\n",
      "no improvement for 64/100 epochs\n",
      "\n",
      "→ Starting epoch 159  (printing every 172 iters)\n",
      "[Epoch 159] iter 172/172, avg loss: 0.0020\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "T/BB2347                  | T/BB2347                  | 0.9997\n",
      "VGT9721                   | VGT9721                   | 0.9807\n",
      "NAH!1048                  | NAH!1048                  | 0.9974\n",
      "VS5705                    | VS5705                    | 0.9992\n",
      "QAA3858U                  | QAA3858U                  | 0.9989\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 159 done in 11.5s | train_loss=0.0020  valid_loss=0.3583  valid_acc=78.43%\n",
      "\n",
      "no improvement for 65/100 epochs\n",
      "\n",
      "→ Starting epoch 160  (printing every 172 iters)\n",
      "[Epoch 160] iter 172/172, avg loss: 0.0028\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QLE!4710                  | QLE!4710                  | 0.9985\n",
      "QTN3878                   | QTN3878                   | 0.9803\n",
      "WQN4163                   | WQN4163                   | 0.9940\n",
      "SAB8373                   | SAB8373                   | 0.9914\n",
      "AER7905                   | AER7905                   | 0.9873\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 160 done in 11.1s | train_loss=0.0028  valid_loss=0.3930  valid_acc=77.55%\n",
      "\n",
      "no improvement for 66/100 epochs\n",
      "\n",
      "→ Starting epoch 161  (printing every 172 iters)\n",
      "[Epoch 161] iter 172/172, avg loss: 0.0017\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VKB9657                   | VKB9657                   | 0.9974\n",
      "QKS8556                   | QKS8556                   | 0.9997\n",
      "JKN8193                   | JKN8193                   | 0.9758\n",
      "QTN3878                   | QTN3878                   | 0.9948\n",
      "VCF2025                   | VCF2025                   | 0.9867\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 161 done in 10.8s | train_loss=0.0017  valid_loss=0.3768  valid_acc=79.30%\n",
      "\n",
      "no improvement for 67/100 epochs\n",
      "\n",
      "→ Starting epoch 162  (printing every 172 iters)\n",
      "[Epoch 162] iter 172/172, avg loss: 0.0014\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "9222H                     | 9222H                     | 0.9934\n",
      "TTB8278                   | TTB8278                   | 0.9927\n",
      "QCS1194                   | QCS1194                   | 0.9993\n",
      "PAC!6969                  | PAC!6969                  | 0.9655\n",
      "QSW!8828                  | QSW!8828                  | 0.9949\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 162 done in 10.9s | train_loss=0.0014  valid_loss=0.3748  valid_acc=77.26%\n",
      "\n",
      "no improvement for 68/100 epochs\n",
      "\n",
      "→ Starting epoch 163  (printing every 172 iters)\n",
      "[Epoch 163] iter 172/172, avg loss: 0.0080\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WTW6533                   | WTW6533                   | 0.9963\n",
      "QCA6734                   | QCA6734                   | 0.9937\n",
      "T/JA7639                  | T/JA7639                  | 0.9839\n",
      "BDA8389                   | BDA8389                   | 0.9986\n",
      "QAA6411                   | QAA6411                   | 0.9820\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 163 done in 11.0s | train_loss=0.0080  valid_loss=0.4007  valid_acc=77.55%\n",
      "\n",
      "no improvement for 69/100 epochs\n",
      "\n",
      "→ Starting epoch 164  (printing every 172 iters)\n",
      "[Epoch 164] iter 172/172, avg loss: 0.0051\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VCF2025                   | VCF2025                   | 0.9966\n",
      "PRM41                     | PRM41                     | 0.9919\n",
      "QCM5317                   | QCM5317                   | 0.9999\n",
      "MY!3045                   | MY!3045                   | 0.9629\n",
      "PBW!9097                  | PBW!9097                  | 0.9997\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 164 done in 10.8s | train_loss=0.0051  valid_loss=0.4215  valid_acc=77.55%\n",
      "\n",
      "no improvement for 70/100 epochs\n",
      "\n",
      "→ Starting epoch 165  (printing every 172 iters)\n",
      "[Epoch 165] iter 172/172, avg loss: 0.0032\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VDL4789                   | VDL4789                   | 0.9853\n",
      "JSS1383                   | JSS1383                   | 0.9927\n",
      "WB1351J                   | WB1351J                   | 0.9749\n",
      "JQT4395                   | JQT4395                   | 0.9999\n",
      "MCV!3797                  | MCV!3797                  | 0.9770\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 165 done in 10.8s | train_loss=0.0032  valid_loss=0.4108  valid_acc=76.68%\n",
      "\n",
      "no improvement for 71/100 epochs\n",
      "\n",
      "→ Starting epoch 166  (printing every 172 iters)\n",
      "[Epoch 166] iter 172/172, avg loss: 0.0019\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "FC9447                    | FC9447                    | 0.9997\n",
      "SWH1319                   | SWH1319                   | 0.9923\n",
      "VAU6344                   | VAU6344                   | 0.9974\n",
      "SYD7215                   | SYD7215                   | 0.9974\n",
      "QCS7968                   | QCS7968                   | 0.9579\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 166 done in 11.0s | train_loss=0.0019  valid_loss=0.3884  valid_acc=76.68%\n",
      "\n",
      "no improvement for 72/100 epochs\n",
      "\n",
      "→ Starting epoch 167  (printing every 172 iters)\n",
      "[Epoch 167] iter 172/172, avg loss: 0.0025\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QRL1169                   | QRL1169                   | 0.9892\n",
      "QS437C                    | QS437C                    | 0.9885\n",
      "QAT!6517                  | QAT!6517                  | 0.9887\n",
      "KAK2779                   | KAK2779                   | 0.9915\n",
      "BPC!9173                  | BPC!9173                  | 0.9996\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 167 done in 10.7s | train_loss=0.0025  valid_loss=0.3832  valid_acc=76.97%\n",
      "\n",
      "no improvement for 73/100 epochs\n",
      "\n",
      "→ Starting epoch 168  (printing every 172 iters)\n",
      "[Epoch 168] iter 172/172, avg loss: 0.0027\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QCJ2794                   | QCJ2794                   | 0.9848\n",
      "NAP4617                   | NAP4617                   | 0.9937\n",
      "QSX2233                   | QSX2233                   | 0.9939\n",
      "DFC4000                   | DFC4000                   | 0.9970\n",
      "ABX8314                   | ABX8314                   | 0.9804\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 168 done in 11.0s | train_loss=0.0027  valid_loss=0.4139  valid_acc=76.09%\n",
      "\n",
      "no improvement for 74/100 epochs\n",
      "\n",
      "→ Starting epoch 169  (printing every 172 iters)\n",
      "[Epoch 169] iter 172/172, avg loss: 0.0052\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VJJ!5970                  | VJJ!5970                  | 0.9670\n",
      "AGC!7322                  | AGC!7322                  | 0.9829\n",
      "WRX3310                   | WRX3310                   | 0.9851\n",
      "RC!9863                   | RC!9863                   | 0.9925\n",
      "JMY!6993                  | JMY!6993                  | 0.9771\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 169 done in 11.1s | train_loss=0.0052  valid_loss=0.4594  valid_acc=75.80%\n",
      "\n",
      "no improvement for 75/100 epochs\n",
      "\n",
      "→ Starting epoch 170  (printing every 172 iters)\n",
      "[Epoch 170] iter 172/172, avg loss: 0.0026\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "TCJ!8981                  | TCJ!8981                  | 0.9497\n",
      "BNY!4363                  | BNY!4363                  | 0.9986\n",
      "QAA!4673S                 | QAA!4673S                 | 0.9975\n",
      "KDQ4187                   | KDQ4187                   | 0.9998\n",
      "TAM!408                   | TAM!408                   | 0.9922\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 170 done in 10.8s | train_loss=0.0026  valid_loss=0.3854  valid_acc=77.84%\n",
      "\n",
      "no improvement for 76/100 epochs\n",
      "\n",
      "→ Starting epoch 171  (printing every 172 iters)\n",
      "[Epoch 171] iter 172/172, avg loss: 0.0035\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "SYY!4563                  | SYY!4563                  | 0.9797\n",
      "VKA!3464                  | VKA!3464                  | 0.9525\n",
      "QCS1194                   | QCS1194                   | 0.9875\n",
      "DBR9492                   | DBR9492                   | 0.9817\n",
      "JLC!8890                  | JLC!8890                  | 0.9690\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 171 done in 10.9s | train_loss=0.0035  valid_loss=0.4120  valid_acc=78.43%\n",
      "\n",
      "no improvement for 77/100 epochs\n",
      "\n",
      "→ Starting epoch 172  (printing every 172 iters)\n",
      "[Epoch 172] iter 172/172, avg loss: 0.0025\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VMQ981                    | VMQ981                    | 0.9990\n",
      "QAS2693                   | QAS2693                   | 0.9974\n",
      "QM4997P                   | QM4997P                   | 0.9785\n",
      "QS3284P                   | QS3284P                   | 0.9996\n",
      "GOLD!5333                 | GOLD!5333                 | 0.9436\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 172 done in 11.0s | train_loss=0.0025  valid_loss=0.3931  valid_acc=78.13%\n",
      "\n",
      "no improvement for 78/100 epochs\n",
      "\n",
      "→ Starting epoch 173  (printing every 172 iters)\n",
      "[Epoch 173] iter 172/172, avg loss: 0.0108\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "JPA!501                   | JPA!501                   | 0.9911\n",
      "QTS6613                   | QTS6613                   | 0.9970\n",
      "JCY7217                   | JCY7211                   | 0.9876\n",
      "AKK!4491                  | AKK!4491                  | 0.9705\n",
      "PKT1579                   | PKT1579                   | 0.9994\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 173 done in 10.7s | train_loss=0.0108  valid_loss=0.3760  valid_acc=78.13%\n",
      "\n",
      "no improvement for 79/100 epochs\n",
      "\n",
      "→ Starting epoch 174  (printing every 172 iters)\n",
      "[Epoch 174] iter 172/172, avg loss: 0.0066\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "MDN!8761                  | MDN!8761                  | 0.9998\n",
      "ALA1689                   | ALA1689                   | 0.9965\n",
      "WXX!2093                  | WXX!2093                  | 0.9890\n",
      "QAA6615Q                  | QAA6615Q                  | 0.9805\n",
      "AM7017                    | AM7017                    | 0.9976\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 174 done in 11.5s | train_loss=0.0066  valid_loss=0.3058  valid_acc=78.72%\n",
      "\n",
      "no improvement for 80/100 epochs\n",
      "\n",
      "→ Starting epoch 175  (printing every 172 iters)\n",
      "[Epoch 175] iter 172/172, avg loss: 0.0034\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WWN6994                   | WWN6994                   | 0.9896\n",
      "QTY9455                   | QTY9455                   | 0.9978\n",
      "VAQ!511                   | VAQ!511                   | 0.9979\n",
      "AKS8887                   | AKS8887                   | 0.9974\n",
      "JTU3636                   | JTU3636                   | 0.9948\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 175 done in 11.8s | train_loss=0.0034  valid_loss=0.3228  valid_acc=79.01%\n",
      "\n",
      "no improvement for 81/100 epochs\n",
      "\n",
      "→ Starting epoch 176  (printing every 172 iters)\n",
      "[Epoch 176] iter 172/172, avg loss: 0.0027\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "TCF8978                   | TCF8978                   | 0.9989\n",
      "QAA!9831T                 | QAA!9831T                 | 0.9980\n",
      "QAY4173                   | QAY4173                   | 0.9776\n",
      "KDC!4153                  | KDC!4153                  | 0.9827\n",
      "QAD!5337                  | QAD!5337                  | 0.9829\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 176 done in 11.0s | train_loss=0.0027  valid_loss=0.3571  valid_acc=80.17%\n",
      "\n",
      "no improvement for 82/100 epochs\n",
      "\n",
      "→ Starting epoch 177  (printing every 172 iters)\n",
      "[Epoch 177] iter 172/172, avg loss: 0.0023\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "PRP!5757                  | PRP!5757                  | 0.9906\n",
      "AM7017                    | AM7017                    | 0.9528\n",
      "VDJ5953                   | VDJ5953                   | 0.9979\n",
      "QM!9337Q                  | QM!9337Q                  | 0.9983\n",
      "QAB!8977J                 | QAB!8977J                 | 0.9570\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 177 done in 10.9s | train_loss=0.0023  valid_loss=0.3343  valid_acc=81.34%\n",
      "\n",
      "no improvement for 83/100 epochs\n",
      "\n",
      "→ Starting epoch 178  (printing every 172 iters)\n",
      "[Epoch 178] iter 172/172, avg loss: 0.0070\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VJP!6180                  | VJP!6180                  | 0.9774\n",
      "WTM!3755                  | WTM!3755                  | 0.9935\n",
      "SYX3611                   | SYX3611                   | 0.9979\n",
      "W8723V                    | W8723V                    | 0.9600\n",
      "QAB4631C                  | QAB4631C                  | 0.9990\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 178 done in 11.0s | train_loss=0.0070  valid_loss=0.3690  valid_acc=75.22%\n",
      "\n",
      "no improvement for 84/100 epochs\n",
      "\n",
      "→ Starting epoch 179  (printing every 172 iters)\n",
      "[Epoch 179] iter 172/172, avg loss: 0.0094\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAB9731D                  | QAB9731D                  | 0.9972\n",
      "T/BD!1513                 | T/BD!1513                 | 0.9352\n",
      "WYX8694                   | WYX8694                   | 0.9774\n",
      "QSU9715                   | QSU9715                   | 0.9922\n",
      "WJE4152                   | WJE4152                   | 0.9987\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 179 done in 10.8s | train_loss=0.0094  valid_loss=0.3476  valid_acc=79.30%\n",
      "\n",
      "no improvement for 85/100 epochs\n",
      "\n",
      "→ Starting epoch 180  (printing every 172 iters)\n",
      "[Epoch 180] iter 172/172, avg loss: 0.0107\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "BLG7607                   | BLG7607                   | 0.9952\n",
      "WQD6028                   | WQD6028                   | 0.9993\n",
      "PJN!538                   | PJN!538                   | 0.9842\n",
      "QAA2660J                  | QAA2660J                  | 0.9730\n",
      "AJJ2772                   | AJJ2772                   | 0.9959\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 180 done in 10.7s | train_loss=0.0107  valid_loss=0.3757  valid_acc=79.30%\n",
      "\n",
      "no improvement for 86/100 epochs\n",
      "\n",
      "→ Starting epoch 181  (printing every 172 iters)\n",
      "[Epoch 181] iter 172/172, avg loss: 0.0041\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "ANT8883                   | ANT8883                   | 0.9828\n",
      "QS5007G                   | QS5007G                   | 0.9945\n",
      "QCS5289                   | QCS5289                   | 0.9899\n",
      "PLX8764                   | PLX8764                   | 0.9975\n",
      "QCA2869                   | QCA2869                   | 0.9598\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 181 done in 11.1s | train_loss=0.0041  valid_loss=0.3727  valid_acc=80.47%\n",
      "\n",
      "no improvement for 87/100 epochs\n",
      "\n",
      "→ Starting epoch 182  (printing every 172 iters)\n",
      "[Epoch 182] iter 172/172, avg loss: 0.0093\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "KW!655                    | KW!655                    | 0.9770\n",
      "PPT549                    | PPT549                    | 0.9763\n",
      "TCM3335                   | TCM3335                   | 1.0000\n",
      "QBG6774                   | QBG6774                   | 0.9897\n",
      "T/BD8758                  | T/BD8758                  | 0.9985\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 182 done in 10.7s | train_loss=0.0093  valid_loss=0.3719  valid_acc=77.26%\n",
      "\n",
      "no improvement for 88/100 epochs\n",
      "\n",
      "→ Starting epoch 183  (printing every 172 iters)\n",
      "[Epoch 183] iter 172/172, avg loss: 0.0077\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WC3688R                   | WC3688R                   | 0.9886\n",
      "JNA3294                   | JNA3294                   | 0.9877\n",
      "JTU3636                   | JTU3636                   | 0.9930\n",
      "SML6789                   | SML6789                   | 0.9942\n",
      "WPH!317                   | WPH!317                   | 0.9805\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 183 done in 10.7s | train_loss=0.0077  valid_loss=0.3299  valid_acc=78.43%\n",
      "\n",
      "no improvement for 89/100 epochs\n",
      "\n",
      "→ Starting epoch 184  (printing every 172 iters)\n",
      "[Epoch 184] iter 172/172, avg loss: 0.0050\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "SD288V                    | SD288V                    | 1.0000\n",
      "KFW2299                   | KFW2299                   | 0.9843\n",
      "VH6789                    | VH6789                    | 0.9921\n",
      "QAA8020Q                  | QAA8020Q                  | 0.9762\n",
      "VM6611                    | VM6611                    | 0.9972\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 184 done in 11.1s | train_loss=0.0050  valid_loss=0.4814  valid_acc=71.14%\n",
      "\n",
      "no improvement for 90/100 epochs\n",
      "\n",
      "→ Starting epoch 185  (printing every 172 iters)\n",
      "[Epoch 185] iter 172/172, avg loss: 0.0102\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VHR7459                   | VHR7459                   | 0.9772\n",
      "QAA!4494H                 | QAA!4494H                 | 0.9763\n",
      "BMW8953                   | BMW8953                   | 0.9932\n",
      "QAA514K                   | QAA514K                   | 0.9719\n",
      "QAA5623H                  | QAA5623H                  | 0.9940\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 185 done in 10.8s | train_loss=0.0102  valid_loss=0.3491  valid_acc=75.51%\n",
      "\n",
      "no improvement for 91/100 epochs\n",
      "\n",
      "→ Starting epoch 186  (printing every 172 iters)\n",
      "[Epoch 186] iter 172/172, avg loss: 0.0040\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QCD8869                   | QCD8869                   | 0.9925\n",
      "QS!8781R                  | QS!8781R                  | 0.9886\n",
      "QAB2170K                  | QAB2170K                  | 0.9789\n",
      "QAA!328A                  | QAA!328A                  | 0.9294\n",
      "MDL1672                   | MDL1672                   | 0.9927\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 186 done in 10.7s | train_loss=0.0040  valid_loss=0.3354  valid_acc=77.55%\n",
      "\n",
      "no improvement for 92/100 epochs\n",
      "\n",
      "→ Starting epoch 187  (printing every 172 iters)\n",
      "[Epoch 187] iter 172/172, avg loss: 0.0026\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WMJ5949                   | WMJ5949                   | 0.9701\n",
      "ZC!3873                   | ZC!3873                   | 0.9665\n",
      "WFR9497                   | WFR9497                   | 0.9963\n",
      "VAP4435                   | VAP4435                   | 0.9962\n",
      "SA1408K                   | SA1408K                   | 0.9724\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 187 done in 11.0s | train_loss=0.0026  valid_loss=0.3534  valid_acc=78.72%\n",
      "\n",
      "no improvement for 93/100 epochs\n",
      "\n",
      "→ Starting epoch 188  (printing every 172 iters)\n",
      "[Epoch 188] iter 172/172, avg loss: 0.0032\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QTV6692                   | QTV6692                   | 0.9989\n",
      "JWJ!7952                  | JWJ!7952                  | 0.9994\n",
      "QPA3382                   | QPA3382                   | 0.9899\n",
      "KDH!2309                  | KDH!2309                  | 0.9808\n",
      "PKA!440                   | PKA!440                   | 0.9634\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 188 done in 10.8s | train_loss=0.0032  valid_loss=0.3641  valid_acc=79.59%\n",
      "\n",
      "no improvement for 94/100 epochs\n",
      "\n",
      "→ Starting epoch 189  (printing every 172 iters)\n",
      "[Epoch 189] iter 172/172, avg loss: 0.0023\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAQ1011                   | QAQ1011                   | 0.9820\n",
      "QCJ6959                   | QCJ6959                   | 0.9850\n",
      "QMY4519                   | QMY4519                   | 0.9714\n",
      "QLD2696                   | QLD2696                   | 0.9848\n",
      "BJR!9891                  | BJR!9891                  | 0.9988\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 189 done in 10.7s | train_loss=0.0023  valid_loss=0.3404  valid_acc=79.88%\n",
      "\n",
      "no improvement for 95/100 epochs\n",
      "\n",
      "→ Starting epoch 190  (printing every 172 iters)\n",
      "[Epoch 190] iter 172/172, avg loss: 0.0024\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "SJF!5203                  | SJF!5203                  | 0.9703\n",
      "QS5565M                   | QS5565M                   | 0.9874\n",
      "KAK!2474                  | KAK!2474                  | 0.9858\n",
      "QS!8781R                  | QS!8781R                  | 0.9886\n",
      "QAB9218                   | QAB9218                   | 0.9993\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 190 done in 11.0s | train_loss=0.0024  valid_loss=0.3275  valid_acc=78.43%\n",
      "\n",
      "no improvement for 96/100 epochs\n",
      "\n",
      "→ Starting epoch 191  (printing every 172 iters)\n",
      "[Epoch 191] iter 172/172, avg loss: 0.0020\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAY865                    | QAY865                    | 0.9892\n",
      "DCS3819                   | DCS3819                   | 0.9994\n",
      "JXP8326                   | JXP8326                   | 0.9972\n",
      "QAB7710K                  | QAB7710K                  | 0.9976\n",
      "QS3469R                   | QS3469R                   | 0.9674\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 191 done in 10.7s | train_loss=0.0020  valid_loss=0.3191  valid_acc=79.30%\n",
      "\n",
      "no improvement for 97/100 epochs\n",
      "\n",
      "→ Starting epoch 192  (printing every 172 iters)\n",
      "[Epoch 192] iter 172/172, avg loss: 0.0038\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "JTW!5239                  | JTW!5239                  | 0.9770\n",
      "QRR!5692                  | QRR!5692                  | 0.9998\n",
      "AFM2020                   | AFM2020                   | 0.9754\n",
      "QAA!9328G                 | QAA!9328G                 | 0.9959\n",
      "KEN!7203                  | KEN!7203                  | 0.9941\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 192 done in 10.8s | train_loss=0.0038  valid_loss=0.3095  valid_acc=78.43%\n",
      "\n",
      "no improvement for 98/100 epochs\n",
      "\n",
      "→ Starting epoch 193  (printing every 172 iters)\n",
      "[Epoch 193] iter 172/172, avg loss: 0.0033\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAB1552A                  | QAB1552A                  | 0.9798\n",
      "JLW!8830                  | JLW!8830                  | 0.9968\n",
      "QAB2477H                  | QAB2477H                  | 0.9875\n",
      "BHS5465                   | BHS5465                   | 0.9901\n",
      "QAA!4673S                 | QAA!4673S                 | 0.9819\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 193 done in 10.8s | train_loss=0.0033  valid_loss=0.3108  valid_acc=81.05%\n",
      "\n",
      "no improvement for 99/100 epochs\n",
      "\n",
      "→ Starting epoch 194  (printing every 172 iters)\n",
      "[Epoch 194] iter 172/172, avg loss: 0.0026\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "SB6436D                   | SB6436D                   | 0.9680\n",
      "QS5039N                   | QS5039N                   | 0.9797\n",
      "QAB7710K                  | QAB7710K                  | 0.9670\n",
      "PQD!8388                  | PQD!8388                  | 0.9768\n",
      "QAB9886J                  | QAB9886J                  | 0.9854\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 194 done in 11.1s | train_loss=0.0026  valid_loss=0.3054  valid_acc=80.47%\n",
      "\n",
      "no improvement for 100/100 epochs\n",
      "\n",
      "🔚 Early stopping: val_acc hasn't improved for 100 epochs.\n"
     ]
    }
   ],
   "source": [
    "# ─── Cell 6: training w/ history, best‐model saving + EARLY STOPPING ───\n",
    "\n",
    "# hyper‑params\n",
    "best_val_acc   = 0.0\n",
    "history        = {'epoch': [], 'train_loss': [], 'val_loss': [], 'val_acc': []}\n",
    "\n",
    "patience_cnt   = 0           # how many epochs since last improvement\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    print(f\"→ Starting epoch {epoch}  (printing every {PRINT_EVERY} iters)\")\n",
    "    model.train()\n",
    "    epoch_loss = Averager()\n",
    "    start = time.time()\n",
    "\n",
    "    # ─── training ──────────────────────────────────────────────────────────\n",
    "    for i, (images, texts) in enumerate(train_loader, 1):\n",
    "        images = images.to(device)\n",
    "\n",
    "        text, length   = converter.encode(texts, batch_max_length=MAX_LABEL_LENGTH)\n",
    "        text_input     = text[:, :-1].to(device)\n",
    "        text_target    = text[:,  1:].to(device)\n",
    "\n",
    "        preds = model(\n",
    "            images,\n",
    "            text=text_input,\n",
    "            is_train=True,\n",
    "            batch_max_length=MAX_LABEL_LENGTH\n",
    "        )  # [B, S, C]\n",
    "        B, S, C = preds.size()\n",
    "        loss = criterion(\n",
    "            preds.view(B * S, C),\n",
    "            text_target.contiguous().view(B * S)\n",
    "        )\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "        optimizer.step()\n",
    "        epoch_loss.add(loss)\n",
    "\n",
    "        # mini‐table prints\n",
    "        if i % PRINT_EVERY == 0:\n",
    "            print(f\"[Epoch {epoch}] iter {i}/{len(train_loader)}, avg loss: {epoch_loss.val():.4f}\", flush=True)\n",
    "            with torch.no_grad():\n",
    "                probs     = preds.softmax(2)\n",
    "                max_vals, max_inds = probs.max(2)\n",
    "                pred_strs = converter.decode(max_inds, length)\n",
    "                pred_strs = [s.split('[s]')[0] for s in pred_strs]\n",
    "\n",
    "            print(\"-\" * 80)\n",
    "            print(f\"{'Ground Truth':25s} | {'Prediction':25s} | AvgConfidence\")\n",
    "            print(\"-\" * 80)\n",
    "            for gt, pr, conf_seq in zip(texts[:5], pred_strs[:5], max_vals[:5]):\n",
    "                conf = conf_seq.mean().item()\n",
    "                print(f\"{gt:25s} | {pr:25s} | {conf_seq.mean().item():.4f}\")\n",
    "            print(\"-\" * 80)\n",
    "\n",
    "    # ─── validation ────────────────────────────────────────────────────────\n",
    "    val_loss, val_acc = validate(model, val_loader)\n",
    "    elapsed   = time.time() - start\n",
    "    train_l   = epoch_loss.val()\n",
    "    print(f\"==> Epoch {epoch} done in {elapsed:.1f}s | \"\n",
    "          f\"train_loss={train_l:.4f}  valid_loss={val_loss:.4f}  valid_acc={val_acc:.2f}%\\n\")\n",
    "\n",
    "    # ─── record history ───────────────────────────────────────────────────\n",
    "    history['epoch'].append(epoch)\n",
    "    history['train_loss'].append(train_l)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "\n",
    "    # ─── best‑model tracking & early‑stopping logic ───────────────────────\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"best_attention_crnn_!_augment_no_TPS.pth\")\n",
    "        print(f\"💾 New best model saved (epoch {epoch}, val_acc={val_acc:.2f}%)\\n\")\n",
    "        patience_cnt = 0                          # reset counter\n",
    "    else:\n",
    "        patience_cnt += 1\n",
    "        print(f\"no improvement for {patience_cnt}/{PATIENCE} epochs\\n\")\n",
    "        if patience_cnt >= PATIENCE:\n",
    "            print(f\"🔚 Early stopping: val_acc hasn't improved for {PATIENCE} epochs.\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b49a536f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.614335</td>\n",
       "      <td>2.409936</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.665804</td>\n",
       "      <td>1.157825</td>\n",
       "      <td>6.122449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.906646</td>\n",
       "      <td>0.754006</td>\n",
       "      <td>46.064140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.623801</td>\n",
       "      <td>0.546563</td>\n",
       "      <td>59.475219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.414145</td>\n",
       "      <td>0.510754</td>\n",
       "      <td>49.854227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>190</td>\n",
       "      <td>0.002440</td>\n",
       "      <td>0.327500</td>\n",
       "      <td>78.425656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>191</td>\n",
       "      <td>0.001980</td>\n",
       "      <td>0.319136</td>\n",
       "      <td>79.300292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>192</td>\n",
       "      <td>0.003848</td>\n",
       "      <td>0.309519</td>\n",
       "      <td>78.425656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>193</td>\n",
       "      <td>0.003328</td>\n",
       "      <td>0.310769</td>\n",
       "      <td>81.049563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>194</td>\n",
       "      <td>0.002630</td>\n",
       "      <td>0.305401</td>\n",
       "      <td>80.466472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>194 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     epoch  train_loss  val_loss    val_acc\n",
       "0        1    2.614335  2.409936   0.000000\n",
       "1        2    1.665804  1.157825   6.122449\n",
       "2        3    0.906646  0.754006  46.064140\n",
       "3        4    0.623801  0.546563  59.475219\n",
       "4        5    0.414145  0.510754  49.854227\n",
       "..     ...         ...       ...        ...\n",
       "189    190    0.002440  0.327500  78.425656\n",
       "190    191    0.001980  0.319136  79.300292\n",
       "191    192    0.003848  0.309519  78.425656\n",
       "192    193    0.003328  0.310769  81.049563\n",
       "193    194    0.002630  0.305401  80.466472\n",
       "\n",
       "[194 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clean_history = {\n",
    "  'epoch':      history['epoch'],\n",
    "  'train_loss': [x.cpu().item() if hasattr(x, 'cpu') else x for x in history['train_loss']],\n",
    "  'val_loss':   [x.cpu().item() if hasattr(x, 'cpu') else x for x in history['val_loss']],\n",
    "  'val_acc':    [x.cpu().item() if hasattr(x, 'cpu') else x for x in history['val_acc']],\n",
    "}\n",
    "df = pd.DataFrame(clean_history)\n",
    "display(df)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(df['epoch'], df['train_loss'], label='Train Loss')\n",
    "plt.plot(df['epoch'], df['val_loss'],   label='Val Loss')\n",
    "plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.legend()\n",
    "plt.title('Loss over Epochs')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(df['epoch'], df['val_acc'],   label='Val Accuracy')\n",
    "plt.xlabel('Epoch'); plt.ylabel('Accuracy (%)'); plt.legend()\n",
    "plt.title('Val Accuracy over Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe117ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ─── Cell 9: ONNX export via isolated inference head ─────────────────────────\n",
    "# import torch\n",
    "\n",
    "# class CRNNInference(torch.nn.Module):\n",
    "#     def __init__(self, crnn, max_len):\n",
    "#         super().__init__()\n",
    "#         # use exactly the names printed out by your inspection\n",
    "#         self.Transformation     = crnn.Transformation\n",
    "#         self.FeatureExtraction = crnn.FeatureExtraction\n",
    "#         self.AdaptiveAvgPool    = crnn.AdaptiveAvgPool\n",
    "#         self.SequenceModeling   = crnn.SequenceModeling\n",
    "#         self.Prediction         = crnn.Prediction\n",
    "#         self.max_len           = max_len\n",
    "#         # adjust this if your converter stores start-token under a different key\n",
    "#         self.start_id          = crnn.converter.dict['[GO]']\n",
    "\n",
    "#     def forward(self, image):\n",
    "#         # 1) Spatial‐transformer + feature CNN\n",
    "#         x = self.Transformation(image)                     # [B, C, H, W]\n",
    "#         x = self.FeatureExtraction(x)                      # [B, C, H, W]\n",
    "\n",
    "#         # 2) Pool down height to 1\n",
    "#         x = self.AdaptiveAvgPool(x)                        # [B, C, 1, W]\n",
    "#         x = x.squeeze(2)                                   # [B, C, W]\n",
    "#         x = x.permute(0, 2, 1)                             # [B, W, C]\n",
    "\n",
    "#         # 3) 2‐layer BiLSTM\n",
    "#         contextual = self.SequenceModeling(x)              # [B, W, hidden]\n",
    "\n",
    "#         # 4) Dummy “[GO]” token vector\n",
    "#         B = contextual.size(0)\n",
    "#         dummy_text = torch.full(\n",
    "#             (B,),\n",
    "#             self.start_id,\n",
    "#             dtype=torch.long,\n",
    "#             device=image.device\n",
    "#         )  # shape [B]\n",
    "\n",
    "#         # 5) Attention decoder (inference path)\n",
    "#         return self.Prediction(\n",
    "#             batch_H           = contextual,\n",
    "#             text              = dummy_text,\n",
    "#             is_train          = False,\n",
    "#             batch_max_length  = self.max_len\n",
    "#         )\n",
    "\n",
    "# # Wrap and export\n",
    "# inference_model = CRNNInference(model, BATCH_MAX_LENGTH).eval()\n",
    "# dummy_img       = torch.randn(1, INPUT_CHANNEL, IMG_HEIGHT, IMG_WIDTH, device=device)\n",
    "\n",
    "# torch.onnx.export(\n",
    "#     inference_model,\n",
    "#     dummy_img,\n",
    "#     \"best_attention_crnn.onnx\",\n",
    "#     input_names   = ['image'],\n",
    "#     output_names  = ['logits'],\n",
    "#     dynamic_axes  = {\n",
    "#         'image':  {0: 'batch'},\n",
    "#         'logits': {0: 'batch', 1: 'time'}\n",
    "#     },\n",
    "#     opset_version = 13,\n",
    "# )\n",
    "\n",
    "# print(\"✅ Exported best_attention_crnn.onnx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9587a5dc",
   "metadata": {},
   "source": [
    "# DUMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99a300a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ─── cell 6: attention‐based training loop ──────────────────────────────────────\n",
    "# for epoch in range(1, NUM_EPOCHS+1):\n",
    "#     print(f\"→ Starting epoch {epoch}  (printing every {PRINT_EVERY} iters)\")\n",
    "#     model.train()\n",
    "#     epoch_loss = Averager()\n",
    "#     start      = time.time()\n",
    "\n",
    "#     for i, (images, texts) in enumerate(train_loader, 1):\n",
    "#         images = images.to(device)\n",
    "\n",
    "#         # encode with [GO] & [s]; also get lengths\n",
    "#         text, length = converter.encode(texts, batch_max_length=BATCH_MAX_LENGTH)\n",
    "#         text_input  = text[:, :-1].to(device)   # drop final [s]\n",
    "#         text_target = text[:,  1:].to(device)   # everything after [GO]\n",
    "\n",
    "#         # forward + loss\n",
    "#         preds = model(images,\n",
    "#                       text=text_input,\n",
    "#                       is_train=True,\n",
    "#                       batch_max_length=BATCH_MAX_LENGTH)  # [B, S, C]\n",
    "#         B, S, C = preds.size()\n",
    "#         loss = criterion(\n",
    "#             preds.view(B * S, C),\n",
    "#             text_target.contiguous().view(B * S)\n",
    "#         )\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "#         optimizer.step()\n",
    "#         epoch_loss.add(loss)\n",
    "\n",
    "#         if i % PRINT_EVERY == 0 or i == 1:\n",
    "#             print(f\"[Epoch {epoch}] iter {i}/{len(train_loader)}, avg loss: {epoch_loss.val():.4f}\", flush=True)\n",
    "\n",
    "#             # quick greedy‐decode\n",
    "#             with torch.no_grad():\n",
    "#                 probs        = preds.softmax(2)           # [B, S, C]\n",
    "#                 max_vals, max_inds = probs.max(2)         # [B, S]\n",
    "#                 pred_strs    = converter.decode(max_inds, length)\n",
    "#                 pred_strs    = [s.split('[s]')[0] for s in pred_strs]\n",
    "\n",
    "#             # print a mini‐table\n",
    "#             print(\"-\" * 80)\n",
    "#             print(f\"{'Ground Truth':25s} | {'Prediction':25s} | AvgConfidence\")\n",
    "#             print(\"-\" * 80)\n",
    "#             for gt, pr, conf_seq in zip(texts[:5], pred_strs[:5], max_vals[:5]):\n",
    "#                 conf = conf_seq.mean().item()\n",
    "#                 print(f\"{gt:25s} | {pr:25s} | {conf:0.4f}\")\n",
    "#             print(\"-\" * 80)\n",
    "\n",
    "#     # end‐of‐epoch validation\n",
    "#     val_loss, val_acc = validate(model, val_loader)\n",
    "#     elapsed = time.time() - start\n",
    "#     print(f\"==> Epoch {epoch} done in {elapsed:.1f}s | \"\n",
    "#           f\"train_loss={epoch_loss.val():.4f}\"\n",
    "#           f\"  valid_loss={val_loss:.4f}  valid_acc={val_acc:.2f}%\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d861ce44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ─── Cell 6: training w/ history, best‐model saving ───\n",
    "\n",
    "# # hyper‐params\n",
    "# best_val_acc    = 0.0\n",
    "# history         = {'epoch': [], 'train_loss': [], 'val_loss': [], 'val_acc': []}\n",
    "\n",
    "# for epoch in range(1, NUM_EPOCHS+1):\n",
    "#     print(f\"→ Starting epoch {epoch}  (printing every {PRINT_EVERY} iters)\")\n",
    "#     model.train()\n",
    "#     epoch_loss = Averager()\n",
    "#     start = time.time()\n",
    "\n",
    "#     # ─── training ─────────────────────────────────────────────────────────────\n",
    "#     for i, (images, texts) in enumerate(train_loader, 1):\n",
    "#         images = images.to(device)\n",
    "\n",
    "#         text, length   = converter.encode(texts, batch_max_length=MAX_LABEL_LENGTH)\n",
    "#         text_input     = text[:, :-1].to(device)\n",
    "#         text_target    = text[:,  1:].to(device)\n",
    "\n",
    "#         preds = model(\n",
    "#             images,\n",
    "#             text=text_input,\n",
    "#             is_train=True,\n",
    "#             batch_max_length=MAX_LABEL_LENGTH\n",
    "#         )  # [B, S, C]\n",
    "#         B, S, C = preds.size()\n",
    "#         loss = criterion(\n",
    "#             preds.view(B * S, C),\n",
    "#             text_target.contiguous().view(B * S)\n",
    "#         )\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "#         optimizer.step()\n",
    "#         epoch_loss.add(loss)\n",
    "\n",
    "#         # mini‐table prints\n",
    "#         if i % PRINT_EVERY == 0:\n",
    "#             print(f\"[Epoch {epoch}] iter {i}/{len(train_loader)}, avg loss: {epoch_loss.val():.4f}\", flush=True)\n",
    "#             with torch.no_grad():\n",
    "#                 probs     = preds.softmax(2)\n",
    "#                 max_vals, max_inds = probs.max(2)\n",
    "#                 pred_strs = converter.decode(max_inds, length)\n",
    "#                 pred_strs = [s.split('[s]')[0] for s in pred_strs]\n",
    "\n",
    "#             print(\"-\" * 80)\n",
    "#             print(f\"{'Ground Truth':25s} | {'Prediction':25s} | AvgConfidence\")\n",
    "#             print(\"-\" * 80)\n",
    "#             for gt, pr, conf_seq in zip(texts[:5], pred_strs[:5], max_vals[:5]):\n",
    "#                 conf = conf_seq.mean().item()\n",
    "#                 print(f\"{gt:25s} | {pr:25s} | {conf_seq.mean().item():.4f}\")\n",
    "#             print(\"-\" * 80)\n",
    "\n",
    "#     # ─── validation ────────────────────────────────────────────────────────────\n",
    "#     val_loss, val_acc = validate(model, val_loader)\n",
    "#     elapsed = time.time() - start\n",
    "#     train_l = epoch_loss.val()\n",
    "#     print(f\"==> Epoch {epoch} done in {elapsed:.1f}s | \"\n",
    "#           f\"train_loss={train_l:.4f}  valid_loss={val_loss:.4f}  valid_acc={val_acc:.2f}%\\n\")\n",
    "\n",
    "#     # ─── record history & save best ──────────────────────────────────────────\n",
    "#     history['epoch'].append(epoch)\n",
    "#     history['train_loss'].append(train_l)\n",
    "#     history['val_loss'].append(val_loss)\n",
    "#     history['val_acc'].append(val_acc)\n",
    "\n",
    "#     if val_acc > best_val_acc:\n",
    "#         best_val_acc = val_acc\n",
    "#         torch.save(model.state_dict(), \"best_attention_crnn_!.pth\")\n",
    "#         print(f\"💾 New best model saved (epoch {epoch}, val_acc={val_acc:.2f}%)\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
