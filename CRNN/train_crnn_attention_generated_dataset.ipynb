{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "493b766c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cuda\n"
     ]
    }
   ],
   "source": [
    "# cell 1\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from config import (IMG_HEIGHT, IMG_WIDTH, NUM_FIDUCIAL,\n",
    "                    INPUT_CHANNEL, OUTPUT_CHANNEL, HIDDEN_SIZE,\n",
    "                    CHARACTERS, MAX_LABEL_LENGTH)\n",
    "from dataset import LmdbDataset, AlignCollate\n",
    "# from utils import CTCLabelConverter, Averager\n",
    "from utils import AttnLabelConverter, Averager\n",
    "from model import CRNN\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Running on\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2c361de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All seeds set to 300188, cudnn.deterministic=True\n"
     ]
    }
   ],
   "source": [
    "# ─── cell 0: reproducibility ────────────────────────────────────────────────\n",
    "SEED = 300188\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# Make cuDNN deterministic (slower but reproducible)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "print(f\"All seeds set to {SEED}, cudnn.deterministic={torch.backends.cudnn.deterministic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea60e7b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 8000 valid samples from generated_lmdb_data/train\n",
      "Loaded 2000 valid samples from generated_lmdb_data/val\n",
      "8000 train / 2000 val samples\n"
     ]
    }
   ],
   "source": [
    "# cell 2\n",
    "# paths to your LMDBs\n",
    "train_lmdb = \"generated_lmdb_data/train\"\n",
    "val_lmdb   = \"generated_lmdb_data/val\"\n",
    "\n",
    "# instantiate datasets\n",
    "train_dataset = LmdbDataset(train_lmdb)\n",
    "val_dataset   = LmdbDataset(val_lmdb)\n",
    "\n",
    "# collate_fn resizes + normalizes\n",
    "collate_fn = AlignCollate(\n",
    "    imgH=IMG_HEIGHT, imgW=IMG_WIDTH, keep_ratio_with_pad=False\n",
    ")\n",
    "\n",
    "# loaders\n",
    "BATCH_SIZE = 128\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "    num_workers=0, collate_fn=collate_fn, pin_memory=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "    num_workers=0, collate_fn=collate_fn, pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"{len(train_dataset)} train / {len(val_dataset)} val samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e3d612b",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter   = AttnLabelConverter(CHARACTERS)\n",
    "num_classes = len(converter.character)   # includes [GO] and [s]\n",
    "\n",
    "model = CRNN(\n",
    "    IMG_HEIGHT,      # imgH\n",
    "    IMG_WIDTH,       # imgW\n",
    "    INPUT_CHANNEL,   # input_channel\n",
    "    OUTPUT_CHANNEL,  # output_channel\n",
    "    HIDDEN_SIZE,     # hidden_size\n",
    "    num_classes,     # num_classes (with GO/s)\n",
    "    True,            # use_attention\n",
    "    NUM_FIDUCIAL     # num_fiducial\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0).to(device)\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=1.0)\n",
    "\n",
    "model.Transformation = nn.Identity() # <-- no transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a80e2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── cell 4: validate (Attention) ─────────────────────────────────────────────\n",
    "NUM_EPOCHS       = 500\n",
    "PRINT_EVERY      = len(train_dataset) // BATCH_SIZE + 1\n",
    "PATIENCE       = 100          # stop if no val_acc ↑ for 50 epochs\n",
    "\n",
    "def validate(model, loader):\n",
    "    model.eval()\n",
    "    avg_loss = Averager()\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, texts in loader:\n",
    "            images = images.to(device)\n",
    "\n",
    "            # encode full text → shape [B, L+1], plus lengths\n",
    "            text, length = converter.encode(texts, batch_max_length=MAX_LABEL_LENGTH)\n",
    "            text_input  = text[:, :-1].to(device)  # drop final [s]\n",
    "            text_target = text[:,  1:].to(device)  # everything after [GO]\n",
    "\n",
    "            # forward\n",
    "            preds = model(images, text_input, is_train=False,\n",
    "                          batch_max_length=MAX_LABEL_LENGTH)\n",
    "            B, S, C = preds.size()\n",
    "\n",
    "            # cross‐entropy over (B×S) predictions\n",
    "            loss = criterion(\n",
    "                preds.view(B * S, C),\n",
    "                text_target.contiguous().view(B * S)\n",
    "            )\n",
    "            avg_loss.add(loss)\n",
    "\n",
    "            # greedy decode\n",
    "            _, pred_inds = preds.max(2)                   # [B, S]\n",
    "            pred_strs = converter.decode(pred_inds, length)  # pass length\n",
    "\n",
    "            # strip off anything after the \"[s]\" token\n",
    "            pred_strs = [s.split('[s]')[0] for s in pred_strs]\n",
    "\n",
    "            total += len(texts)\n",
    "            correct += sum(p == g for p, g in zip(pred_strs, texts))\n",
    "\n",
    "    acc = correct / total * 100\n",
    "    return avg_loss.val(), acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36d430a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded pretrained Attn weights\n"
     ]
    }
   ],
   "source": [
    "# ─── cell 5: load pretrained CTC weights (skip old Prediction head) ────────────\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "orig      = torch.load(\"pretrained_model/TPS-ResNet-BiLSTM-Attn.pth\", map_location=device)\n",
    "# strip off the \"module.\" prefix if you wrapped in DataParallel\n",
    "stripped  = OrderedDict((k[len(\"module.\"):], v)\n",
    "                        for k, v in orig.items()\n",
    "                        if k.startswith(\"module.\"))\n",
    "\n",
    "own = model.state_dict()\n",
    "for k, v in stripped.items():\n",
    "    # skip the old attention head entirely\n",
    "    if k.startswith(\"Prediction.\") or k.startswith(\"Transformation.\"):\n",
    "        continue\n",
    "    # only overwrite if shapes match\n",
    "    if k in own and v.size() == own[k].size():\n",
    "        own[k] = v\n",
    "\n",
    "model.load_state_dict(own)\n",
    "print(\"✅ Loaded pretrained Attn weights\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d861ce44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Starting epoch 1  (printing every 63 iters)\n",
      "[Epoch 1] iter 63/63, avg loss: 3.1041\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VDH29                     | H9999                     | 0.3974\n",
      "WB10B                     | B888888                   | 0.2473\n",
      "JBS367                    | B6666                     | 0.3816\n",
      "DQO6216E                  | 6666666                   | 0.2552\n",
      "YV147Z                    | Z777                      | 0.3551\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 1 done in 10.4s | train_loss=3.1041  valid_loss=2.6962  valid_acc=0.00%\n",
      "\n",
      "no improvement for 1/100 epochs\n",
      "\n",
      "→ Starting epoch 2  (printing every 63 iters)\n",
      "[Epoch 2] iter 63/63, avg loss: 2.3607\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "TH8529                    | HH88299                   | 0.3800\n",
      "ZG5D                      | GG55DDDDDDDDDDDDDDDDD     | 0.4019\n",
      "U9680                     | UU8888888888888888888     | 0.4741\n",
      "KUZ5                      | UUUZ                      | 0.3602\n",
      "WH58                      | WW888888HHHHHHHHHHHHH     | 0.3794\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 2 done in 10.0s | train_loss=2.3607  valid_loss=1.9036  valid_acc=1.05%\n",
      "\n",
      "💾 New best model saved (epoch 2, val_acc=1.05%)\n",
      "\n",
      "→ Starting epoch 3  (printing every 63 iters)\n",
      "[Epoch 3] iter 63/63, avg loss: 1.6281\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QTU3                      | QTUUU                     | 0.5066\n",
      "HEM4S                     | HEMMM                     | 0.5801\n",
      "PSN072                    | PSN22                     | 0.4541\n",
      "WOS30                     | WOS00                     | 0.4197\n",
      "MZJ6M                     | MZJM                      | 0.4775\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 3 done in 10.0s | train_loss=1.6281  valid_loss=1.1487  valid_acc=12.00%\n",
      "\n",
      "💾 New best model saved (epoch 3, val_acc=12.00%)\n",
      "\n",
      "→ Starting epoch 4  (printing every 63 iters)\n",
      "[Epoch 4] iter 63/63, avg loss: 1.1375\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QXZ1002                   | QXZ002                    | 0.6335\n",
      "PRT8                      | PRT8                      | 0.7985\n",
      "O4306T                    | OT666                     | 0.5879\n",
      "KU93                      | KU93                      | 0.8312\n",
      "P566Y                     | P566                      | 0.8333\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 4 done in 10.2s | train_loss=1.1375  valid_loss=1.0873  valid_acc=14.55%\n",
      "\n",
      "💾 New best model saved (epoch 4, val_acc=14.55%)\n",
      "\n",
      "→ Starting epoch 5  (printing every 63 iters)\n",
      "[Epoch 5] iter 63/63, avg loss: 0.8466\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "MZJ6M                     | MZJ7MMM                   | 0.6923\n",
      "OL63R                     | OL88RR                    | 0.5772\n",
      "A5026                     | A50226                    | 0.8001\n",
      "CZY1695                   | CZY11995                  | 0.7135\n",
      "E6                        | E6                        | 0.9626\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 5 done in 10.1s | train_loss=0.8466  valid_loss=1.7887  valid_acc=6.30%\n",
      "\n",
      "no improvement for 1/100 epochs\n",
      "\n",
      "→ Starting epoch 6  (printing every 63 iters)\n",
      "[Epoch 6] iter 63/63, avg loss: 0.6851\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "KTI4                      | KTI4                      | 0.9261\n",
      "C3C                       | C3C                       | 0.9759\n",
      "RE2F                      | RE2F                      | 0.8810\n",
      "R713                      | R713                      | 0.8676\n",
      "G06                       | G66                       | 0.9836\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 6 done in 10.1s | train_loss=0.6851  valid_loss=0.9724  valid_acc=10.25%\n",
      "\n",
      "no improvement for 2/100 epochs\n",
      "\n",
      "→ Starting epoch 7  (printing every 63 iters)\n",
      "[Epoch 7] iter 63/63, avg loss: 0.5456\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "IOS4153U                  | IOS113UU                  | 0.6638\n",
      "D58                       | D58                       | 0.9759\n",
      "ID9110Z                   | ID910Z                    | 0.8389\n",
      "R291                      | R291                      | 0.9218\n",
      "LXE1                      | LXE1                      | 0.8524\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 7 done in 10.0s | train_loss=0.5456  valid_loss=0.4442  valid_acc=52.70%\n",
      "\n",
      "💾 New best model saved (epoch 7, val_acc=52.70%)\n",
      "\n",
      "→ Starting epoch 8  (printing every 63 iters)\n",
      "[Epoch 8] iter 63/63, avg loss: 0.3893\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "N70                       | N70                       | 0.8615\n",
      "EMM326B                   | EMM326BB                  | 0.8637\n",
      "WZ5                       | WZ5                       | 0.9439\n",
      "R333                      | R333                      | 0.9656\n",
      "TV4075Q                   | TV00755                   | 0.7159\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 8 done in 10.0s | train_loss=0.3893  valid_loss=0.7918  valid_acc=36.40%\n",
      "\n",
      "no improvement for 1/100 epochs\n",
      "\n",
      "→ Starting epoch 9  (printing every 63 iters)\n",
      "[Epoch 9] iter 63/63, avg loss: 0.3499\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "XP7431                    | XP7431                    | 0.9217\n",
      "U1D                       | U3D                       | 0.9360\n",
      "RJZ5                      | RJZ5                      | 0.9465\n",
      "M001A                     | M001A                     | 0.7851\n",
      "D31Y                      | D31Y                      | 0.9418\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 9 done in 9.7s | train_loss=0.3499  valid_loss=0.3347  valid_acc=64.40%\n",
      "\n",
      "💾 New best model saved (epoch 9, val_acc=64.40%)\n",
      "\n",
      "→ Starting epoch 10  (printing every 63 iters)\n",
      "[Epoch 10] iter 63/63, avg loss: 0.3210\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "BE30X                     | BE00X                     | 0.8040\n",
      "B51                       | B51                       | 0.9339\n",
      "OPI27                     | OPI27                     | 0.8924\n",
      "N05                       | N05                       | 0.8911\n",
      "NGV1752J                  | NGV7722J                  | 0.6716\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 10 done in 9.7s | train_loss=0.3210  valid_loss=0.3663  valid_acc=61.00%\n",
      "\n",
      "no improvement for 1/100 epochs\n",
      "\n",
      "→ Starting epoch 11  (printing every 63 iters)\n",
      "[Epoch 11] iter 63/63, avg loss: 0.2564\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "TLG0023                   | TLG0023                   | 0.9519\n",
      "F5                        | F5                        | 0.9007\n",
      "LZF30                     | LZF30                     | 0.9884\n",
      "TZ867                     | TZ867                     | 0.9574\n",
      "JWY6955A                  | JWY995AA                  | 0.8135\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 11 done in 9.8s | train_loss=0.2564  valid_loss=0.1828  valid_acc=74.40%\n",
      "\n",
      "💾 New best model saved (epoch 11, val_acc=74.40%)\n",
      "\n",
      "→ Starting epoch 12  (printing every 63 iters)\n",
      "[Epoch 12] iter 63/63, avg loss: 0.1719\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "X0Z                       | X9Z                       | 0.8749\n",
      "G0                        | G0                        | 0.9259\n",
      "WIT6W                     | WIT1W                     | 0.8996\n",
      "ON85F                     | ON85F                     | 0.9091\n",
      "XRW36                     | XRW36                     | 0.9607\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 12 done in 9.8s | train_loss=0.1719  valid_loss=0.1749  valid_acc=75.40%\n",
      "\n",
      "💾 New best model saved (epoch 12, val_acc=75.40%)\n",
      "\n",
      "→ Starting epoch 13  (printing every 63 iters)\n",
      "[Epoch 13] iter 63/63, avg loss: 0.1536\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "X7247                     | X7247                     | 0.8961\n",
      "O7102                     | O7102                     | 0.9843\n",
      "GUF0673                   | GUF0673                   | 0.9224\n",
      "TZ6101                    | TZ6101                    | 0.9335\n",
      "IYU6367O                  | IYU4367O                  | 0.8772\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 13 done in 9.6s | train_loss=0.1536  valid_loss=0.1985  valid_acc=72.30%\n",
      "\n",
      "no improvement for 1/100 epochs\n",
      "\n",
      "→ Starting epoch 14  (printing every 63 iters)\n",
      "[Epoch 14] iter 63/63, avg loss: 0.2065\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WA3                       | WA3                       | 0.9331\n",
      "OM1656S                   | OM6656S                   | 0.8518\n",
      "D68A                      | D88A                      | 0.9218\n",
      "OP8275D                   | OP8275D                   | 0.9161\n",
      "G6R                       | G6R                       | 0.8720\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 14 done in 9.7s | train_loss=0.2065  valid_loss=0.1764  valid_acc=74.50%\n",
      "\n",
      "no improvement for 2/100 epochs\n",
      "\n",
      "→ Starting epoch 15  (printing every 63 iters)\n",
      "[Epoch 15] iter 63/63, avg loss: 0.0904\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "M7137C                    | M1137C                    | 0.8456\n",
      "S18Z                      | S18Z                      | 0.9086\n",
      "U45                       | U45                       | 0.9365\n",
      "HH156H                    | HH156H                    | 0.9704\n",
      "ADW8097W                  | ADW4097W                  | 0.8718\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 15 done in 9.7s | train_loss=0.0904  valid_loss=0.1692  valid_acc=76.30%\n",
      "\n",
      "💾 New best model saved (epoch 15, val_acc=76.30%)\n",
      "\n",
      "→ Starting epoch 16  (printing every 63 iters)\n",
      "[Epoch 16] iter 63/63, avg loss: 0.0549\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WZ3218U                   | WZ1218U                   | 0.8565\n",
      "H7629                     | H7629                     | 0.9628\n",
      "K8                        | K8                        | 0.9903\n",
      "P1E                       | P1E                       | 0.8755\n",
      "IB4                       | IB4                       | 0.9648\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 16 done in 9.6s | train_loss=0.0549  valid_loss=0.1698  valid_acc=75.65%\n",
      "\n",
      "no improvement for 1/100 epochs\n",
      "\n",
      "→ Starting epoch 17  (printing every 63 iters)\n",
      "[Epoch 17] iter 63/63, avg loss: 0.0379\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "S56                       | S56                       | 0.9506\n",
      "P1662                     | P1662                     | 0.9581\n",
      "DX2344                    | DX2344                    | 0.9515\n",
      "KCS4                      | KCS4                      | 0.9485\n",
      "DXL992                    | DXL992                    | 0.9636\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 17 done in 9.6s | train_loss=0.0379  valid_loss=0.1950  valid_acc=75.65%\n",
      "\n",
      "no improvement for 2/100 epochs\n",
      "\n",
      "→ Starting epoch 18  (printing every 63 iters)\n",
      "[Epoch 18] iter 63/63, avg loss: 0.1325\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "BKD987Y                   | BKD487Y                   | 0.9443\n",
      "D053S                     | D353S                     | 0.8870\n",
      "ANN407L                   | ANN407L                   | 0.9453\n",
      "YFF06S                    | YFF06S                    | 0.9329\n",
      "S944W                     | S9444                     | 0.8442\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 18 done in 9.6s | train_loss=0.1325  valid_loss=0.1889  valid_acc=75.65%\n",
      "\n",
      "no improvement for 3/100 epochs\n",
      "\n",
      "→ Starting epoch 19  (printing every 63 iters)\n",
      "[Epoch 19] iter 63/63, avg loss: 0.0827\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "E3568Q                    | E3568Q                    | 0.9603\n",
      "J071                      | J071                      | 0.9584\n",
      "CIX3U                     | CIX3U                     | 0.9181\n",
      "EJ34L                     | EJ34L                     | 0.9320\n",
      "BE8                       | BE8                       | 0.9126\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 19 done in 10.1s | train_loss=0.0827  valid_loss=0.1947  valid_acc=76.35%\n",
      "\n",
      "💾 New best model saved (epoch 19, val_acc=76.35%)\n",
      "\n",
      "→ Starting epoch 20  (printing every 63 iters)\n",
      "[Epoch 20] iter 63/63, avg loss: 0.0282\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "NB6868                    | NB6868                    | 0.9900\n",
      "Y6                        | Y6                        | 0.9288\n",
      "VUI4W                     | VUI4W                     | 0.9575\n",
      "HX54L                     | HX54L                     | 0.8887\n",
      "J72                       | J72                       | 0.9946\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 20 done in 9.9s | train_loss=0.0282  valid_loss=0.2117  valid_acc=76.10%\n",
      "\n",
      "no improvement for 1/100 epochs\n",
      "\n",
      "→ Starting epoch 21  (printing every 63 iters)\n",
      "[Epoch 21] iter 63/63, avg loss: 0.0207\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "MF42A                     | MF42A                     | 0.9007\n",
      "VH0559                    | VH0559                    | 0.9724\n",
      "UX91I                     | UX91I                     | 0.9963\n",
      "IMU32Z                    | IMU32Z                    | 0.9505\n",
      "KCX5925                   | KCX5925                   | 0.9698\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 21 done in 10.0s | train_loss=0.0207  valid_loss=0.8619  valid_acc=63.35%\n",
      "\n",
      "no improvement for 2/100 epochs\n",
      "\n",
      "→ Starting epoch 22  (printing every 63 iters)\n",
      "[Epoch 22] iter 63/63, avg loss: 0.1803\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "UE8                       | UE8                       | 0.9859\n",
      "CZ7                       | CZ7                       | 0.9445\n",
      "DD1X                      | DD1X                      | 0.9779\n",
      "DVX650                    | DVX650                    | 0.9922\n",
      "M2                        | M2                        | 0.9659\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 22 done in 9.9s | train_loss=0.1803  valid_loss=0.1913  valid_acc=75.75%\n",
      "\n",
      "no improvement for 3/100 epochs\n",
      "\n",
      "→ Starting epoch 23  (printing every 63 iters)\n",
      "[Epoch 23] iter 63/63, avg loss: 0.0160\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "ALN766M                   | ALN766M                   | 0.9779\n",
      "PG5                       | PG5                       | 0.9532\n",
      "CR1F                      | CR1F                      | 0.9555\n",
      "YT596                     | YT596                     | 0.9944\n",
      "TTZ1B                     | TTZ1B                     | 0.9635\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 23 done in 10.0s | train_loss=0.0160  valid_loss=0.1953  valid_acc=76.55%\n",
      "\n",
      "💾 New best model saved (epoch 23, val_acc=76.55%)\n",
      "\n",
      "→ Starting epoch 24  (printing every 63 iters)\n",
      "[Epoch 24] iter 63/63, avg loss: 0.0973\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "JR578H                    | JR578H                    | 0.9322\n",
      "G6502                     | G6502                     | 0.9660\n",
      "SH58                      | SH58                      | 0.9481\n",
      "ZC40G                     | ZC40G                     | 0.9679\n",
      "TF6                       | TF6                       | 0.9490\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 24 done in 10.0s | train_loss=0.0973  valid_loss=0.2046  valid_acc=76.30%\n",
      "\n",
      "no improvement for 1/100 epochs\n",
      "\n",
      "→ Starting epoch 25  (printing every 63 iters)\n",
      "[Epoch 25] iter 63/63, avg loss: 0.0113\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "GSU280J                   | GSU280J                   | 0.9382\n",
      "WVB24V                    | WVB24V                    | 0.9480\n",
      "IR87Y                     | IR87Y                     | 0.9805\n",
      "A613U                     | A613U                     | 0.9770\n",
      "ZO675T                    | ZO675T                    | 0.9819\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 25 done in 9.9s | train_loss=0.0113  valid_loss=0.1996  valid_acc=76.80%\n",
      "\n",
      "💾 New best model saved (epoch 25, val_acc=76.80%)\n",
      "\n",
      "→ Starting epoch 26  (printing every 63 iters)\n",
      "[Epoch 26] iter 63/63, avg loss: 0.0046\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "AH750                     | AH750                     | 0.9994\n",
      "H021                      | H021                      | 0.9261\n",
      "QMQ69J                    | QMQ69J                    | 0.9453\n",
      "IEC363Z                   | IEC363Z                   | 0.9542\n",
      "TGQ5C                     | TGQ5C                     | 0.9751\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 26 done in 9.9s | train_loss=0.0046  valid_loss=0.2071  valid_acc=76.80%\n",
      "\n",
      "no improvement for 1/100 epochs\n",
      "\n",
      "→ Starting epoch 27  (printing every 63 iters)\n",
      "[Epoch 27] iter 63/63, avg loss: 0.0034\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "L4                        | L4                        | 0.9173\n",
      "C22E                      | C22E                      | 0.9971\n",
      "D4582                     | D4582                     | 0.9980\n",
      "AM7U                      | AM7U                      | 0.9781\n",
      "GP535                     | GP535                     | 0.9396\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 27 done in 9.9s | train_loss=0.0034  valid_loss=0.2078  valid_acc=76.90%\n",
      "\n",
      "💾 New best model saved (epoch 27, val_acc=76.90%)\n",
      "\n",
      "→ Starting epoch 28  (printing every 63 iters)\n",
      "[Epoch 28] iter 63/63, avg loss: 0.0021\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "YTX9989A                  | YTX9989A                  | 0.9709\n",
      "CA66                      | CA66                      | 0.9483\n",
      "OED9D                     | OED9D                     | 0.9863\n",
      "VRB39W                    | VRB39W                    | 0.9555\n",
      "V314U                     | V314U                     | 0.9733\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 28 done in 9.8s | train_loss=0.0021  valid_loss=0.2131  valid_acc=76.50%\n",
      "\n",
      "no improvement for 1/100 epochs\n",
      "\n",
      "→ Starting epoch 29  (printing every 63 iters)\n",
      "[Epoch 29] iter 63/63, avg loss: 0.0025\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "EUK1V                     | EUK1V                     | 0.9634\n",
      "Q710                      | Q710                      | 0.9363\n",
      "LUL387P                   | LUL387P                   | 0.9765\n",
      "VBK9092                   | VBK9092                   | 0.9763\n",
      "JI7721                    | JI7721                    | 0.9967\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 29 done in 9.7s | train_loss=0.0025  valid_loss=0.2143  valid_acc=76.60%\n",
      "\n",
      "no improvement for 2/100 epochs\n",
      "\n",
      "→ Starting epoch 30  (printing every 63 iters)\n",
      "[Epoch 30] iter 63/63, avg loss: 0.0659\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "F2558                     | F2558                     | 0.9494\n",
      "Y6829K                    | Y6829K                    | 0.9457\n",
      "WVS3                      | WVS3                      | 0.9679\n",
      "XQX1                      | XQX1                      | 0.9745\n",
      "BOR2                      | BOR2                      | 0.9839\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 30 done in 9.7s | train_loss=0.0659  valid_loss=0.2091  valid_acc=76.75%\n",
      "\n",
      "no improvement for 3/100 epochs\n",
      "\n",
      "→ Starting epoch 31  (printing every 63 iters)\n",
      "[Epoch 31] iter 63/63, avg loss: 0.0111\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QOY21G                    | QOY21G                    | 0.9801\n",
      "NYE0P                     | NYE0P                     | 0.9788\n",
      "FZ909D                    | FZ909D                    | 0.9659\n",
      "BWG2210                   | BWG2210                   | 0.9550\n",
      "A47                       | A47                       | 0.9733\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 31 done in 9.7s | train_loss=0.0111  valid_loss=0.2195  valid_acc=76.60%\n",
      "\n",
      "no improvement for 4/100 epochs\n",
      "\n",
      "→ Starting epoch 32  (printing every 63 iters)\n",
      "[Epoch 32] iter 63/63, avg loss: 0.0038\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "DNI2                      | DNI2                      | 0.9869\n",
      "DVP8                      | DVP8                      | 0.9878\n",
      "SAZ5270                   | SAZ5270                   | 0.9342\n",
      "U0452U                    | U0452U                    | 0.9647\n",
      "N1                        | N1                        | 0.9165\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 32 done in 9.8s | train_loss=0.0038  valid_loss=0.2146  valid_acc=77.10%\n",
      "\n",
      "💾 New best model saved (epoch 32, val_acc=77.10%)\n",
      "\n",
      "→ Starting epoch 33  (printing every 63 iters)\n",
      "[Epoch 33] iter 63/63, avg loss: 0.0019\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "OJC03E                    | OJC03E                    | 0.9575\n",
      "W65                       | W65                       | 0.9838\n",
      "F135Q                     | F135Q                     | 0.9830\n",
      "DZ9                       | DZ9                       | 0.9590\n",
      "LKM3806                   | LKM3806                   | 0.9949\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 33 done in 10.0s | train_loss=0.0019  valid_loss=0.2186  valid_acc=77.40%\n",
      "\n",
      "💾 New best model saved (epoch 33, val_acc=77.40%)\n",
      "\n",
      "→ Starting epoch 34  (printing every 63 iters)\n",
      "[Epoch 34] iter 63/63, avg loss: 0.0013\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "PJY477                    | PJY477                    | 0.9631\n",
      "Q2889L                    | Q2889L                    | 0.9694\n",
      "MTR32                     | MTR32                     | 0.9611\n",
      "FN6                       | FN6                       | 0.9662\n",
      "Z8584M                    | Z8584M                    | 0.9882\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 34 done in 9.9s | train_loss=0.0013  valid_loss=0.2221  valid_acc=77.20%\n",
      "\n",
      "no improvement for 1/100 epochs\n",
      "\n",
      "→ Starting epoch 35  (printing every 63 iters)\n",
      "[Epoch 35] iter 63/63, avg loss: 0.0010\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QW4942                    | QW4942                    | 0.9961\n",
      "LL8794                    | LL8794                    | 0.9883\n",
      "FYG0                      | FYG0                      | 0.9784\n",
      "TIW225                    | TIW225                    | 0.9964\n",
      "C356                      | C356                      | 0.9947\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 35 done in 10.0s | train_loss=0.0010  valid_loss=0.2257  valid_acc=77.15%\n",
      "\n",
      "no improvement for 2/100 epochs\n",
      "\n",
      "→ Starting epoch 36  (printing every 63 iters)\n",
      "[Epoch 36] iter 63/63, avg loss: 0.0009\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "LF2                       | LF2                       | 0.9487\n",
      "M5X                       | M5X                       | 0.9582\n",
      "HUY58                     | HUY58                     | 0.9970\n",
      "MMV51                     | MMV51                     | 0.9984\n",
      "K0Q                       | K0Q                       | 0.9787\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 36 done in 9.9s | train_loss=0.0009  valid_loss=0.2258  valid_acc=77.10%\n",
      "\n",
      "no improvement for 3/100 epochs\n",
      "\n",
      "→ Starting epoch 37  (printing every 63 iters)\n",
      "[Epoch 37] iter 63/63, avg loss: 0.0009\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "TMN4266                   | TMN4266                   | 0.9546\n",
      "KLS583B                   | KLS583B                   | 0.9877\n",
      "KCX5925                   | KCX5925                   | 0.9474\n",
      "C05P                      | C05P                      | 0.9819\n",
      "PW386                     | PW386                     | 0.9765\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 37 done in 10.0s | train_loss=0.0009  valid_loss=0.2325  valid_acc=76.05%\n",
      "\n",
      "no improvement for 4/100 epochs\n",
      "\n",
      "→ Starting epoch 38  (printing every 63 iters)\n",
      "[Epoch 38] iter 63/63, avg loss: 0.0011\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "H97                       | H97                       | 0.9436\n",
      "XA53J                     | XA53J                     | 0.9734\n",
      "GG06W                     | GG06W                     | 0.9866\n",
      "UHX9Z                     | UHX9Z                     | 0.9987\n",
      "TH8529                    | TH8529                    | 0.9827\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 38 done in 10.0s | train_loss=0.0011  valid_loss=0.2278  valid_acc=77.30%\n",
      "\n",
      "no improvement for 5/100 epochs\n",
      "\n",
      "→ Starting epoch 39  (printing every 63 iters)\n",
      "[Epoch 39] iter 63/63, avg loss: 0.0007\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "W3N                       | W3N                       | 0.9985\n",
      "RUM8P                     | RUM8P                     | 0.9719\n",
      "EU9Z                      | EU9Z                      | 0.9849\n",
      "XB591                     | XB591                     | 0.9733\n",
      "NEI0                      | NEI0                      | 0.9773\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 39 done in 9.7s | train_loss=0.0007  valid_loss=0.2277  valid_acc=77.00%\n",
      "\n",
      "no improvement for 6/100 epochs\n",
      "\n",
      "→ Starting epoch 40  (printing every 63 iters)\n",
      "[Epoch 40] iter 63/63, avg loss: 0.0006\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "GUM7A                     | GUM7A                     | 0.9527\n",
      "PVW292                    | PVW292                    | 0.9871\n",
      "KYJ8372                   | KYJ8372                   | 0.9892\n",
      "NJ16                      | NJ16                      | 0.9654\n",
      "C9Y                       | C9Y                       | 0.9355\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 40 done in 9.7s | train_loss=0.0006  valid_loss=0.2307  valid_acc=76.90%\n",
      "\n",
      "no improvement for 7/100 epochs\n",
      "\n",
      "→ Starting epoch 41  (printing every 63 iters)\n",
      "[Epoch 41] iter 63/63, avg loss: 0.0006\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "HO21A                     | HO21A                     | 0.9989\n",
      "DHM3577                   | DHM3577                   | 0.9975\n",
      "B501                      | B501                      | 0.9975\n",
      "AWF8                      | AWF8                      | 0.9950\n",
      "ZBP34                     | ZBP34                     | 0.9605\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 41 done in 9.8s | train_loss=0.0006  valid_loss=0.2326  valid_acc=76.95%\n",
      "\n",
      "no improvement for 8/100 epochs\n",
      "\n",
      "→ Starting epoch 42  (printing every 63 iters)\n",
      "[Epoch 42] iter 63/63, avg loss: 0.0005\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "EA33K                     | EA33K                     | 0.9866\n",
      "PKQ1T                     | PKQ1T                     | 0.9846\n",
      "VO16                      | VO16                      | 0.9944\n",
      "JX1734                    | JX1734                    | 0.9740\n",
      "BS449                     | BS449                     | 0.9595\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 42 done in 9.8s | train_loss=0.0005  valid_loss=0.2327  valid_acc=77.05%\n",
      "\n",
      "no improvement for 9/100 epochs\n",
      "\n",
      "→ Starting epoch 43  (printing every 63 iters)\n",
      "[Epoch 43] iter 63/63, avg loss: 0.0005\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "OUL9220                   | OUL9220                   | 0.9635\n",
      "PTV44L                    | PTV44L                    | 0.9883\n",
      "NDM406                    | NDM406                    | 0.9800\n",
      "P157Z                     | P157Z                     | 0.9148\n",
      "K8084                     | K8084                     | 0.9536\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 43 done in 9.7s | train_loss=0.0005  valid_loss=0.2331  valid_acc=77.20%\n",
      "\n",
      "no improvement for 10/100 epochs\n",
      "\n",
      "→ Starting epoch 44  (printing every 63 iters)\n",
      "[Epoch 44] iter 63/63, avg loss: 0.0005\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "GA98                      | GA98                      | 0.9470\n",
      "NL24                      | NL24                      | 0.9935\n",
      "IIB4054                   | IIB4054                   | 0.9990\n",
      "VFT3                      | VFT3                      | 0.9983\n",
      "DZ117                     | DZ117                     | 0.9824\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 44 done in 9.7s | train_loss=0.0005  valid_loss=0.2360  valid_acc=76.90%\n",
      "\n",
      "no improvement for 11/100 epochs\n",
      "\n",
      "→ Starting epoch 45  (printing every 63 iters)\n",
      "[Epoch 45] iter 63/63, avg loss: 0.0004\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "H052                      | H052                      | 0.9823\n",
      "EGI3J                     | EGI3J                     | 0.9783\n",
      "QLL506N                   | QLL506N                   | 0.9985\n",
      "YB94B                     | YB94B                     | 0.9632\n",
      "WJ7391                    | WJ7391                    | 0.9962\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 45 done in 9.8s | train_loss=0.0004  valid_loss=0.2363  valid_acc=76.90%\n",
      "\n",
      "no improvement for 12/100 epochs\n",
      "\n",
      "→ Starting epoch 46  (printing every 63 iters)\n",
      "[Epoch 46] iter 63/63, avg loss: 0.0004\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "JZY6727                   | JZY6727                   | 0.9921\n",
      "BF594                     | BF594                     | 0.9634\n",
      "Y56F                      | Y56F                      | 0.9659\n",
      "NUH185U                   | NUH185U                   | 0.9714\n",
      "U826                      | U826                      | 0.9968\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 46 done in 9.8s | train_loss=0.0004  valid_loss=0.2367  valid_acc=76.90%\n",
      "\n",
      "no improvement for 13/100 epochs\n",
      "\n",
      "→ Starting epoch 47  (printing every 63 iters)\n",
      "[Epoch 47] iter 63/63, avg loss: 0.0004\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "HI6546                    | HI6546                    | 0.9937\n",
      "Z6006                     | Z6006                     | 0.9982\n",
      "XJ2X                      | XJ2X                      | 0.9740\n",
      "H799Y                     | H799Y                     | 0.9491\n",
      "LQQ008                    | LQQ008                    | 0.9979\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 47 done in 9.8s | train_loss=0.0004  valid_loss=0.2385  valid_acc=77.05%\n",
      "\n",
      "no improvement for 14/100 epochs\n",
      "\n",
      "→ Starting epoch 48  (printing every 63 iters)\n",
      "[Epoch 48] iter 63/63, avg loss: 0.0004\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WME483A                   | WME483A                   | 0.9866\n",
      "M8                        | M8                        | 0.9989\n",
      "PBY5J                     | PBY5J                     | 0.9784\n",
      "POE0M                     | POE0M                     | 0.9913\n",
      "SUX4626                   | SUX4626                   | 0.9783\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 48 done in 9.7s | train_loss=0.0004  valid_loss=0.2406  valid_acc=76.75%\n",
      "\n",
      "no improvement for 15/100 epochs\n",
      "\n",
      "→ Starting epoch 49  (printing every 63 iters)\n",
      "[Epoch 49] iter 63/63, avg loss: 0.0004\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "KS6                       | KS6                       | 0.9934\n",
      "EOT4417D                  | EOT4417D                  | 0.9243\n",
      "UY25D                     | UY25D                     | 0.9744\n",
      "MWA08B                    | MWA08B                    | 0.9979\n",
      "JH4882                    | JH4882                    | 0.9765\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 49 done in 9.7s | train_loss=0.0004  valid_loss=0.2384  valid_acc=77.05%\n",
      "\n",
      "no improvement for 16/100 epochs\n",
      "\n",
      "→ Starting epoch 50  (printing every 63 iters)\n",
      "[Epoch 50] iter 63/63, avg loss: 0.0004\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "P6T                       | P6T                       | 0.9998\n",
      "HB268                     | HB268                     | 0.9802\n",
      "O160O                     | O160O                     | 0.9701\n",
      "L8N                       | L8N                       | 0.9984\n",
      "ZOA834X                   | ZOA834X                   | 0.9987\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 50 done in 9.8s | train_loss=0.0004  valid_loss=0.2403  valid_acc=76.90%\n",
      "\n",
      "no improvement for 17/100 epochs\n",
      "\n",
      "→ Starting epoch 51  (printing every 63 iters)\n",
      "[Epoch 51] iter 63/63, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "Y04S                      | Y04S                      | 0.9791\n",
      "Z4036                     | Z4036                     | 0.9738\n",
      "LGT303                    | LGT303                    | 0.9480\n",
      "SRV899P                   | SRV899P                   | 0.9665\n",
      "DL4770R                   | DL4770R                   | 0.9806\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 51 done in 9.8s | train_loss=0.0003  valid_loss=0.2406  valid_acc=77.00%\n",
      "\n",
      "no improvement for 18/100 epochs\n",
      "\n",
      "→ Starting epoch 52  (printing every 63 iters)\n",
      "[Epoch 52] iter 63/63, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "CEF125                    | CEF125                    | 0.9941\n",
      "M8186X                    | M8186X                    | 0.9694\n",
      "LG18                      | LG18                      | 0.9871\n",
      "W65                       | W65                       | 0.9802\n",
      "ZHK5                      | ZHK5                      | 0.9922\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 52 done in 9.7s | train_loss=0.0003  valid_loss=0.2417  valid_acc=76.95%\n",
      "\n",
      "no improvement for 19/100 epochs\n",
      "\n",
      "→ Starting epoch 53  (printing every 63 iters)\n",
      "[Epoch 53] iter 63/63, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "SL51                      | SL51                      | 0.9977\n",
      "V0N                       | V0N                       | 0.9930\n",
      "FC9Y                      | FC9Y                      | 0.9968\n",
      "R984                      | R984                      | 0.9579\n",
      "RSN756Z                   | RSN756Z                   | 0.9815\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 53 done in 9.8s | train_loss=0.0003  valid_loss=0.2412  valid_acc=76.90%\n",
      "\n",
      "no improvement for 20/100 epochs\n",
      "\n",
      "→ Starting epoch 54  (printing every 63 iters)\n",
      "[Epoch 54] iter 63/63, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "JR578H                    | JR578H                    | 0.9955\n",
      "BN71K                     | BN71K                     | 0.9719\n",
      "J30                       | J30                       | 0.9846\n",
      "QMP4                      | QMP4                      | 0.9803\n",
      "BK9V                      | BK9V                      | 0.9994\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 54 done in 10.1s | train_loss=0.0003  valid_loss=0.2424  valid_acc=77.00%\n",
      "\n",
      "no improvement for 21/100 epochs\n",
      "\n",
      "→ Starting epoch 55  (printing every 63 iters)\n",
      "[Epoch 55] iter 63/63, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "B5                        | B5                        | 0.9987\n",
      "JU8015B                   | JU8015B                   | 0.9679\n",
      "WZ5201                    | WZ5201                    | 0.9811\n",
      "MF82                      | MF82                      | 0.9942\n",
      "BN0129X                   | BN0129X                   | 0.9995\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 55 done in 10.0s | train_loss=0.0003  valid_loss=0.2429  valid_acc=76.90%\n",
      "\n",
      "no improvement for 22/100 epochs\n",
      "\n",
      "→ Starting epoch 56  (printing every 63 iters)\n",
      "[Epoch 56] iter 63/63, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "K305                      | K305                      | 0.9983\n",
      "MH66A                     | MH66A                     | 0.9486\n",
      "KCL91                     | KCL91                     | 0.9762\n",
      "O848O                     | O848O                     | 0.9877\n",
      "QI93                      | QI93                      | 0.9895\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 56 done in 9.8s | train_loss=0.0003  valid_loss=0.2455  valid_acc=76.90%\n",
      "\n",
      "no improvement for 23/100 epochs\n",
      "\n",
      "→ Starting epoch 57  (printing every 63 iters)\n",
      "[Epoch 57] iter 63/63, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "FJ77S                     | FJ77S                     | 0.9731\n",
      "OM1438T                   | OM1438T                   | 0.9982\n",
      "M75                       | M75                       | 0.9869\n",
      "EBO245                    | EBO245                    | 0.9756\n",
      "T9Z                       | T9Z                       | 0.9719\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 57 done in 10.2s | train_loss=0.0003  valid_loss=0.2456  valid_acc=77.00%\n",
      "\n",
      "no improvement for 24/100 epochs\n",
      "\n",
      "→ Starting epoch 58  (printing every 63 iters)\n",
      "[Epoch 58] iter 63/63, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "NI200                     | NI200                     | 0.9620\n",
      "P3                        | P3                        | 0.9581\n",
      "BUJ04E                    | BUJ04E                    | 0.9643\n",
      "S714                      | S714                      | 0.9878\n",
      "QG6L                      | QG6L                      | 0.9455\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 58 done in 9.9s | train_loss=0.0003  valid_loss=0.2450  valid_acc=76.95%\n",
      "\n",
      "no improvement for 25/100 epochs\n",
      "\n",
      "→ Starting epoch 59  (printing every 63 iters)\n",
      "[Epoch 59] iter 63/63, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "I6                        | I6                        | 0.9556\n",
      "IA3782                    | IA3782                    | 0.9694\n",
      "EQ8X                      | EQ8X                      | 0.9814\n",
      "TSC1B                     | TSC1B                     | 0.9756\n",
      "CFW7689Y                  | CFW7689Y                  | 0.9733\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 59 done in 10.0s | train_loss=0.0003  valid_loss=0.2446  valid_acc=76.90%\n",
      "\n",
      "no improvement for 26/100 epochs\n",
      "\n",
      "→ Starting epoch 60  (printing every 63 iters)\n",
      "[Epoch 60] iter 63/63, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "O880O                     | O880O                     | 0.9699\n",
      "VMH895                    | VMH895                    | 0.9960\n",
      "Y442                      | Y442                      | 0.9839\n",
      "M14X                      | M14X                      | 0.9579\n",
      "IG611                     | IG611                     | 0.9815\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 60 done in 9.9s | train_loss=0.0003  valid_loss=0.2445  valid_acc=76.95%\n",
      "\n",
      "no improvement for 27/100 epochs\n",
      "\n",
      "→ Starting epoch 61  (printing every 63 iters)\n",
      "[Epoch 61] iter 63/63, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "FL57M                     | FL57M                     | 0.9897\n",
      "T085                      | T085                      | 0.9954\n",
      "Y2395                     | Y2395                     | 0.9997\n",
      "DZ9                       | DZ9                       | 0.9933\n",
      "OU372I                    | OU372I                    | 0.9973\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 61 done in 9.7s | train_loss=0.0002  valid_loss=0.2463  valid_acc=76.90%\n",
      "\n",
      "no improvement for 28/100 epochs\n",
      "\n",
      "→ Starting epoch 62  (printing every 63 iters)\n",
      "[Epoch 62] iter 63/63, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "GCK93                     | GCK93                     | 0.9984\n",
      "A11T                      | A11T                      | 0.9713\n",
      "NAD680B                   | NAD680B                   | 0.9985\n",
      "WDA7719                   | WDA7719                   | 0.9977\n",
      "XUC0961                   | XUC0961                   | 0.9824\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 62 done in 9.7s | train_loss=0.0002  valid_loss=0.2482  valid_acc=76.90%\n",
      "\n",
      "no improvement for 29/100 epochs\n",
      "\n",
      "→ Starting epoch 63  (printing every 63 iters)\n",
      "[Epoch 63] iter 63/63, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "N816                      | N816                      | 0.9515\n",
      "K3188                     | K3188                     | 0.9824\n",
      "BS409T                    | BS409T                    | 0.9942\n",
      "QD30                      | QD30                      | 0.9998\n",
      "ZLB255H                   | ZLB255H                   | 0.9986\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 63 done in 9.8s | train_loss=0.0002  valid_loss=0.2476  valid_acc=76.80%\n",
      "\n",
      "no improvement for 30/100 epochs\n",
      "\n",
      "→ Starting epoch 64  (printing every 63 iters)\n",
      "[Epoch 64] iter 63/63, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "KI0552K                   | KI0552K                   | 0.9681\n",
      "T3252                     | T3252                     | 0.9686\n",
      "XBR1                      | XBR1                      | 0.9863\n",
      "SOA2                      | SOA2                      | 0.9875\n",
      "EIZ47                     | EIZ47                     | 0.9752\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 64 done in 10.0s | train_loss=0.0002  valid_loss=0.2489  valid_acc=76.80%\n",
      "\n",
      "no improvement for 31/100 epochs\n",
      "\n",
      "→ Starting epoch 65  (printing every 63 iters)\n",
      "[Epoch 65] iter 63/63, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "HP5187K                   | HP5187K                   | 0.9659\n",
      "D2T                       | D2T                       | 0.9707\n",
      "ERZ83F                    | ERZ83F                    | 0.9731\n",
      "LIQ709U                   | LIQ709U                   | 0.9967\n",
      "BOT78                     | BOT78                     | 0.9835\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 65 done in 9.9s | train_loss=0.0002  valid_loss=0.2486  valid_acc=76.80%\n",
      "\n",
      "no improvement for 32/100 epochs\n",
      "\n",
      "→ Starting epoch 66  (printing every 63 iters)\n",
      "[Epoch 66] iter 63/63, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "I1561                     | I1561                     | 0.9848\n",
      "HFK192O                   | HFK192O                   | 0.9838\n",
      "VT8873V                   | VT8873V                   | 0.9996\n",
      "M229R                     | M229R                     | 0.9952\n",
      "ZH3367H                   | ZH3367H                   | 0.9773\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 66 done in 10.1s | train_loss=0.0002  valid_loss=0.2493  valid_acc=76.90%\n",
      "\n",
      "no improvement for 33/100 epochs\n",
      "\n",
      "→ Starting epoch 67  (printing every 63 iters)\n",
      "[Epoch 67] iter 63/63, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "J7763O                    | J7763O                    | 0.9825\n",
      "GJO1                      | GJO1                      | 0.9987\n",
      "NWJ8                      | NWJ8                      | 0.9944\n",
      "UMY99F                    | UMY99F                    | 0.9937\n",
      "H79Z                      | H79Z                      | 0.9606\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 67 done in 10.2s | train_loss=0.0002  valid_loss=0.2490  valid_acc=76.90%\n",
      "\n",
      "no improvement for 34/100 epochs\n",
      "\n",
      "→ Starting epoch 68  (printing every 63 iters)\n",
      "[Epoch 68] iter 63/63, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VAY0I                     | VAY0I                     | 0.9808\n",
      "N28L                      | N28L                      | 0.9752\n",
      "FXV5873Z                  | FXV5873Z                  | 0.9559\n",
      "QY7518                    | QY7518                    | 0.9958\n",
      "DKL520                    | DKL520                    | 0.9975\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 68 done in 10.1s | train_loss=0.0002  valid_loss=0.2496  valid_acc=76.95%\n",
      "\n",
      "no improvement for 35/100 epochs\n",
      "\n",
      "→ Starting epoch 69  (printing every 63 iters)\n",
      "[Epoch 69] iter 63/63, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "HPM479D                   | HPM479D                   | 0.9775\n",
      "CA66                      | CA66                      | 0.9805\n",
      "UA4438                    | UA4438                    | 0.9997\n",
      "T848                      | T848                      | 0.9908\n",
      "DGF55                     | DGF55                     | 0.9985\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 69 done in 9.8s | train_loss=0.0002  valid_loss=0.2509  valid_acc=76.85%\n",
      "\n",
      "no improvement for 36/100 epochs\n",
      "\n",
      "→ Starting epoch 70  (printing every 63 iters)\n",
      "[Epoch 70] iter 63/63, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "TF2                       | TF2                       | 0.9808\n",
      "UF6                       | UF6                       | 0.9722\n",
      "IFJ755W                   | IFJ755W                   | 0.9721\n",
      "VP0775                    | VP0775                    | 0.9968\n",
      "GB6163                    | GB6163                    | 0.9947\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 70 done in 9.8s | train_loss=0.0002  valid_loss=0.2535  valid_acc=76.85%\n",
      "\n",
      "no improvement for 37/100 epochs\n",
      "\n",
      "→ Starting epoch 71  (printing every 63 iters)\n",
      "[Epoch 71] iter 63/63, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "KDK9A                     | KDK9A                     | 0.9977\n",
      "A2597                     | A2597                     | 0.9739\n",
      "KT2                       | KT2                       | 0.9841\n",
      "GKR6S                     | GKR6S                     | 0.9966\n",
      "R641H                     | R641H                     | 0.9633\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 71 done in 9.9s | train_loss=0.0002  valid_loss=0.2504  valid_acc=77.05%\n",
      "\n",
      "no improvement for 38/100 epochs\n",
      "\n",
      "→ Starting epoch 72  (printing every 63 iters)\n",
      "[Epoch 72] iter 63/63, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "M08                       | M08                       | 0.9728\n",
      "DT88Z                     | DT88Z                     | 0.9774\n",
      "F84P                      | F84P                      | 0.9839\n",
      "FYE507J                   | FYE507J                   | 0.9773\n",
      "RTK5203                   | RTK5203                   | 0.9943\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 72 done in 9.8s | train_loss=0.0002  valid_loss=0.2500  valid_acc=77.00%\n",
      "\n",
      "no improvement for 39/100 epochs\n",
      "\n",
      "→ Starting epoch 73  (printing every 63 iters)\n",
      "[Epoch 73] iter 63/63, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "FY81                      | FY81                      | 0.9767\n",
      "G4698                     | G4698                     | 0.9870\n",
      "G8Y                       | G8Y                       | 0.9611\n",
      "SP365                     | SP365                     | 0.9784\n",
      "DVP8                      | DVP8                      | 0.9683\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 73 done in 9.8s | train_loss=0.0002  valid_loss=0.2520  valid_acc=76.95%\n",
      "\n",
      "no improvement for 40/100 epochs\n",
      "\n",
      "→ Starting epoch 74  (printing every 63 iters)\n",
      "[Epoch 74] iter 63/63, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "ON847                     | ON847                     | 0.9982\n",
      "A7L                       | A7L                       | 0.9837\n",
      "DU177                     | DU177                     | 0.9985\n",
      "IG4754E                   | IG4754E                   | 0.9842\n",
      "VED84                     | VED84                     | 0.9978\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 74 done in 9.9s | train_loss=0.0002  valid_loss=0.2520  valid_acc=77.00%\n",
      "\n",
      "no improvement for 41/100 epochs\n",
      "\n",
      "→ Starting epoch 75  (printing every 63 iters)\n",
      "[Epoch 75] iter 63/63, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "K5255F                    | K5255F                    | 0.9933\n",
      "WY01                      | WY01                      | 0.9596\n",
      "H8561                     | H8561                     | 0.9725\n",
      "EBG80L                    | EBG80L                    | 0.9850\n",
      "EBE542V                   | EBE542V                   | 0.9979\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 75 done in 9.9s | train_loss=0.0002  valid_loss=0.2547  valid_acc=76.95%\n",
      "\n",
      "no improvement for 42/100 epochs\n",
      "\n",
      "→ Starting epoch 76  (printing every 63 iters)\n",
      "[Epoch 76] iter 63/63, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "W453                      | W453                      | 0.9996\n",
      "CEI7698                   | CEI7698                   | 0.9953\n",
      "Z63G                      | Z63G                      | 0.9993\n",
      "J0859C                    | J0859C                    | 0.9591\n",
      "MD34O                     | MD34O                     | 0.9724\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 76 done in 9.8s | train_loss=0.0002  valid_loss=0.2537  valid_acc=77.00%\n",
      "\n",
      "no improvement for 43/100 epochs\n",
      "\n",
      "→ Starting epoch 77  (printing every 63 iters)\n",
      "[Epoch 77] iter 63/63, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QQW72                     | QQW72                     | 0.9566\n",
      "OXJ7C                     | OXJ7C                     | 0.9634\n",
      "FN9905K                   | FN9905K                   | 0.9647\n",
      "NW149                     | NW149                     | 0.9995\n",
      "X241X                     | X241X                     | 0.9763\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 77 done in 9.8s | train_loss=0.0002  valid_loss=0.2533  valid_acc=77.05%\n",
      "\n",
      "no improvement for 44/100 epochs\n",
      "\n",
      "→ Starting epoch 78  (printing every 63 iters)\n",
      "[Epoch 78] iter 63/63, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "JLM7688                   | JLM7688                   | 0.9883\n",
      "I678                      | I678                      | 0.9957\n",
      "NNU2178                   | NNU2178                   | 0.9689\n",
      "VOT4350S                  | VOT4350S                  | 0.9688\n",
      "P10I                      | P10I                      | 0.9747\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 78 done in 9.9s | train_loss=0.0002  valid_loss=0.2539  valid_acc=77.00%\n",
      "\n",
      "no improvement for 45/100 epochs\n",
      "\n",
      "→ Starting epoch 79  (printing every 63 iters)\n",
      "[Epoch 79] iter 63/63, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "SH58                      | SH58                      | 0.9789\n",
      "MY8501N                   | MY8501N                   | 0.9679\n",
      "FT96                      | FT96                      | 0.9604\n",
      "THY0Z                     | THY0Z                     | 0.9913\n",
      "QYF86                     | QYF86                     | 0.9805\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 79 done in 9.8s | train_loss=0.0002  valid_loss=0.2565  valid_acc=76.70%\n",
      "\n",
      "no improvement for 46/100 epochs\n",
      "\n",
      "→ Starting epoch 80  (printing every 63 iters)\n",
      "[Epoch 80] iter 63/63, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "G3327                     | G3327                     | 0.9770\n",
      "B0J                       | B0J                       | 0.9843\n",
      "PDM04H                    | PDM04H                    | 0.9813\n",
      "Z4272                     | Z4272                     | 0.9884\n",
      "UJV5Q                     | UJV5Q                     | 0.9773\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 80 done in 9.9s | train_loss=0.0002  valid_loss=0.2556  valid_acc=76.95%\n",
      "\n",
      "no improvement for 47/100 epochs\n",
      "\n",
      "→ Starting epoch 81  (printing every 63 iters)\n",
      "[Epoch 81] iter 63/63, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "D10U                      | D10U                      | 0.9518\n",
      "HG758S                    | HG758S                    | 0.9822\n",
      "YIP10S                    | YIP10S                    | 0.9875\n",
      "L4                        | L4                        | 0.9674\n",
      "HNN846Z                   | HNN846Z                   | 0.9926\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 81 done in 9.8s | train_loss=0.0002  valid_loss=0.2539  valid_acc=76.95%\n",
      "\n",
      "no improvement for 48/100 epochs\n",
      "\n",
      "→ Starting epoch 82  (printing every 63 iters)\n",
      "[Epoch 82] iter 63/63, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "HKE401Z                   | HKE401Z                   | 0.9903\n",
      "PVZ2T                     | PVZ2T                     | 0.9715\n",
      "J8M                       | J8M                       | 0.9989\n",
      "ES057M                    | ES057M                    | 0.9944\n",
      "E0                        | E0                        | 0.9563\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 82 done in 9.8s | train_loss=0.0002  valid_loss=0.2551  valid_acc=76.80%\n",
      "\n",
      "no improvement for 49/100 epochs\n",
      "\n",
      "→ Starting epoch 83  (printing every 63 iters)\n",
      "[Epoch 83] iter 63/63, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "IG236G                    | IG236G                    | 0.9690\n",
      "S3                        | S3                        | 0.9974\n",
      "T5031Q                    | T5031Q                    | 0.9976\n",
      "Y371                      | Y371                      | 0.9803\n",
      "AB1J                      | AB1J                      | 0.9908\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 83 done in 9.8s | train_loss=0.0002  valid_loss=0.2564  valid_acc=76.90%\n",
      "\n",
      "no improvement for 50/100 epochs\n",
      "\n",
      "→ Starting epoch 84  (printing every 63 iters)\n",
      "[Epoch 84] iter 63/63, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "MQ2235                    | MQ2235                    | 0.9867\n",
      "VB1                       | VB1                       | 0.9853\n",
      "GFT60D                    | GFT60D                    | 0.9993\n",
      "AOG6979Y                  | AOG6979Y                  | 0.9660\n",
      "PB90                      | PB90                      | 0.9809\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 84 done in 9.8s | train_loss=0.0001  valid_loss=0.2554  valid_acc=76.90%\n",
      "\n",
      "no improvement for 51/100 epochs\n",
      "\n",
      "→ Starting epoch 85  (printing every 63 iters)\n",
      "[Epoch 85] iter 63/63, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QBA4C                     | QBA4C                     | 0.9971\n",
      "HOI454                    | HOI454                    | 0.9986\n",
      "D747                      | D747                      | 0.9759\n",
      "W224P                     | W224P                     | 0.9941\n",
      "H13                       | H13                       | 0.9939\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 85 done in 9.8s | train_loss=0.0001  valid_loss=0.2574  valid_acc=76.80%\n",
      "\n",
      "no improvement for 52/100 epochs\n",
      "\n",
      "→ Starting epoch 86  (printing every 63 iters)\n",
      "[Epoch 86] iter 63/63, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "O5Q                       | O5Q                       | 0.9998\n",
      "J52Z                      | J52Z                      | 0.9843\n",
      "A07P                      | A07P                      | 0.9925\n",
      "ALV8                      | ALV8                      | 0.9986\n",
      "M9                        | M9                        | 0.9996\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 86 done in 9.8s | train_loss=0.0001  valid_loss=0.2554  valid_acc=76.75%\n",
      "\n",
      "no improvement for 53/100 epochs\n",
      "\n",
      "→ Starting epoch 87  (printing every 63 iters)\n",
      "[Epoch 87] iter 63/63, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "TBD2322Q                  | TBD2322Q                  | 0.9907\n",
      "AFR3M                     | AFR3M                     | 0.9205\n",
      "G37                       | G37                       | 0.9991\n",
      "JZN755                    | JZN755                    | 0.9792\n",
      "L2007D                    | L2007D                    | 0.9716\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 87 done in 9.8s | train_loss=0.0001  valid_loss=0.2579  valid_acc=76.80%\n",
      "\n",
      "no improvement for 54/100 epochs\n",
      "\n",
      "→ Starting epoch 88  (printing every 63 iters)\n",
      "[Epoch 88] iter 63/63, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "SRD2                      | SRD2                      | 0.9725\n",
      "MGP40                     | MGP40                     | 0.9990\n",
      "BF11                      | BF11                      | 0.9851\n",
      "TXJ641O                   | TXJ641O                   | 0.9989\n",
      "E49                       | E49                       | 0.9314\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 88 done in 9.8s | train_loss=0.0001  valid_loss=0.2570  valid_acc=76.90%\n",
      "\n",
      "no improvement for 55/100 epochs\n",
      "\n",
      "→ Starting epoch 89  (printing every 63 iters)\n",
      "[Epoch 89] iter 63/63, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "R33D                      | R33D                      | 0.9546\n",
      "ZDB75                     | ZDB75                     | 0.9988\n",
      "JG1176P                   | JG1176P                   | 0.9892\n",
      "DF4165Y                   | DF4165Y                   | 0.9640\n",
      "LZA3                      | LZA3                      | 0.9976\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 89 done in 9.8s | train_loss=0.0001  valid_loss=0.2569  valid_acc=76.90%\n",
      "\n",
      "no improvement for 56/100 epochs\n",
      "\n",
      "→ Starting epoch 90  (printing every 63 iters)\n",
      "[Epoch 90] iter 63/63, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "TE2L                      | TE2L                      | 0.9986\n",
      "GMH1U                     | GMH1U                     | 0.9767\n",
      "JM25R                     | JM25R                     | 0.9841\n",
      "V846                      | V846                      | 0.9826\n",
      "E9                        | E9                        | 0.9994\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 90 done in 9.8s | train_loss=0.0001  valid_loss=0.2563  valid_acc=76.95%\n",
      "\n",
      "no improvement for 57/100 epochs\n",
      "\n",
      "→ Starting epoch 91  (printing every 63 iters)\n",
      "[Epoch 91] iter 63/63, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "RBY5953P                  | RBY5953P                  | 0.9949\n",
      "OM1438T                   | OM1438T                   | 0.9887\n",
      "CN1                       | CN1                       | 0.9863\n",
      "IYU6367O                  | IYU6367O                  | 0.9893\n",
      "SH2372D                   | SH2372D                   | 0.9846\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 91 done in 9.7s | train_loss=0.0001  valid_loss=0.2575  valid_acc=76.90%\n",
      "\n",
      "no improvement for 58/100 epochs\n",
      "\n",
      "→ Starting epoch 92  (printing every 63 iters)\n",
      "[Epoch 92] iter 63/63, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "BM8                       | BM8                       | 0.9970\n",
      "CY679                     | CY679                     | 0.9712\n",
      "FOE997Q                   | FOE997Q                   | 0.9973\n",
      "EFZ52                     | EFZ52                     | 0.9759\n",
      "EL9                       | EL9                       | 0.9611\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 92 done in 9.8s | train_loss=0.0001  valid_loss=0.2585  valid_acc=76.95%\n",
      "\n",
      "no improvement for 59/100 epochs\n",
      "\n",
      "→ Starting epoch 93  (printing every 63 iters)\n",
      "[Epoch 93] iter 63/63, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "FFT5109                   | FFT5109                   | 0.9873\n",
      "BPX4                      | BPX4                      | 0.9826\n",
      "JP9                       | JP9                       | 0.9473\n",
      "DUP95W                    | DUP95W                    | 0.9705\n",
      "CW1210                    | CW1210                    | 0.9985\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 93 done in 9.8s | train_loss=0.0001  valid_loss=0.2595  valid_acc=76.85%\n",
      "\n",
      "no improvement for 60/100 epochs\n",
      "\n",
      "→ Starting epoch 94  (printing every 63 iters)\n",
      "[Epoch 94] iter 63/63, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "J2693                     | J2693                     | 0.9994\n",
      "F49                       | F49                       | 0.9926\n",
      "SIW1N                     | SIW1N                     | 0.9984\n",
      "N6D                       | N6D                       | 0.9291\n",
      "NEI9304                   | NEI9304                   | 0.9782\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 94 done in 9.9s | train_loss=0.0001  valid_loss=0.2572  valid_acc=76.90%\n",
      "\n",
      "no improvement for 61/100 epochs\n",
      "\n",
      "→ Starting epoch 95  (printing every 63 iters)\n",
      "[Epoch 95] iter 63/63, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "J9N                       | J9N                       | 0.9996\n",
      "X3                        | X3                        | 0.9987\n",
      "W186                      | W186                      | 0.9874\n",
      "OZQ7J                     | OZQ7J                     | 0.9959\n",
      "CN55                      | CN55                      | 0.9949\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 95 done in 9.7s | train_loss=0.0001  valid_loss=0.2589  valid_acc=76.90%\n",
      "\n",
      "no improvement for 62/100 epochs\n",
      "\n",
      "→ Starting epoch 96  (printing every 63 iters)\n",
      "[Epoch 96] iter 63/63, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "LH2443S                   | LH2443S                   | 0.9963\n",
      "X0                        | X0                        | 0.9974\n",
      "SAZ5270                   | SAZ5270                   | 0.9856\n",
      "E7W                       | E7W                       | 0.9733\n",
      "RRH6S                     | RRH6S                     | 0.9932\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 96 done in 9.9s | train_loss=0.0001  valid_loss=0.2591  valid_acc=76.95%\n",
      "\n",
      "no improvement for 63/100 epochs\n",
      "\n",
      "→ Starting epoch 97  (printing every 63 iters)\n",
      "[Epoch 97] iter 63/63, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "D82U                      | D82U                      | 0.9708\n",
      "RGE0P                     | RGE0P                     | 0.9765\n",
      "Q5W                       | Q5W                       | 0.9874\n",
      "KQC9                      | KQC9                      | 0.9939\n",
      "QC0931                    | QC0931                    | 0.9771\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 97 done in 9.8s | train_loss=0.0001  valid_loss=0.2585  valid_acc=76.95%\n",
      "\n",
      "no improvement for 64/100 epochs\n",
      "\n",
      "→ Starting epoch 98  (printing every 63 iters)\n",
      "[Epoch 98] iter 63/63, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "NNU2178                   | NNU2178                   | 0.9808\n",
      "EOB1152                   | EOB1152                   | 0.9998\n",
      "TC26                      | TC26                      | 0.9966\n",
      "TU4187B                   | TU4187B                   | 0.9722\n",
      "VAE53Q                    | VAE53Q                    | 0.9520\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 98 done in 9.9s | train_loss=0.0001  valid_loss=0.2596  valid_acc=76.95%\n",
      "\n",
      "no improvement for 65/100 epochs\n",
      "\n",
      "→ Starting epoch 99  (printing every 63 iters)\n",
      "[Epoch 99] iter 63/63, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "BV0Q                      | BV0Q                      | 0.9509\n",
      "JDA5                      | JDA5                      | 0.9907\n",
      "AG5                       | AG5                       | 0.9943\n",
      "R70                       | R70                       | 0.9967\n",
      "VB09G                     | VB09G                     | 0.9822\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 99 done in 10.0s | train_loss=0.0001  valid_loss=0.2588  valid_acc=76.95%\n",
      "\n",
      "no improvement for 66/100 epochs\n",
      "\n",
      "→ Starting epoch 100  (printing every 63 iters)\n",
      "[Epoch 100] iter 63/63, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "AGR1604                   | AGR1604                   | 0.9758\n",
      "X5                        | X5                        | 0.9989\n",
      "MSK871                    | MSK871                    | 0.9831\n",
      "G090                      | G090                      | 0.9998\n",
      "BEN7                      | BEN7                      | 0.9874\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 100 done in 9.8s | train_loss=0.0001  valid_loss=0.2606  valid_acc=76.95%\n",
      "\n",
      "no improvement for 67/100 epochs\n",
      "\n",
      "→ Starting epoch 101  (printing every 63 iters)\n",
      "[Epoch 101] iter 63/63, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "TL7429                    | TL7429                    | 0.9833\n",
      "AA2A                      | AA2A                      | 0.9982\n",
      "B5798                     | B5798                     | 0.9987\n",
      "IQK68Y                    | IQK68Y                    | 0.9827\n",
      "JPA57                     | JPA57                     | 0.9821\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 101 done in 9.9s | train_loss=0.0001  valid_loss=0.2596  valid_acc=76.85%\n",
      "\n",
      "no improvement for 68/100 epochs\n",
      "\n",
      "→ Starting epoch 102  (printing every 63 iters)\n",
      "[Epoch 102] iter 63/63, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "TH40                      | TH40                      | 0.9693\n",
      "O502                      | O502                      | 0.9833\n",
      "CD4                       | CD4                       | 0.9735\n",
      "X734M                     | X734M                     | 0.9735\n",
      "OJM5                      | OJM5                      | 0.9986\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 102 done in 9.8s | train_loss=0.0001  valid_loss=0.2610  valid_acc=76.95%\n",
      "\n",
      "no improvement for 69/100 epochs\n",
      "\n",
      "→ Starting epoch 103  (printing every 63 iters)\n",
      "[Epoch 103] iter 63/63, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "TL7106I                   | TL7106I                   | 0.9548\n",
      "Y6                        | Y6                        | 0.9441\n",
      "ZN1788                    | ZN1788                    | 0.9854\n",
      "Q48                       | Q48                       | 0.9905\n",
      "FGP5F                     | FGP5F                     | 0.9955\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 103 done in 9.8s | train_loss=0.0001  valid_loss=0.2602  valid_acc=76.90%\n",
      "\n",
      "no improvement for 70/100 epochs\n",
      "\n",
      "→ Starting epoch 104  (printing every 63 iters)\n",
      "[Epoch 104] iter 63/63, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "ZOE04N                    | ZOE04N                    | 0.9625\n",
      "KQB8910                   | KQB8910                   | 0.9940\n",
      "PQ0990X                   | PQ0990X                   | 0.9811\n",
      "L2175                     | L2175                     | 0.9935\n",
      "KE1392V                   | KE1392V                   | 0.9994\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 104 done in 9.7s | train_loss=0.0001  valid_loss=0.2617  valid_acc=76.90%\n",
      "\n",
      "no improvement for 71/100 epochs\n",
      "\n",
      "→ Starting epoch 105  (printing every 63 iters)\n",
      "[Epoch 105] iter 63/63, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "APN18                     | APN18                     | 0.9806\n",
      "E3568Q                    | E3568Q                    | 0.9791\n",
      "QD50E                     | QD50E                     | 0.9713\n",
      "SMN51                     | SMN51                     | 0.9967\n",
      "DM71                      | DM71                      | 0.9895\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 105 done in 9.9s | train_loss=0.0001  valid_loss=0.2619  valid_acc=76.85%\n",
      "\n",
      "no improvement for 72/100 epochs\n",
      "\n",
      "→ Starting epoch 106  (printing every 63 iters)\n",
      "[Epoch 106] iter 63/63, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "L573                      | L573                      | 0.9947\n",
      "NBZ210                    | NBZ210                    | 0.9990\n",
      "AWZ8                      | AWZ8                      | 0.9973\n",
      "D16                       | D16                       | 0.9690\n",
      "EM56C                     | EM56C                     | 0.9984\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 106 done in 9.8s | train_loss=0.0001  valid_loss=0.2625  valid_acc=76.75%\n",
      "\n",
      "no improvement for 73/100 epochs\n",
      "\n",
      "→ Starting epoch 107  (printing every 63 iters)\n",
      "[Epoch 107] iter 63/63, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "GS1205M                   | GS1205M                   | 0.9834\n",
      "B6E                       | B6E                       | 0.9375\n",
      "V40                       | V40                       | 0.9920\n",
      "VC198M                    | VC198M                    | 0.9776\n",
      "ZDQ2530R                  | ZDQ2530R                  | 0.9988\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 107 done in 9.7s | train_loss=0.0001  valid_loss=0.2617  valid_acc=76.80%\n",
      "\n",
      "no improvement for 74/100 epochs\n",
      "\n",
      "→ Starting epoch 108  (printing every 63 iters)\n",
      "[Epoch 108] iter 63/63, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "OLF36W                    | OLF36W                    | 0.9891\n",
      "GB93                      | GB93                      | 0.9674\n",
      "NET061                    | NET061                    | 0.9979\n",
      "OBJ1O                     | OBJ1O                     | 0.9664\n",
      "SH2372D                   | SH2372D                   | 0.9732\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 108 done in 9.6s | train_loss=0.0001  valid_loss=0.2634  valid_acc=76.80%\n",
      "\n",
      "no improvement for 75/100 epochs\n",
      "\n",
      "→ Starting epoch 109  (printing every 63 iters)\n",
      "[Epoch 109] iter 63/63, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "H3E                       | H3E                       | 0.9997\n",
      "YE1                       | YE1                       | 0.9945\n",
      "D8I                       | D8I                       | 0.9395\n",
      "PWU3                      | PWU3                      | 0.9988\n",
      "M75                       | M75                       | 0.9734\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 109 done in 9.6s | train_loss=0.0001  valid_loss=0.2615  valid_acc=76.80%\n",
      "\n",
      "no improvement for 76/100 epochs\n",
      "\n",
      "→ Starting epoch 110  (printing every 63 iters)\n",
      "[Epoch 110] iter 63/63, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "U03E                      | U03E                      | 0.9989\n",
      "I71                       | I71                       | 0.9996\n",
      "V9773H                    | V9773H                    | 0.9747\n",
      "BS561                     | BS561                     | 0.9928\n",
      "U4080N                    | U4080N                    | 0.9424\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 110 done in 9.6s | train_loss=0.0001  valid_loss=0.2609  valid_acc=76.80%\n",
      "\n",
      "no improvement for 77/100 epochs\n",
      "\n",
      "→ Starting epoch 111  (printing every 63 iters)\n",
      "[Epoch 111] iter 63/63, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "LUU4A                     | LUU4A                     | 0.9558\n",
      "CON8803                   | CON8803                   | 0.9831\n",
      "MVX829U                   | MVX829U                   | 0.9630\n",
      "LUT77                     | LUT77                     | 0.9714\n",
      "D7                        | D7                        | 0.9456\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 111 done in 9.8s | train_loss=0.0001  valid_loss=0.2625  valid_acc=76.85%\n",
      "\n",
      "no improvement for 78/100 epochs\n",
      "\n",
      "→ Starting epoch 112  (printing every 63 iters)\n",
      "[Epoch 112] iter 63/63, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "ML8                       | ML8                       | 0.9962\n",
      "GPS3                      | GPS3                      | 0.9985\n",
      "UJ2                       | UJ2                       | 0.9862\n",
      "LRX0                      | LRX0                      | 0.9799\n",
      "ABM9                      | ABM9                      | 0.9933\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 112 done in 10.3s | train_loss=0.0001  valid_loss=0.2633  valid_acc=76.85%\n",
      "\n",
      "no improvement for 79/100 epochs\n",
      "\n",
      "→ Starting epoch 113  (printing every 63 iters)\n",
      "[Epoch 113] iter 63/63, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "GSU280J                   | GSU280J                   | 0.9763\n",
      "AH072Y                    | AH072Y                    | 0.9994\n",
      "ME9                       | ME9                       | 0.9549\n",
      "PNV47                     | PNV47                     | 0.9744\n",
      "UAH0962R                  | UAH0962R                  | 0.9822\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 113 done in 10.2s | train_loss=0.0001  valid_loss=0.2645  valid_acc=76.80%\n",
      "\n",
      "no improvement for 80/100 epochs\n",
      "\n",
      "→ Starting epoch 114  (printing every 63 iters)\n",
      "[Epoch 114] iter 63/63, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "KA04                      | KA04                      | 0.9670\n",
      "T2Z                       | T2Z                       | 0.9491\n",
      "X732                      | X732                      | 0.9998\n",
      "XFE625Q                   | XFE625Q                   | 0.9756\n",
      "R1                        | R1                        | 0.9719\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 114 done in 10.2s | train_loss=0.0001  valid_loss=0.2631  valid_acc=76.85%\n",
      "\n",
      "no improvement for 81/100 epochs\n",
      "\n",
      "→ Starting epoch 115  (printing every 63 iters)\n",
      "[Epoch 115] iter 63/63, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "GPJ512                    | GPJ512                    | 0.9956\n",
      "H724U                     | H724U                     | 0.9910\n",
      "EG9765                    | EG9765                    | 0.9956\n",
      "G97Z                      | G97Z                      | 0.9976\n",
      "FQG955                    | FQG955                    | 0.9973\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 115 done in 9.9s | train_loss=0.0001  valid_loss=0.2646  valid_acc=76.80%\n",
      "\n",
      "no improvement for 82/100 epochs\n",
      "\n",
      "→ Starting epoch 116  (printing every 63 iters)\n",
      "[Epoch 116] iter 63/63, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "IH9R                      | IH9R                      | 0.9969\n",
      "TK17                      | TK17                      | 0.9970\n",
      "UO6457                    | UO6457                    | 0.9666\n",
      "MQ4130                    | MQ4130                    | 0.9821\n",
      "A27                       | A27                       | 0.9961\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 116 done in 9.8s | train_loss=0.0001  valid_loss=0.2637  valid_acc=76.80%\n",
      "\n",
      "no improvement for 83/100 epochs\n",
      "\n",
      "→ Starting epoch 117  (printing every 63 iters)\n",
      "[Epoch 117] iter 63/63, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "EWQ677                    | EWQ677                    | 0.9964\n",
      "OZQ7J                     | OZQ7J                     | 0.9935\n",
      "B6668A                    | B6668A                    | 0.9281\n",
      "S555                      | S555                      | 0.9783\n",
      "IU0666                    | IU0666                    | 0.9722\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 117 done in 9.8s | train_loss=0.0001  valid_loss=0.2645  valid_acc=76.80%\n",
      "\n",
      "no improvement for 84/100 epochs\n",
      "\n",
      "→ Starting epoch 118  (printing every 63 iters)\n",
      "[Epoch 118] iter 63/63, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "PPD5                      | PPD5                      | 1.0000\n",
      "O6                        | O6                        | 0.9998\n",
      "D3504D                    | D3504D                    | 0.9915\n",
      "JD6677                    | JD6677                    | 0.9799\n",
      "GJ83T                     | GJ83T                     | 0.9646\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 118 done in 9.8s | train_loss=0.0001  valid_loss=0.2643  valid_acc=76.70%\n",
      "\n",
      "no improvement for 85/100 epochs\n",
      "\n",
      "→ Starting epoch 119  (printing every 63 iters)\n",
      "[Epoch 119] iter 63/63, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "ZV493                     | ZV493                     | 0.9553\n",
      "UBP8580N                  | UBP8580N                  | 0.9935\n",
      "B6E                       | B6E                       | 0.9737\n",
      "BPT603B                   | BPT603B                   | 0.9958\n",
      "LP1                       | LP1                       | 0.9910\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 119 done in 9.8s | train_loss=0.0001  valid_loss=0.2659  valid_acc=76.75%\n",
      "\n",
      "no improvement for 86/100 epochs\n",
      "\n",
      "→ Starting epoch 120  (printing every 63 iters)\n",
      "[Epoch 120] iter 63/63, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "GH27F                     | GH27F                     | 0.9741\n",
      "AP75A                     | AP75A                     | 0.9998\n",
      "GE576                     | GE576                     | 0.9981\n",
      "W633N                     | W633N                     | 0.9994\n",
      "RAR0820                   | RAR0820                   | 0.9911\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 120 done in 9.7s | train_loss=0.0001  valid_loss=0.2653  valid_acc=76.75%\n",
      "\n",
      "no improvement for 87/100 epochs\n",
      "\n",
      "→ Starting epoch 121  (printing every 63 iters)\n",
      "[Epoch 121] iter 63/63, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QCS9489                   | QCS9489                   | 0.9992\n",
      "X0                        | X0                        | 0.9659\n",
      "VQ739I                    | VQ739I                    | 0.9996\n",
      "Z420L                     | Z420L                     | 0.9993\n",
      "ACT82T                    | ACT82T                    | 0.9470\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 121 done in 9.8s | train_loss=0.0001  valid_loss=0.2641  valid_acc=76.70%\n",
      "\n",
      "no improvement for 88/100 epochs\n",
      "\n",
      "→ Starting epoch 122  (printing every 63 iters)\n",
      "[Epoch 122] iter 63/63, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "T03                       | T03                       | 0.9744\n",
      "MQ08                      | MQ08                      | 0.9705\n",
      "V4813O                    | V4813O                    | 0.9639\n",
      "GX6125G                   | GX6125G                   | 0.9896\n",
      "DL8F                      | DL8F                      | 0.9849\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 122 done in 9.7s | train_loss=0.0001  valid_loss=0.2661  valid_acc=76.80%\n",
      "\n",
      "no improvement for 89/100 epochs\n",
      "\n",
      "→ Starting epoch 123  (printing every 63 iters)\n",
      "[Epoch 123] iter 63/63, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "C92S                      | C92S                      | 0.9981\n",
      "HTI2Z                     | HTI2Z                     | 0.9951\n",
      "IHV9U                     | IHV9U                     | 0.9963\n",
      "XT80C                     | XT80C                     | 0.9789\n",
      "NE4                       | NE4                       | 0.9859\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 123 done in 9.8s | train_loss=0.0001  valid_loss=0.2681  valid_acc=76.80%\n",
      "\n",
      "no improvement for 90/100 epochs\n",
      "\n",
      "→ Starting epoch 124  (printing every 63 iters)\n",
      "[Epoch 124] iter 63/63, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "YXA10C                    | YXA10C                    | 0.9849\n",
      "MWA08B                    | MWA08B                    | 0.9984\n",
      "X3678O                    | X3678O                    | 0.9902\n",
      "W8M                       | W8M                       | 0.9973\n",
      "KPH63                     | KPH63                     | 0.9610\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 124 done in 9.8s | train_loss=0.0001  valid_loss=0.2652  valid_acc=76.80%\n",
      "\n",
      "no improvement for 91/100 epochs\n",
      "\n",
      "→ Starting epoch 125  (printing every 63 iters)\n",
      "[Epoch 125] iter 63/63, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "XPS0999                   | XPS0999                   | 0.9998\n",
      "C541L                     | C541L                     | 0.9873\n",
      "MOU5777K                  | MOU5777K                  | 0.9942\n",
      "DV3                       | DV3                       | 0.9629\n",
      "OO3                       | OO3                       | 0.9987\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 125 done in 9.8s | train_loss=0.0001  valid_loss=0.2658  valid_acc=76.85%\n",
      "\n",
      "no improvement for 92/100 epochs\n",
      "\n",
      "→ Starting epoch 126  (printing every 63 iters)\n",
      "[Epoch 126] iter 63/63, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "YR0                       | YR0                       | 0.9818\n",
      "NTL27                     | NTL27                     | 0.9809\n",
      "LFQ9480M                  | LFQ9480M                  | 0.9983\n",
      "YDC37                     | YDC37                     | 0.9999\n",
      "BYU54Q                    | BYU54Q                    | 0.9705\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 126 done in 9.8s | train_loss=0.0001  valid_loss=0.2676  valid_acc=76.85%\n",
      "\n",
      "no improvement for 93/100 epochs\n",
      "\n",
      "→ Starting epoch 127  (printing every 63 iters)\n",
      "[Epoch 127] iter 63/63, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "I6391A                    | I6391A                    | 0.9887\n",
      "U57O                      | U57O                      | 0.9856\n",
      "E72                       | E72                       | 0.9842\n",
      "NS726                     | NS726                     | 0.9975\n",
      "Q92Q                      | Q92Q                      | 0.9832\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 127 done in 9.8s | train_loss=0.0001  valid_loss=0.2677  valid_acc=76.80%\n",
      "\n",
      "no improvement for 94/100 epochs\n",
      "\n",
      "→ Starting epoch 128  (printing every 63 iters)\n",
      "[Epoch 128] iter 63/63, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "MM7193                    | MM7193                    | 0.9591\n",
      "HSR980                    | HSR980                    | 0.9514\n",
      "BDB20I                    | BDB20I                    | 0.9891\n",
      "VH0559                    | VH0559                    | 0.9939\n",
      "ED9195                    | ED9195                    | 0.9920\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 128 done in 9.8s | train_loss=0.0001  valid_loss=0.2681  valid_acc=76.75%\n",
      "\n",
      "no improvement for 95/100 epochs\n",
      "\n",
      "→ Starting epoch 129  (printing every 63 iters)\n",
      "[Epoch 129] iter 63/63, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "V076                      | V076                      | 0.9749\n",
      "ED9195                    | ED9195                    | 0.9936\n",
      "GFT60D                    | GFT60D                    | 0.9965\n",
      "G0                        | G0                        | 0.9470\n",
      "WQ9822J                   | WQ9822J                   | 0.9886\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 129 done in 9.8s | train_loss=0.0001  valid_loss=0.2677  valid_acc=76.70%\n",
      "\n",
      "no improvement for 96/100 epochs\n",
      "\n",
      "→ Starting epoch 130  (printing every 63 iters)\n",
      "[Epoch 130] iter 63/63, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "UMC837                    | UMC837                    | 0.9996\n",
      "ONA2                      | ONA2                      | 0.9681\n",
      "FYG0                      | FYG0                      | 0.9611\n",
      "EYC15Z                    | EYC15Z                    | 0.9943\n",
      "YEN0066W                  | YEN0066W                  | 0.9709\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 130 done in 9.9s | train_loss=0.0001  valid_loss=0.2677  valid_acc=76.65%\n",
      "\n",
      "no improvement for 97/100 epochs\n",
      "\n",
      "→ Starting epoch 131  (printing every 63 iters)\n",
      "[Epoch 131] iter 63/63, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "SH58                      | SH58                      | 0.9448\n",
      "PM518T                    | PM518T                    | 0.9870\n",
      "NMH0046P                  | NMH0046P                  | 0.9914\n",
      "IEE7                      | IEE7                      | 0.9993\n",
      "T4003                     | T4003                     | 0.9990\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 131 done in 9.8s | train_loss=0.0001  valid_loss=0.2680  valid_acc=76.75%\n",
      "\n",
      "no improvement for 98/100 epochs\n",
      "\n",
      "→ Starting epoch 132  (printing every 63 iters)\n",
      "[Epoch 132] iter 63/63, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "NV733H                    | NV733H                    | 0.9755\n",
      "S1                        | S1                        | 0.9941\n",
      "E388I                     | E388I                     | 0.9728\n",
      "GJO1                      | GJO1                      | 0.9776\n",
      "C75                       | C75                       | 0.9720\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 132 done in 9.8s | train_loss=0.0001  valid_loss=0.2663  valid_acc=76.75%\n",
      "\n",
      "no improvement for 99/100 epochs\n",
      "\n",
      "→ Starting epoch 133  (printing every 63 iters)\n",
      "[Epoch 133] iter 63/63, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "A1J                       | A1J                       | 0.9624\n",
      "PQ031B                    | PQ031B                    | 0.9847\n",
      "IE9423                    | IE9423                    | 0.9899\n",
      "HO21A                     | HO21A                     | 0.9998\n",
      "UZD8                      | UZD8                      | 0.9667\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 133 done in 10.0s | train_loss=0.0001  valid_loss=0.2684  valid_acc=76.70%\n",
      "\n",
      "no improvement for 100/100 epochs\n",
      "\n",
      "🔚 Early stopping: val_acc hasn't improved for 100 epochs.\n"
     ]
    }
   ],
   "source": [
    "# ─── Cell 6: training w/ history, best‐model saving + EARLY STOPPING ───\n",
    "\n",
    "# hyper‑params\n",
    "best_val_acc   = 0.0\n",
    "history        = {'epoch': [], 'train_loss': [], 'val_loss': [], 'val_acc': []}\n",
    "\n",
    "patience_cnt   = 0           # how many epochs since last improvement\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    print(f\"→ Starting epoch {epoch}  (printing every {PRINT_EVERY} iters)\")\n",
    "    model.train()\n",
    "    epoch_loss = Averager()\n",
    "    start = time.time()\n",
    "\n",
    "    # ─── training ──────────────────────────────────────────────────────────\n",
    "    for i, (images, texts) in enumerate(train_loader, 1):\n",
    "        images = images.to(device)\n",
    "\n",
    "        text, length   = converter.encode(texts, batch_max_length=MAX_LABEL_LENGTH)\n",
    "        text_input     = text[:, :-1].to(device)\n",
    "        text_target    = text[:,  1:].to(device)\n",
    "\n",
    "        preds = model(\n",
    "            images,\n",
    "            text=text_input,\n",
    "            is_train=True,\n",
    "            batch_max_length=MAX_LABEL_LENGTH\n",
    "        )  # [B, S, C]\n",
    "        B, S, C = preds.size()\n",
    "        loss = criterion(\n",
    "            preds.view(B * S, C),\n",
    "            text_target.contiguous().view(B * S)\n",
    "        )\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "        optimizer.step()\n",
    "        epoch_loss.add(loss)\n",
    "\n",
    "        # mini‐table prints\n",
    "        if i % PRINT_EVERY == 0:\n",
    "            print(f\"[Epoch {epoch}] iter {i}/{len(train_loader)}, avg loss: {epoch_loss.val():.4f}\", flush=True)\n",
    "            with torch.no_grad():\n",
    "                probs     = preds.softmax(2)\n",
    "                max_vals, max_inds = probs.max(2)\n",
    "                pred_strs = converter.decode(max_inds, length)\n",
    "                pred_strs = [s.split('[s]')[0] for s in pred_strs]\n",
    "\n",
    "            print(\"-\" * 80)\n",
    "            print(f\"{'Ground Truth':25s} | {'Prediction':25s} | AvgConfidence\")\n",
    "            print(\"-\" * 80)\n",
    "            for gt, pr, conf_seq in zip(texts[:5], pred_strs[:5], max_vals[:5]):\n",
    "                conf = conf_seq.mean().item()\n",
    "                print(f\"{gt:25s} | {pr:25s} | {conf_seq.mean().item():.4f}\")\n",
    "            print(\"-\" * 80)\n",
    "\n",
    "    # ─── validation ────────────────────────────────────────────────────────\n",
    "    val_loss, val_acc = validate(model, val_loader)\n",
    "    elapsed   = time.time() - start\n",
    "    train_l   = epoch_loss.val()\n",
    "    print(f\"==> Epoch {epoch} done in {elapsed:.1f}s | \"\n",
    "          f\"train_loss={train_l:.4f}  valid_loss={val_loss:.4f}  valid_acc={val_acc:.2f}%\\n\")\n",
    "\n",
    "    # ─── record history ───────────────────────────────────────────────────\n",
    "    history['epoch'].append(epoch)\n",
    "    history['train_loss'].append(train_l)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "\n",
    "    # ─── best‑model tracking & early‑stopping logic ───────────────────────\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"best_attention_crnn_generated_dataset.pth\")\n",
    "        print(f\"💾 New best model saved (epoch {epoch}, val_acc={val_acc:.2f}%)\\n\")\n",
    "        patience_cnt = 0                          # reset counter\n",
    "    else:\n",
    "        patience_cnt += 1\n",
    "        print(f\"no improvement for {patience_cnt}/{PATIENCE} epochs\\n\")\n",
    "        if patience_cnt >= PATIENCE:\n",
    "            print(f\"🔚 Early stopping: val_acc hasn't improved for {PATIENCE} epochs.\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b49a536f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3.104064</td>\n",
       "      <td>2.696229</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.360739</td>\n",
       "      <td>1.903633</td>\n",
       "      <td>1.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.628060</td>\n",
       "      <td>1.148686</td>\n",
       "      <td>12.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.137536</td>\n",
       "      <td>1.087282</td>\n",
       "      <td>14.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.846556</td>\n",
       "      <td>1.788725</td>\n",
       "      <td>6.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>129</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.267703</td>\n",
       "      <td>76.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>130</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.267677</td>\n",
       "      <td>76.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>131</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.268005</td>\n",
       "      <td>76.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>132</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.266264</td>\n",
       "      <td>76.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>133</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.268369</td>\n",
       "      <td>76.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>133 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     epoch  train_loss  val_loss  val_acc\n",
       "0        1    3.104064  2.696229     0.00\n",
       "1        2    2.360739  1.903633     1.05\n",
       "2        3    1.628060  1.148686    12.00\n",
       "3        4    1.137536  1.087282    14.55\n",
       "4        5    0.846556  1.788725     6.30\n",
       "..     ...         ...       ...      ...\n",
       "128    129    0.000085  0.267703    76.70\n",
       "129    130    0.000084  0.267677    76.65\n",
       "130    131    0.000084  0.268005    76.75\n",
       "131    132    0.000085  0.266264    76.75\n",
       "132    133    0.000082  0.268369    76.70\n",
       "\n",
       "[133 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clean_history = {\n",
    "  'epoch':      history['epoch'],\n",
    "  'train_loss': [x.cpu().item() if hasattr(x, 'cpu') else x for x in history['train_loss']],\n",
    "  'val_loss':   [x.cpu().item() if hasattr(x, 'cpu') else x for x in history['val_loss']],\n",
    "  'val_acc':    [x.cpu().item() if hasattr(x, 'cpu') else x for x in history['val_acc']],\n",
    "}\n",
    "df = pd.DataFrame(clean_history)\n",
    "display(df)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(df['epoch'], df['train_loss'], label='Train Loss')\n",
    "plt.plot(df['epoch'], df['val_loss'],   label='Val Loss')\n",
    "plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.legend()\n",
    "plt.title('Loss over Epochs')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(df['epoch'], df['val_acc'],   label='Val Accuracy')\n",
    "plt.xlabel('Epoch'); plt.ylabel('Accuracy (%)'); plt.legend()\n",
    "plt.title('Val Accuracy over Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe117ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ─── Cell 9: ONNX export via isolated inference head ─────────────────────────\n",
    "# import torch\n",
    "\n",
    "# class CRNNInference(torch.nn.Module):\n",
    "#     def __init__(self, crnn, max_len):\n",
    "#         super().__init__()\n",
    "#         # use exactly the names printed out by your inspection\n",
    "#         self.Transformation     = crnn.Transformation\n",
    "#         self.FeatureExtraction = crnn.FeatureExtraction\n",
    "#         self.AdaptiveAvgPool    = crnn.AdaptiveAvgPool\n",
    "#         self.SequenceModeling   = crnn.SequenceModeling\n",
    "#         self.Prediction         = crnn.Prediction\n",
    "#         self.max_len           = max_len\n",
    "#         # adjust this if your converter stores start-token under a different key\n",
    "#         self.start_id          = crnn.converter.dict['[GO]']\n",
    "\n",
    "#     def forward(self, image):\n",
    "#         # 1) Spatial‐transformer + feature CNN\n",
    "#         x = self.Transformation(image)                     # [B, C, H, W]\n",
    "#         x = self.FeatureExtraction(x)                      # [B, C, H, W]\n",
    "\n",
    "#         # 2) Pool down height to 1\n",
    "#         x = self.AdaptiveAvgPool(x)                        # [B, C, 1, W]\n",
    "#         x = x.squeeze(2)                                   # [B, C, W]\n",
    "#         x = x.permute(0, 2, 1)                             # [B, W, C]\n",
    "\n",
    "#         # 3) 2‐layer BiLSTM\n",
    "#         contextual = self.SequenceModeling(x)              # [B, W, hidden]\n",
    "\n",
    "#         # 4) Dummy “[GO]” token vector\n",
    "#         B = contextual.size(0)\n",
    "#         dummy_text = torch.full(\n",
    "#             (B,),\n",
    "#             self.start_id,\n",
    "#             dtype=torch.long,\n",
    "#             device=image.device\n",
    "#         )  # shape [B]\n",
    "\n",
    "#         # 5) Attention decoder (inference path)\n",
    "#         return self.Prediction(\n",
    "#             batch_H           = contextual,\n",
    "#             text              = dummy_text,\n",
    "#             is_train          = False,\n",
    "#             batch_max_length  = self.max_len\n",
    "#         )\n",
    "\n",
    "# # Wrap and export\n",
    "# inference_model = CRNNInference(model, BATCH_MAX_LENGTH).eval()\n",
    "# dummy_img       = torch.randn(1, INPUT_CHANNEL, IMG_HEIGHT, IMG_WIDTH, device=device)\n",
    "\n",
    "# torch.onnx.export(\n",
    "#     inference_model,\n",
    "#     dummy_img,\n",
    "#     \"best_attention_crnn.onnx\",\n",
    "#     input_names   = ['image'],\n",
    "#     output_names  = ['logits'],\n",
    "#     dynamic_axes  = {\n",
    "#         'image':  {0: 'batch'},\n",
    "#         'logits': {0: 'batch', 1: 'time'}\n",
    "#     },\n",
    "#     opset_version = 13,\n",
    "# )\n",
    "\n",
    "# print(\"✅ Exported best_attention_crnn.onnx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9587a5dc",
   "metadata": {},
   "source": [
    "# DUMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99a300a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ─── cell 6: attention‐based training loop ──────────────────────────────────────\n",
    "# for epoch in range(1, NUM_EPOCHS+1):\n",
    "#     print(f\"→ Starting epoch {epoch}  (printing every {PRINT_EVERY} iters)\")\n",
    "#     model.train()\n",
    "#     epoch_loss = Averager()\n",
    "#     start      = time.time()\n",
    "\n",
    "#     for i, (images, texts) in enumerate(train_loader, 1):\n",
    "#         images = images.to(device)\n",
    "\n",
    "#         # encode with [GO] & [s]; also get lengths\n",
    "#         text, length = converter.encode(texts, batch_max_length=BATCH_MAX_LENGTH)\n",
    "#         text_input  = text[:, :-1].to(device)   # drop final [s]\n",
    "#         text_target = text[:,  1:].to(device)   # everything after [GO]\n",
    "\n",
    "#         # forward + loss\n",
    "#         preds = model(images,\n",
    "#                       text=text_input,\n",
    "#                       is_train=True,\n",
    "#                       batch_max_length=BATCH_MAX_LENGTH)  # [B, S, C]\n",
    "#         B, S, C = preds.size()\n",
    "#         loss = criterion(\n",
    "#             preds.view(B * S, C),\n",
    "#             text_target.contiguous().view(B * S)\n",
    "#         )\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "#         optimizer.step()\n",
    "#         epoch_loss.add(loss)\n",
    "\n",
    "#         if i % PRINT_EVERY == 0 or i == 1:\n",
    "#             print(f\"[Epoch {epoch}] iter {i}/{len(train_loader)}, avg loss: {epoch_loss.val():.4f}\", flush=True)\n",
    "\n",
    "#             # quick greedy‐decode\n",
    "#             with torch.no_grad():\n",
    "#                 probs        = preds.softmax(2)           # [B, S, C]\n",
    "#                 max_vals, max_inds = probs.max(2)         # [B, S]\n",
    "#                 pred_strs    = converter.decode(max_inds, length)\n",
    "#                 pred_strs    = [s.split('[s]')[0] for s in pred_strs]\n",
    "\n",
    "#             # print a mini‐table\n",
    "#             print(\"-\" * 80)\n",
    "#             print(f\"{'Ground Truth':25s} | {'Prediction':25s} | AvgConfidence\")\n",
    "#             print(\"-\" * 80)\n",
    "#             for gt, pr, conf_seq in zip(texts[:5], pred_strs[:5], max_vals[:5]):\n",
    "#                 conf = conf_seq.mean().item()\n",
    "#                 print(f\"{gt:25s} | {pr:25s} | {conf:0.4f}\")\n",
    "#             print(\"-\" * 80)\n",
    "\n",
    "#     # end‐of‐epoch validation\n",
    "#     val_loss, val_acc = validate(model, val_loader)\n",
    "#     elapsed = time.time() - start\n",
    "#     print(f\"==> Epoch {epoch} done in {elapsed:.1f}s | \"\n",
    "#           f\"train_loss={epoch_loss.val():.4f}\"\n",
    "#           f\"  valid_loss={val_loss:.4f}  valid_acc={val_acc:.2f}%\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
