{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "493b766c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cuda\n"
     ]
    }
   ],
   "source": [
    "# cell 1\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from config import (IMG_HEIGHT, IMG_WIDTH, NUM_FIDUCIAL,\n",
    "                    INPUT_CHANNEL, OUTPUT_CHANNEL, HIDDEN_SIZE,\n",
    "                    CHARACTERS, MAX_LABEL_LENGTH)\n",
    "from dataset import LmdbDataset, AlignCollate\n",
    "# from utils import CTCLabelConverter, Averager\n",
    "from utils import AttnLabelConverter, Averager\n",
    "from model import CRNN\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Running on\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2c361de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All seeds set to 300188, cudnn.deterministic=True\n"
     ]
    }
   ],
   "source": [
    "# ─── cell 0: reproducibility ────────────────────────────────────────────────\n",
    "SEED = 300188\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# Make cuDNN deterministic (slower but reproducible)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "print(f\"All seeds set to {SEED}, cudnn.deterministic={torch.backends.cudnn.deterministic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea60e7b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1372 valid samples from v4_lmdb_data_!/train\n",
      "Loaded 343 valid samples from v4_lmdb_data_!/val\n",
      "1372 train / 343 val samples\n"
     ]
    }
   ],
   "source": [
    "# cell 2\n",
    "# paths to your LMDBs\n",
    "train_lmdb = \"v4_lmdb_data_!/train\"\n",
    "val_lmdb   = \"v4_lmdb_data_!/val\"\n",
    "\n",
    "# instantiate datasets\n",
    "train_dataset = LmdbDataset(train_lmdb)\n",
    "val_dataset   = LmdbDataset(val_lmdb)\n",
    "\n",
    "# collate_fn resizes + normalizes\n",
    "collate_fn = AlignCollate(\n",
    "    imgH=IMG_HEIGHT, imgW=IMG_WIDTH, keep_ratio_with_pad=False\n",
    ")\n",
    "\n",
    "# loaders\n",
    "BATCH_SIZE = 32\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "    num_workers=0, collate_fn=collate_fn, pin_memory=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "    num_workers=0, collate_fn=collate_fn, pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"{len(train_dataset)} train / {len(val_dataset)} val samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87f5359d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 20 labels from loader:\n",
      "['PPA!4817', 'VFT8338', 'QBE9168', 'RAU!369', 'QS3469R', 'VGX3935', 'WXM1116', 'VES!3744', 'BKJ!3569', 'WNH553', 'VJL3065', 'QAA6162E', 'QS9698N', 'QAB7672J', 'VJY4021', 'BKB!9642', 'QAA5515N', 'QAB8907B', 'SYQ!44', 'PLH7338']\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_loader))\n",
    "texts = batch[1]             # list of ground‑truth strings\n",
    "print(\"First 20 labels from loader:\")\n",
    "print(texts[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e3d612b",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter   = AttnLabelConverter(CHARACTERS)\n",
    "num_classes = len(converter.character)   # includes [GO] and [s]\n",
    "\n",
    "model = CRNN(\n",
    "    IMG_HEIGHT,      # imgH\n",
    "    IMG_WIDTH,       # imgW\n",
    "    INPUT_CHANNEL,   # input_channel\n",
    "    OUTPUT_CHANNEL,  # output_channel\n",
    "    HIDDEN_SIZE,     # hidden_size\n",
    "    num_classes,     # num_classes (with GO/s)\n",
    "    True,            # use_attention\n",
    "    NUM_FIDUCIAL     # num_fiducial\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0).to(device)\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=1.0)\n",
    "\n",
    "model.Transformation = nn.Identity() # <-- no transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a80e2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── cell 4: validate (Attention) ─────────────────────────────────────────────\n",
    "NUM_EPOCHS       = 500\n",
    "PRINT_EVERY      = len(train_dataset) // BATCH_SIZE + 1\n",
    "PATIENCE       = 100          # stop if no val_acc ↑ for 50 epochs\n",
    "\n",
    "def validate(model, loader):\n",
    "    model.eval()\n",
    "    avg_loss = Averager()\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, texts in loader:\n",
    "            images = images.to(device)\n",
    "\n",
    "            # encode full text → shape [B, L+1], plus lengths\n",
    "            text, length = converter.encode(texts, batch_max_length=MAX_LABEL_LENGTH)\n",
    "            text_input  = text[:, :-1].to(device)  # drop final [s]\n",
    "            text_target = text[:,  1:].to(device)  # everything after [GO]\n",
    "\n",
    "            # forward\n",
    "            preds = model(images, text_input, is_train=False,\n",
    "                          batch_max_length=MAX_LABEL_LENGTH)\n",
    "            B, S, C = preds.size()\n",
    "\n",
    "            # cross‐entropy over (B×S) predictions\n",
    "            loss = criterion(\n",
    "                preds.view(B * S, C),\n",
    "                text_target.contiguous().view(B * S)\n",
    "            )\n",
    "            avg_loss.add(loss)\n",
    "\n",
    "            # greedy decode\n",
    "            _, pred_inds = preds.max(2)                   # [B, S]\n",
    "            pred_strs = converter.decode(pred_inds, length)  # pass length\n",
    "\n",
    "            # strip off anything after the \"[s]\" token\n",
    "            pred_strs = [s.split('[s]')[0] for s in pred_strs]\n",
    "\n",
    "            total += len(texts)\n",
    "            correct += sum(p == g for p, g in zip(pred_strs, texts))\n",
    "\n",
    "    acc = correct / total * 100\n",
    "    return avg_loss.val(), acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36d430a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded pretrained Attn weights\n"
     ]
    }
   ],
   "source": [
    "# ─── cell 5: load pretrained CTC weights (skip old Prediction head) ────────────\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "orig      = torch.load(\"pretrained_model/TPS-ResNet-BiLSTM-Attn.pth\", map_location=device)\n",
    "# strip off the \"module.\" prefix if you wrapped in DataParallel\n",
    "stripped  = OrderedDict((k[len(\"module.\"):], v)\n",
    "                        for k, v in orig.items()\n",
    "                        if k.startswith(\"module.\"))\n",
    "\n",
    "own = model.state_dict()\n",
    "for k, v in stripped.items():\n",
    "    # skip the old attention head entirely\n",
    "    if k.startswith(\"Prediction.\") or k.startswith(\"Transformation.\"):\n",
    "        continue\n",
    "    # only overwrite if shapes match\n",
    "    if k in own and v.size() == own[k].size():\n",
    "        own[k] = v\n",
    "\n",
    "model.load_state_dict(own)\n",
    "print(\"✅ Loaded pretrained Attn weights\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b9e6646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Starting epoch 1  (printing every 43 iters)\n",
      "[Epoch 1] iter 43/43, avg loss: 3.1271\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QKS8556                   | Q556                      | 0.3128\n",
      "QCP6838                   | Q888                      | 0.3150\n",
      "QAA9552A                  | QA5                       | 0.3688\n",
      "MU!6275                   | !!!!                      | 0.2948\n",
      "VJB1968                   | Q668                      | 0.3284\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 1 done in 3.4s | train_loss=3.1271  valid_loss=2.7606  valid_acc=0.00%\n",
      "\n",
      "no improvement for 1/100 epochs\n",
      "\n",
      "→ Starting epoch 2  (printing every 43 iters)\n",
      "[Epoch 2] iter 43/43, avg loss: 2.5331\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WXP3314                   | QB333                     | 0.5532\n",
      "QAW2391                   | QA22                      | 0.5491\n",
      "ALN8722                   | Q2222                     | 0.4425\n",
      "QAA3440                   | QAA4                      | 0.4962\n",
      "QAA3618X                  | QAA8                      | 0.3926\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 2 done in 3.1s | train_loss=2.5331  valid_loss=2.3227  valid_acc=0.00%\n",
      "\n",
      "no improvement for 2/100 epochs\n",
      "\n",
      "→ Starting epoch 3  (printing every 43 iters)\n",
      "[Epoch 3] iter 43/43, avg loss: 2.1258\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAH1581                   | QAA111                    | 0.4508\n",
      "QKS8556                   | QAM5555                   | 0.4475\n",
      "BNY!4363                  | QA!!!55                   | 0.3625\n",
      "PHY2884                   | QB22288                   | 0.3767\n",
      "WB!2177K                  | QM!27777                  | 0.3490\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 3 done in 3.2s | train_loss=2.1258  valid_loss=1.8741  valid_acc=0.29%\n",
      "\n",
      "💾 New best model saved (epoch 3, val_acc=0.29%)\n",
      "\n",
      "→ Starting epoch 4  (printing every 43 iters)\n",
      "[Epoch 4] iter 43/43, avg loss: 1.8162\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QCN8327                   | QC8837                    | 0.4813\n",
      "SWK426                    | WW42266                   | 0.4581\n",
      "QAM6622                   | QA66222                   | 0.5902\n",
      "QTN3878                   | QB38888                   | 0.5661\n",
      "PLM!1311                  | QP!!311                   | 0.4415\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 4 done in 3.2s | train_loss=1.8162  valid_loss=1.6634  valid_acc=0.29%\n",
      "\n",
      "no improvement for 1/100 epochs\n",
      "\n",
      "→ Starting epoch 5  (printing every 43 iters)\n",
      "[Epoch 5] iter 43/43, avg loss: 1.5198\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QCS3236                   | QCS33336                  | 0.6714\n",
      "B3106A                    | BBB006                    | 0.4061\n",
      "W8723V                    | WW7223                    | 0.5315\n",
      "QCH9191                   | QCC9911                   | 0.6446\n",
      "1M4U3172                  | MMM317                    | 0.5979\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 5 done in 3.1s | train_loss=1.5198  valid_loss=1.2721  valid_acc=1.75%\n",
      "\n",
      "💾 New best model saved (epoch 5, val_acc=1.75%)\n",
      "\n",
      "→ Starting epoch 6  (printing every 43 iters)\n",
      "[Epoch 6] iter 43/43, avg loss: 1.2184\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "BSE!6665                  | QAC!666                   | 0.5552\n",
      "QPA3382                   | QPA3322                   | 0.7158\n",
      "WJT342                    | JJT3442                   | 0.6667\n",
      "AKK!4491                  | AAA!4491                  | 0.5062\n",
      "PLS!114                   | AAA!115                   | 0.3550\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 6 done in 3.2s | train_loss=1.2184  valid_loss=1.0584  valid_acc=13.99%\n",
      "\n",
      "💾 New best model saved (epoch 6, val_acc=13.99%)\n",
      "\n",
      "→ Starting epoch 7  (printing every 43 iters)\n",
      "[Epoch 7] iter 43/43, avg loss: 0.8517\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "BHP7067                   | BHP7067                   | 0.7969\n",
      "SYQ9881                   | SYQ9881                   | 0.7811\n",
      "LE7021                    | LET0211                   | 0.7446\n",
      "VNQ4338                   | VNQ43388                  | 0.8294\n",
      "QAB3641H                  | QAB364HH                  | 0.6873\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 7 done in 3.1s | train_loss=0.8517  valid_loss=0.7544  valid_acc=37.32%\n",
      "\n",
      "💾 New best model saved (epoch 7, val_acc=37.32%)\n",
      "\n",
      "→ Starting epoch 8  (printing every 43 iters)\n",
      "[Epoch 8] iter 43/43, avg loss: 0.7227\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QRR9945                   | QRR9945                   | 0.8829\n",
      "VEH!6204                  | WKH!2204                  | 0.5915\n",
      "QBD9519                   | QBD9519                   | 0.8398\n",
      "MDJ5126                   | MDJ5126                   | 0.8623\n",
      "QAA2892K                  | QAA289KK                  | 0.7826\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 8 done in 2.9s | train_loss=0.7227  valid_loss=0.6853  valid_acc=47.52%\n",
      "\n",
      "💾 New best model saved (epoch 8, val_acc=47.52%)\n",
      "\n",
      "→ Starting epoch 9  (printing every 43 iters)\n",
      "[Epoch 9] iter 43/43, avg loss: 0.5783\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VEH!6204                  | WEH!6244                  | 0.6299\n",
      "JLY2201                   | JLY2201                   | 0.8726\n",
      "QAA8951J                  | QAA8911J                  | 0.8813\n",
      "QMU969                    | QMU9699                   | 0.9337\n",
      "QSV1707                   | QSV1707                   | 0.8761\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 9 done in 2.9s | train_loss=0.5783  valid_loss=0.6742  valid_acc=47.81%\n",
      "\n",
      "💾 New best model saved (epoch 9, val_acc=47.81%)\n",
      "\n",
      "→ Starting epoch 10  (printing every 43 iters)\n",
      "[Epoch 10] iter 43/43, avg loss: 0.4620\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QCM5317                   | QCM5317                   | 0.9119\n",
      "JRG6799                   | JRG6799                   | 0.9382\n",
      "8559                      | 5553                      | 0.6842\n",
      "QAA8020Q                  | QAA800QQ                  | 0.8696\n",
      "KDN!1893                  | LCW!1893                  | 0.7066\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 10 done in 3.0s | train_loss=0.4620  valid_loss=1.9022  valid_acc=0.58%\n",
      "\n",
      "no improvement for 1/100 epochs\n",
      "\n",
      "→ Starting epoch 11  (printing every 43 iters)\n",
      "[Epoch 11] iter 43/43, avg loss: 0.5216\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QS6811S                   | QS6811S                   | 0.9019\n",
      "QAA844Q                   | QAA844Q                   | 0.9052\n",
      "CDD!8169                  | BDD!8199                  | 0.7266\n",
      "QCB1918                   | QCB1918                   | 0.9567\n",
      "XOIC29                    | XQ1C29                    | 0.8087\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 11 done in 2.9s | train_loss=0.5216  valid_loss=0.5380  valid_acc=56.56%\n",
      "\n",
      "💾 New best model saved (epoch 11, val_acc=56.56%)\n",
      "\n",
      "→ Starting epoch 12  (printing every 43 iters)\n",
      "[Epoch 12] iter 43/43, avg loss: 0.3607\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "ANU7888                   | ANU7888                   | 0.9399\n",
      "QS9953S                   | QS9953S                   | 0.9131\n",
      "VN815                     | VN815                     | 0.8342\n",
      "QKM5112                   | QKM5112                   | 0.9480\n",
      "WDM!5963                  | WDM!5963                  | 0.7296\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 12 done in 3.1s | train_loss=0.3607  valid_loss=0.5045  valid_acc=56.56%\n",
      "\n",
      "no improvement for 1/100 epochs\n",
      "\n",
      "→ Starting epoch 13  (printing every 43 iters)\n",
      "[Epoch 13] iter 43/43, avg loss: 0.3024\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WEH8092                   | WEH8092                   | 0.9434\n",
      "QCA6734                   | QCA6734                   | 0.9526\n",
      "QAA6198S                  | QAA6198S                  | 0.8582\n",
      "QCG7936                   | QCG7936                   | 0.9802\n",
      "VDM!8068                  | VDM!8068                  | 0.8177\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 13 done in 2.9s | train_loss=0.3024  valid_loss=0.4705  valid_acc=58.89%\n",
      "\n",
      "💾 New best model saved (epoch 13, val_acc=58.89%)\n",
      "\n",
      "→ Starting epoch 14  (printing every 43 iters)\n",
      "[Epoch 14] iter 43/43, avg loss: 0.1776\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "JLX!6457                  | JLX!6457                  | 0.7637\n",
      "VJL3065                   | VJL3065                   | 0.9580\n",
      "SMH1061                   | SMH1061                   | 0.9697\n",
      "RP!5366                   | PF!!366                   | 0.7715\n",
      "VHC5744                   | VHC5744                   | 0.9784\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 14 done in 3.0s | train_loss=0.1776  valid_loss=0.4959  valid_acc=61.52%\n",
      "\n",
      "💾 New best model saved (epoch 14, val_acc=61.52%)\n",
      "\n",
      "→ Starting epoch 15  (printing every 43 iters)\n",
      "[Epoch 15] iter 43/43, avg loss: 0.1953\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VK2618                    | VK2618                    | 0.9802\n",
      "MDH7007                   | MDH7007                   | 0.9882\n",
      "LD9188                    | LD9188                    | 0.9892\n",
      "JXP!4469                  | JPH!4469                  | 0.7979\n",
      "WLH6202                   | WLH6202                   | 0.9882\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 15 done in 3.2s | train_loss=0.1953  valid_loss=0.4399  valid_acc=60.93%\n",
      "\n",
      "no improvement for 1/100 epochs\n",
      "\n",
      "→ Starting epoch 16  (printing every 43 iters)\n",
      "[Epoch 16] iter 43/43, avg loss: 0.1096\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QCH7638                   | QCH7638                   | 0.9745\n",
      "JTD2383                   | JTD2383                   | 0.9453\n",
      "QAM6622                   | QAM6622                   | 0.9602\n",
      "WTM!3755                  | WUM!3755                  | 0.8827\n",
      "JUC9711                   | JUC9711                   | 0.9855\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 16 done in 3.4s | train_loss=0.1096  valid_loss=0.3890  valid_acc=69.97%\n",
      "\n",
      "💾 New best model saved (epoch 16, val_acc=69.97%)\n",
      "\n",
      "→ Starting epoch 17  (printing every 43 iters)\n",
      "[Epoch 17] iter 43/43, avg loss: 0.0986\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VCV3619                   | VCV361                    | 0.9550\n",
      "QAA5823N                  | QAA582N                   | 0.9694\n",
      "QS1016K                   | QS101K                    | 0.9629\n",
      "VES!3744                  | VEL!374                   | 0.7782\n",
      "SYY9112                   | SYY912                    | 0.9688\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 17 done in 3.3s | train_loss=0.0986  valid_loss=1.3263  valid_acc=1.46%\n",
      "\n",
      "no improvement for 1/100 epochs\n",
      "\n",
      "→ Starting epoch 18  (printing every 43 iters)\n",
      "[Epoch 18] iter 43/43, avg loss: 0.1276\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QMU6123                   | QMU6123                   | 0.9878\n",
      "JSB675                    | JSB675                    | 0.9545\n",
      "QPB615                    | QPB615                    | 0.9665\n",
      "QCT1194                   | QCT1194                   | 0.9467\n",
      "TBB4878                   | TBB4878                   | 0.9785\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 18 done in 3.2s | train_loss=0.1276  valid_loss=0.4381  valid_acc=68.80%\n",
      "\n",
      "no improvement for 2/100 epochs\n",
      "\n",
      "→ Starting epoch 19  (printing every 43 iters)\n",
      "[Epoch 19] iter 43/43, avg loss: 0.1316\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WLC52                     | WLLC2                     | 0.9276\n",
      "QAA3618X                  | QAA3618X                  | 0.9804\n",
      "104101DC                  | 0Q4101D                   | 0.8157\n",
      "ANB!9161                  | ANB!9161                  | 0.9551\n",
      "QAB1928E                  | QAB1928E                  | 0.9698\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 19 done in 3.1s | train_loss=0.1316  valid_loss=0.4679  valid_acc=68.80%\n",
      "\n",
      "no improvement for 3/100 epochs\n",
      "\n",
      "→ Starting epoch 20  (printing every 43 iters)\n",
      "[Epoch 20] iter 43/43, avg loss: 0.0415\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "TBE9333                   | TBE9333                   | 0.9802\n",
      "QAA3858U                  | QAA3858U                  | 0.9755\n",
      "QAA5191E                  | QAA5191E                  | 0.9872\n",
      "BLR!9830                  | BLR!9830                  | 0.9412\n",
      "MCV!3797                  | MCV!3797                  | 0.9195\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 20 done in 3.1s | train_loss=0.0415  valid_loss=0.3998  valid_acc=70.55%\n",
      "\n",
      "💾 New best model saved (epoch 20, val_acc=70.55%)\n",
      "\n",
      "→ Starting epoch 21  (printing every 43 iters)\n",
      "[Epoch 21] iter 43/43, avg loss: 0.0644\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "UNIMAS6119                | UNIMAS61111               | 0.7529\n",
      "QM!9C                     | QM!99                     | 0.8477\n",
      "ADY!2688                  | ADY!2688                  | 0.9155\n",
      "WB2261T                   | WB2261T                   | 0.9607\n",
      "SM2004                    | SM2004                    | 0.9582\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 21 done in 3.3s | train_loss=0.0644  valid_loss=0.4438  valid_acc=69.97%\n",
      "\n",
      "no improvement for 1/100 epochs\n",
      "\n",
      "→ Starting epoch 22  (printing every 43 iters)\n",
      "[Epoch 22] iter 43/43, avg loss: 0.0819\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WXY6928                   | WXY6928                   | 0.9443\n",
      "VDL4789                   | VDL4789                   | 0.9888\n",
      "QAA!9401U                 | QAA!9411                  | 0.9226\n",
      "QS4848D                   | QS4848D                   | 0.9834\n",
      "QAA686G                   | QAA686G                   | 0.9070\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 22 done in 3.2s | train_loss=0.0819  valid_loss=0.5369  valid_acc=58.31%\n",
      "\n",
      "no improvement for 2/100 epochs\n",
      "\n",
      "→ Starting epoch 23  (printing every 43 iters)\n",
      "[Epoch 23] iter 43/43, avg loss: 0.0452\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "JVY1699                   | JVY1699                   | 0.9835\n",
      "QPA3725                   | QPA3725                   | 0.9654\n",
      "WA1309F                   | WA1309F                   | 0.9476\n",
      "SYF8254                   | SYF8254                   | 0.9594\n",
      "QMW!65                    | QMW!65                    | 0.9348\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 23 done in 3.1s | train_loss=0.0452  valid_loss=0.4506  valid_acc=69.10%\n",
      "\n",
      "no improvement for 3/100 epochs\n",
      "\n",
      "→ Starting epoch 24  (printing every 43 iters)\n",
      "[Epoch 24] iter 43/43, avg loss: 0.0222\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QLD2696                   | QLD2696                   | 0.9841\n",
      "QLC8072                   | QLC8072                   | 0.9551\n",
      "QAA3440                   | QAA3440                   | 0.9682\n",
      "JFR4363                   | JFR4363                   | 0.9595\n",
      "T/JJ115                   | T/JJ115                   | 0.9533\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 24 done in 3.2s | train_loss=0.0222  valid_loss=0.5008  valid_acc=68.22%\n",
      "\n",
      "no improvement for 4/100 epochs\n",
      "\n",
      "→ Starting epoch 25  (printing every 43 iters)\n",
      "[Epoch 25] iter 43/43, avg loss: 0.0160\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WJE4152                   | WJE4152                   | 0.9625\n",
      "QLB7733                   | QLB7733                   | 0.9914\n",
      "W8723V                    | W8723V                    | 0.9642\n",
      "CCP8081                   | CCP8081                   | 0.9913\n",
      "NCH!6650                  | NCH!6650                  | 0.9891\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 25 done in 3.2s | train_loss=0.0160  valid_loss=0.4119  valid_acc=76.09%\n",
      "\n",
      "💾 New best model saved (epoch 25, val_acc=76.09%)\n",
      "\n",
      "→ Starting epoch 26  (printing every 43 iters)\n",
      "[Epoch 26] iter 43/43, avg loss: 0.0135\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WXX!2093                  | WXX!2093                  | 0.9732\n",
      "ADY!2688                  | ADY!2688                  | 0.9380\n",
      "QAE2205                   | QAE2205                   | 0.9774\n",
      "NAD!9748                  | NAD!9748                  | 0.9142\n",
      "BNB!8655                  | BNB!8655                  | 0.9308\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 26 done in 3.1s | train_loss=0.0135  valid_loss=0.4392  valid_acc=73.76%\n",
      "\n",
      "no improvement for 1/100 epochs\n",
      "\n",
      "→ Starting epoch 27  (printing every 43 iters)\n",
      "[Epoch 27] iter 43/43, avg loss: 0.0082\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "JRA!7032                  | JRA!7032                  | 0.9290\n",
      "W5870P                    | W5870P                    | 0.9933\n",
      "QCP9736                   | QCP9736                   | 0.9626\n",
      "QRR9945                   | QRR9945                   | 0.9736\n",
      "VAJ4559                   | VAJ4559                   | 0.9856\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 27 done in 3.1s | train_loss=0.0082  valid_loss=0.4273  valid_acc=76.09%\n",
      "\n",
      "no improvement for 2/100 epochs\n",
      "\n",
      "→ Starting epoch 28  (printing every 43 iters)\n",
      "[Epoch 28] iter 43/43, avg loss: 0.0079\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QTS6613                   | QTS6613                   | 0.9759\n",
      "QAA8678A                  | QAA8678A                  | 0.9964\n",
      "UMK!8883                  | UMK!8883                  | 0.9879\n",
      "JNU8226                   | JNU8226                   | 0.9796\n",
      "WC1484R                   | WC1484R                   | 0.9629\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 28 done in 3.3s | train_loss=0.0079  valid_loss=0.4236  valid_acc=75.80%\n",
      "\n",
      "no improvement for 3/100 epochs\n",
      "\n",
      "→ Starting epoch 29  (printing every 43 iters)\n",
      "[Epoch 29] iter 43/43, avg loss: 0.0078\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VJG3205                   | VJG3205                   | 0.9788\n",
      "QLC8072                   | QLC8072                   | 0.9678\n",
      "PLE8999                   | PLE8999                   | 0.9959\n",
      "DDK!6794                  | DDK!6794                  | 0.9273\n",
      "TBT!3323                  | TBT!3323                  | 0.9597\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 29 done in 3.2s | train_loss=0.0078  valid_loss=0.4367  valid_acc=76.38%\n",
      "\n",
      "💾 New best model saved (epoch 29, val_acc=76.38%)\n",
      "\n",
      "→ Starting epoch 30  (printing every 43 iters)\n",
      "[Epoch 30] iter 43/43, avg loss: 0.0303\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "MU!6275                   | MU!6675                   | 0.8805\n",
      "JXC679                    | JXC679                    | 0.9690\n",
      "BRK!9118                  | BRK!9118                  | 0.9185\n",
      "QAA!9328G                 | QAA!9388G                 | 0.9369\n",
      "QRR9945                   | QRR9945                   | 0.9914\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 30 done in 3.2s | train_loss=0.0303  valid_loss=0.4524  valid_acc=71.72%\n",
      "\n",
      "no improvement for 1/100 epochs\n",
      "\n",
      "→ Starting epoch 31  (printing every 43 iters)\n",
      "[Epoch 31] iter 43/43, avg loss: 0.0345\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QM!155J                   | QM!155J                   | 0.8805\n",
      "VAM!9906                  | VAM!9906                  | 0.9249\n",
      "QAC2127                   | QAC2127                   | 0.9980\n",
      "CEW!485                   | CEW!485                   | 0.9467\n",
      "SYM!4893                  | SYM!4893                  | 0.9073\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 31 done in 3.3s | train_loss=0.0345  valid_loss=0.4177  valid_acc=74.34%\n",
      "\n",
      "no improvement for 2/100 epochs\n",
      "\n",
      "→ Starting epoch 32  (printing every 43 iters)\n",
      "[Epoch 32] iter 43/43, avg loss: 0.0134\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WVB5362                   | WVB5362                   | 0.9904\n",
      "WC8869U                   | WC8869U                   | 0.9804\n",
      "VGL5629                   | VGL5629                   | 0.9773\n",
      "ABS8858                   | ABS8858                   | 0.9838\n",
      "NCB!7903                  | NCB!7903                  | 0.9194\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 32 done in 3.3s | train_loss=0.0134  valid_loss=0.4561  valid_acc=73.76%\n",
      "\n",
      "no improvement for 3/100 epochs\n",
      "\n",
      "→ Starting epoch 33  (printing every 43 iters)\n",
      "[Epoch 33] iter 43/43, avg loss: 0.0100\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WAW8593                   | WAW8593                   | 0.9760\n",
      "SJG7119                   | SJG7119                   | 0.9605\n",
      "QCP9736                   | QCP9736                   | 0.9696\n",
      "VC6786                    | VC6786                    | 0.9690\n",
      "CCP8081                   | CCP8081                   | 0.9708\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 33 done in 3.2s | train_loss=0.0100  valid_loss=0.4667  valid_acc=73.76%\n",
      "\n",
      "no improvement for 4/100 epochs\n",
      "\n",
      "→ Starting epoch 34  (printing every 43 iters)\n",
      "[Epoch 34] iter 43/43, avg loss: 0.0476\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "426                       | 426                       | 0.9090\n",
      "VBH6554                   | VBH6554                   | 0.9897\n",
      "SU5174J                   | SU5174J                   | 0.9843\n",
      "QAB5858                   | QAB5858                   | 0.9957\n",
      "TCT2301                   | TCT2301                   | 0.9532\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 34 done in 3.2s | train_loss=0.0476  valid_loss=0.4460  valid_acc=73.18%\n",
      "\n",
      "no improvement for 5/100 epochs\n",
      "\n",
      "→ Starting epoch 35  (printing every 43 iters)\n",
      "[Epoch 35] iter 43/43, avg loss: 0.0139\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VJJ!5970                  | VJJ!5970                  | 0.9475\n",
      "QAA9839E                  | QAA9839E                  | 0.9971\n",
      "VBY8203                   | VBY8203                   | 0.9550\n",
      "VMC3545                   | VMC3545                   | 0.9939\n",
      "QAA2269Y                  | QAA2269Y                  | 0.9591\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 35 done in 3.1s | train_loss=0.0139  valid_loss=0.4350  valid_acc=72.89%\n",
      "\n",
      "no improvement for 6/100 epochs\n",
      "\n",
      "→ Starting epoch 36  (printing every 43 iters)\n",
      "[Epoch 36] iter 43/43, avg loss: 0.0081\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "KAK!2474                  | KAK!2474                  | 0.9616\n",
      "QTY9455                   | QTY9455                   | 0.9635\n",
      "RX8899                    | RX8899                    | 0.9815\n",
      "QM!7099P                  | QM!7099P                  | 0.9779\n",
      "QCR2878                   | QCR2878                   | 0.9794\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 36 done in 3.2s | train_loss=0.0081  valid_loss=0.4426  valid_acc=75.22%\n",
      "\n",
      "no improvement for 7/100 epochs\n",
      "\n",
      "→ Starting epoch 37  (printing every 43 iters)\n",
      "[Epoch 37] iter 43/43, avg loss: 0.0039\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAA9552A                  | QAA9552A                  | 0.9964\n",
      "VBV198                    | VBV198                    | 0.9774\n",
      "WXQ6691                   | WXQ6691                   | 0.9950\n",
      "SD3933P                   | SD3933P                   | 0.9964\n",
      "BJA!2450                  | BJA!2450                  | 0.9687\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 37 done in 3.2s | train_loss=0.0039  valid_loss=0.4504  valid_acc=76.38%\n",
      "\n",
      "no improvement for 8/100 epochs\n",
      "\n",
      "→ Starting epoch 38  (printing every 43 iters)\n",
      "[Epoch 38] iter 43/43, avg loss: 0.0030\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WD8974A                   | WD8974A                   | 0.9820\n",
      "T/BB578                   | T/BB578                   | 0.9685\n",
      "BLJ6613                   | BLJ6613                   | 0.9548\n",
      "FFF2966                   | FFF2966                   | 0.9709\n",
      "WC3688R                   | WC3688R                   | 0.9676\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 38 done in 3.2s | train_loss=0.0030  valid_loss=0.4413  valid_acc=76.97%\n",
      "\n",
      "💾 New best model saved (epoch 38, val_acc=76.97%)\n",
      "\n",
      "→ Starting epoch 39  (printing every 43 iters)\n",
      "[Epoch 39] iter 43/43, avg loss: 0.0030\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "MCN!7929                  | MCN!7929                  | 0.9584\n",
      "SD288V                    | SD288V                    | 0.9861\n",
      "QMY4519                   | QMY4519                   | 0.9561\n",
      "QAA4693Q                  | QAA4693Q                  | 0.9984\n",
      "QCG9631                   | QCG9631                   | 0.9593\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 39 done in 3.2s | train_loss=0.0030  valid_loss=0.4597  valid_acc=77.26%\n",
      "\n",
      "💾 New best model saved (epoch 39, val_acc=77.26%)\n",
      "\n",
      "→ Starting epoch 40  (printing every 43 iters)\n",
      "[Epoch 40] iter 43/43, avg loss: 0.0025\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WFH6380                   | WFH6380                   | 0.9645\n",
      "QAA!9381W                 | QAA!9381W                 | 0.9584\n",
      "QAA7961C                  | QAA7961C                  | 0.9617\n",
      "AHN!1732                  | AHN!1732                  | 0.9821\n",
      "QKW5158                   | QKW5158                   | 0.9795\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 40 done in 3.2s | train_loss=0.0025  valid_loss=0.4551  valid_acc=76.09%\n",
      "\n",
      "no improvement for 1/100 epochs\n",
      "\n",
      "→ Starting epoch 41  (printing every 43 iters)\n",
      "[Epoch 41] iter 43/43, avg loss: 0.0023\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "PMF!2507                  | PMF!2507                  | 0.9743\n",
      "PJN!538                   | PJN!538                   | 0.9736\n",
      "VAH!7666                  | VAH!7666                  | 0.9930\n",
      "BPA!4342                  | BPA!4342                  | 0.9841\n",
      "QAB9656H                  | QAB9656H                  | 0.9958\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 41 done in 3.3s | train_loss=0.0023  valid_loss=0.4583  valid_acc=76.97%\n",
      "\n",
      "no improvement for 2/100 epochs\n",
      "\n",
      "→ Starting epoch 42  (printing every 43 iters)\n",
      "[Epoch 42] iter 43/43, avg loss: 0.0026\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "MCV1838                   | MCV1838                   | 0.9777\n",
      "QAB401E                   | QAB401E                   | 0.9974\n",
      "QPB615                    | QPB615                    | 0.9680\n",
      "JV271                     | JV271                     | 0.9402\n",
      "JJE!2328                  | JJE!2328                  | 0.9722\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 42 done in 3.2s | train_loss=0.0026  valid_loss=0.4432  valid_acc=76.97%\n",
      "\n",
      "no improvement for 3/100 epochs\n",
      "\n",
      "→ Starting epoch 43  (printing every 43 iters)\n",
      "[Epoch 43] iter 43/43, avg loss: 0.0018\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VNF1215                   | VNF1215                   | 0.9983\n",
      "VDV7199                   | VDV7199                   | 0.9899\n",
      "QMY4519                   | QMY4519                   | 0.9595\n",
      "VHG1732                   | VHG1732                   | 0.9861\n",
      "BRY8828                   | BRY8828                   | 0.9869\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 43 done in 3.2s | train_loss=0.0018  valid_loss=0.4595  valid_acc=76.97%\n",
      "\n",
      "no improvement for 4/100 epochs\n",
      "\n",
      "→ Starting epoch 44  (printing every 43 iters)\n",
      "[Epoch 44] iter 43/43, avg loss: 0.0015\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "T/BD8758                  | T/BD8758                  | 0.9826\n",
      "TBE9333                   | TBE9333                   | 0.9531\n",
      "W1301R                    | W1301R                    | 0.9979\n",
      "QSP!5188                  | QSP!5188                  | 0.9429\n",
      "KEG!9999                  | KEG!9999                  | 0.9198\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 44 done in 3.1s | train_loss=0.0015  valid_loss=0.4696  valid_acc=76.68%\n",
      "\n",
      "no improvement for 5/100 epochs\n",
      "\n",
      "→ Starting epoch 45  (printing every 43 iters)\n",
      "[Epoch 45] iter 43/43, avg loss: 0.0013\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "PMV4916                   | PMV4916                   | 0.9714\n",
      "QAA1918D                  | QAA1918D                  | 0.9976\n",
      "NEA1254                   | NEA1254                   | 0.9715\n",
      "WUX4391                   | WUX4391                   | 0.9857\n",
      "AHN!1732                  | AHN!1732                  | 0.9573\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 45 done in 3.2s | train_loss=0.0013  valid_loss=0.4693  valid_acc=77.26%\n",
      "\n",
      "no improvement for 6/100 epochs\n",
      "\n",
      "→ Starting epoch 46  (printing every 43 iters)\n",
      "[Epoch 46] iter 43/43, avg loss: 0.0013\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VDV7199                   | VDV7199                   | 0.9857\n",
      "QCH2778                   | QCH2778                   | 0.9745\n",
      "QMU969                    | QMU969                    | 0.9919\n",
      "JNB!9682                  | JNB!9682                  | 0.9954\n",
      "SJF!5203                  | SJF!5203                  | 0.9856\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 46 done in 3.2s | train_loss=0.0013  valid_loss=0.4673  valid_acc=76.97%\n",
      "\n",
      "no improvement for 7/100 epochs\n",
      "\n",
      "→ Starting epoch 47  (printing every 43 iters)\n",
      "[Epoch 47] iter 43/43, avg loss: 0.0012\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "JRK1292                   | JRK1292                   | 0.9561\n",
      "VLL!1474                  | VLL!1474                  | 0.9510\n",
      "QLB8533                   | QLB8533                   | 0.9958\n",
      "CCP8081                   | CCP8081                   | 0.9729\n",
      "T/JA6344                  | T/JA6344                  | 0.9859\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 47 done in 3.1s | train_loss=0.0012  valid_loss=0.4700  valid_acc=76.97%\n",
      "\n",
      "no improvement for 8/100 epochs\n",
      "\n",
      "→ Starting epoch 48  (printing every 43 iters)\n",
      "[Epoch 48] iter 43/43, avg loss: 0.0011\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "MAG!7025                  | MAG!7025                  | 0.9769\n",
      "CFB3006                   | CFB3006                   | 0.9987\n",
      "QAA!9381W                 | QAA!9381W                 | 0.9812\n",
      "RT1911                    | RT1911                    | 0.9945\n",
      "T/BD!8333                 | T/BD!8333                 | 0.9078\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 48 done in 3.2s | train_loss=0.0011  valid_loss=0.4673  valid_acc=76.97%\n",
      "\n",
      "no improvement for 9/100 epochs\n",
      "\n",
      "→ Starting epoch 49  (printing every 43 iters)\n",
      "[Epoch 49] iter 43/43, avg loss: 0.0010\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAA8801X                  | QAA8801X                  | 0.9861\n",
      "QAB221                    | QAB221                    | 0.9896\n",
      "QAM5330                   | QAM5330                   | 0.9617\n",
      "QSX2233                   | QSX2233                   | 0.9988\n",
      "VNH9099                   | VNH9099                   | 0.9883\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 49 done in 3.1s | train_loss=0.0010  valid_loss=0.4722  valid_acc=76.68%\n",
      "\n",
      "no improvement for 10/100 epochs\n",
      "\n",
      "→ Starting epoch 50  (printing every 43 iters)\n",
      "[Epoch 50] iter 43/43, avg loss: 0.0010\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "B3106A                    | B3106A                    | 0.9858\n",
      "PMU!3220                  | PMU!3220                  | 0.9803\n",
      "QAA!8698P                 | QAA!8698P                 | 0.9577\n",
      "PGX9411                   | PGX9411                   | 0.9923\n",
      "UNIMAS6119                | UNIMAS6119                | 0.9304\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 50 done in 3.3s | train_loss=0.0010  valid_loss=0.4752  valid_acc=77.26%\n",
      "\n",
      "no improvement for 11/100 epochs\n",
      "\n",
      "→ Starting epoch 51  (printing every 43 iters)\n",
      "[Epoch 51] iter 43/43, avg loss: 0.0009\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QCM4320                   | QCM4320                   | 0.9757\n",
      "VGF!4942                  | VGF!4942                  | 0.9815\n",
      "QAK1881                   | QAK1881                   | 0.9853\n",
      "VGK9975                   | VGK9975                   | 0.9852\n",
      "JNA5822                   | JNA5822                   | 0.9796\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 51 done in 3.2s | train_loss=0.0009  valid_loss=0.4806  valid_acc=77.26%\n",
      "\n",
      "no improvement for 12/100 epochs\n",
      "\n",
      "→ Starting epoch 52  (printing every 43 iters)\n",
      "[Epoch 52] iter 43/43, avg loss: 0.0009\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "SW2769                    | SW2769                    | 0.9548\n",
      "VJR!1999                  | VJR!1999                  | 0.9318\n",
      "WB1351J                   | WB1351J                   | 0.9727\n",
      "W3426P                    | W3426P                    | 0.9805\n",
      "WQX3834                   | WQX3834                   | 0.9864\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 52 done in 3.2s | train_loss=0.0009  valid_loss=0.4826  valid_acc=77.55%\n",
      "\n",
      "💾 New best model saved (epoch 52, val_acc=77.55%)\n",
      "\n",
      "→ Starting epoch 53  (printing every 43 iters)\n",
      "[Epoch 53] iter 43/43, avg loss: 0.0008\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WD1915A                   | WD1915A                   | 0.9516\n",
      "SM2004                    | SM2004                    | 0.9736\n",
      "QM3245P                   | QM3245P                   | 0.9665\n",
      "QCJ6959                   | QCJ6959                   | 0.9850\n",
      "AEP!7737                  | AEP!7737                  | 0.9906\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 53 done in 3.3s | train_loss=0.0008  valid_loss=0.4901  valid_acc=76.97%\n",
      "\n",
      "no improvement for 1/100 epochs\n",
      "\n",
      "→ Starting epoch 54  (printing every 43 iters)\n",
      "[Epoch 54] iter 43/43, avg loss: 0.0008\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VHR7459                   | VHR7459                   | 0.9857\n",
      "WDC!4844                  | WDC!4844                  | 0.9458\n",
      "QAB1879C                  | QAB1879C                  | 0.9988\n",
      "BHS5465                   | BHS5465                   | 0.9596\n",
      "JV271                     | JV271                     | 0.9455\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 54 done in 3.2s | train_loss=0.0008  valid_loss=0.4858  valid_acc=77.55%\n",
      "\n",
      "no improvement for 2/100 epochs\n",
      "\n",
      "→ Starting epoch 55  (printing every 43 iters)\n",
      "[Epoch 55] iter 43/43, avg loss: 0.0008\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "W1301R                    | W1301R                    | 0.9992\n",
      "QCP8767                   | QCP8767                   | 0.9673\n",
      "WCP3338                   | WCP3338                   | 0.9774\n",
      "WTL9654                   | WTL9654                   | 0.9906\n",
      "WGS3960                   | WGS3960                   | 0.9727\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 55 done in 3.1s | train_loss=0.0008  valid_loss=0.4817  valid_acc=77.26%\n",
      "\n",
      "no improvement for 3/100 epochs\n",
      "\n",
      "→ Starting epoch 56  (printing every 43 iters)\n",
      "[Epoch 56] iter 43/43, avg loss: 0.0008\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAM1008                   | QAM1008                   | 0.9995\n",
      "JVD7333                   | JVD7333                   | 0.9616\n",
      "QBC!4734                  | QBC!4734                  | 0.9848\n",
      "XOIC29                    | XOIC29                    | 0.9731\n",
      "QLE5670                   | QLE5670                   | 0.9904\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 56 done in 3.2s | train_loss=0.0008  valid_loss=0.4800  valid_acc=76.68%\n",
      "\n",
      "no improvement for 4/100 epochs\n",
      "\n",
      "→ Starting epoch 57  (printing every 43 iters)\n",
      "[Epoch 57] iter 43/43, avg loss: 0.0008\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "NBC771                    | NBC771                    | 0.9875\n",
      "KDC!4153                  | KDC!4153                  | 0.9801\n",
      "CFB3006                   | CFB3006                   | 0.9989\n",
      "QBG411                    | QBG411                    | 0.9795\n",
      "MDJ!6389                  | MDJ!6389                  | 0.9410\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 57 done in 3.1s | train_loss=0.0008  valid_loss=0.4849  valid_acc=76.68%\n",
      "\n",
      "no improvement for 5/100 epochs\n",
      "\n",
      "→ Starting epoch 58  (printing every 43 iters)\n",
      "[Epoch 58] iter 43/43, avg loss: 0.0007\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QTS6613                   | QTS6613                   | 0.9979\n",
      "RAS1003                   | RAS1003                   | 0.9957\n",
      "VM6611                    | VM6611                    | 0.9885\n",
      "WVB5362                   | WVB5362                   | 0.9821\n",
      "NDC8617                   | NDC8617                   | 0.9636\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 58 done in 3.2s | train_loss=0.0007  valid_loss=0.4867  valid_acc=76.68%\n",
      "\n",
      "no improvement for 6/100 epochs\n",
      "\n",
      "→ Starting epoch 59  (printing every 43 iters)\n",
      "[Epoch 59] iter 43/43, avg loss: 0.0007\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VKS!4174                  | VKS!4174                  | 0.9772\n",
      "ANB!9161                  | ANB!9161                  | 0.9881\n",
      "SJC1718                   | SJC1718                   | 0.9853\n",
      "WFX7807                   | WFX7807                   | 0.9665\n",
      "VNL9999                   | VNL9999                   | 0.9972\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 59 done in 3.1s | train_loss=0.0007  valid_loss=0.4828  valid_acc=75.51%\n",
      "\n",
      "no improvement for 7/100 epochs\n",
      "\n",
      "→ Starting epoch 60  (printing every 43 iters)\n",
      "[Epoch 60] iter 43/43, avg loss: 0.0006\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "SD2901V                   | SD2901V                   | 0.9683\n",
      "QCJ!6565                  | QCJ!6565                  | 0.9666\n",
      "QAB9886J                  | QAB9886J                  | 0.9757\n",
      "KBJ5226                   | KBJ5226                   | 0.9666\n",
      "JVV4188                   | JVV4188                   | 0.9374\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 60 done in 3.0s | train_loss=0.0006  valid_loss=0.4875  valid_acc=76.97%\n",
      "\n",
      "no improvement for 8/100 epochs\n",
      "\n",
      "→ Starting epoch 61  (printing every 43 iters)\n",
      "[Epoch 61] iter 43/43, avg loss: 0.0006\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WFH6380                   | WFH6380                   | 0.9691\n",
      "QKV465                    | QKV465                    | 0.9804\n",
      "W2485B                    | W2485B                    | 0.9381\n",
      "AFM2020                   | AFM2020                   | 0.9982\n",
      "UMK!8883                  | UMK!8883                  | 0.9803\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 61 done in 3.2s | train_loss=0.0006  valid_loss=0.4902  valid_acc=76.09%\n",
      "\n",
      "no improvement for 9/100 epochs\n",
      "\n",
      "→ Starting epoch 62  (printing every 43 iters)\n",
      "[Epoch 62] iter 43/43, avg loss: 0.0006\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VNQ4338                   | VNQ4338                   | 0.9954\n",
      "WA868H                    | WA868H                    | 0.9986\n",
      "QCG7936                   | QCG7936                   | 0.9614\n",
      "TCA7899                   | TCA7899                   | 0.9831\n",
      "QAB7401J                  | QAB7401J                  | 0.9937\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 62 done in 3.1s | train_loss=0.0006  valid_loss=0.4933  valid_acc=76.97%\n",
      "\n",
      "no improvement for 10/100 epochs\n",
      "\n",
      "→ Starting epoch 63  (printing every 43 iters)\n",
      "[Epoch 63] iter 43/43, avg loss: 0.0007\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WA8029J                   | WA8029J                   | 0.9724\n",
      "BSE!6665                  | BSE!6665                  | 0.9451\n",
      "QCB!1921                  | QCB!1921                  | 0.9545\n",
      "QMW2233                   | QMW2233                   | 0.9351\n",
      "RT9009                    | RT9009                    | 0.9857\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 63 done in 3.1s | train_loss=0.0007  valid_loss=0.4900  valid_acc=76.68%\n",
      "\n",
      "no improvement for 11/100 epochs\n",
      "\n",
      "→ Starting epoch 64  (printing every 43 iters)\n",
      "[Epoch 64] iter 43/43, avg loss: 0.0007\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "BRY8828                   | BRY8828                   | 0.9829\n",
      "QAB707K                   | QAB707K                   | 0.9840\n",
      "SYP3885                   | SYP3885                   | 0.9609\n",
      "QCJ2305                   | QCJ2305                   | 0.9730\n",
      "QAA!9381W                 | QAA!9381W                 | 0.9717\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 64 done in 3.1s | train_loss=0.0007  valid_loss=0.4956  valid_acc=77.84%\n",
      "\n",
      "💾 New best model saved (epoch 64, val_acc=77.84%)\n",
      "\n",
      "→ Starting epoch 65  (printing every 43 iters)\n",
      "[Epoch 65] iter 43/43, avg loss: 0.0006\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "PMT5916                   | PMT5916                   | 0.9926\n",
      "DAG309                    | DAG309                    | 0.9983\n",
      "NAD!9748                  | NAD!9748                  | 0.9774\n",
      "BRA2127                   | BRA2127                   | 0.9635\n",
      "HQ2186                    | HQ2186                    | 0.9821\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 65 done in 3.1s | train_loss=0.0006  valid_loss=0.5023  valid_acc=76.09%\n",
      "\n",
      "no improvement for 1/100 epochs\n",
      "\n",
      "→ Starting epoch 66  (printing every 43 iters)\n",
      "[Epoch 66] iter 43/43, avg loss: 0.0005\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "KCD9595                   | KCD9595                   | 0.9785\n",
      "WC3255U                   | WC3255U                   | 0.9771\n",
      "QKD4636                   | QKD4636                   | 0.9871\n",
      "QCS7175                   | QCS7175                   | 0.9747\n",
      "AMB!1960                  | AMB!1960                  | 0.9520\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 66 done in 3.2s | train_loss=0.0005  valid_loss=0.5011  valid_acc=76.68%\n",
      "\n",
      "no improvement for 2/100 epochs\n",
      "\n",
      "→ Starting epoch 67  (printing every 43 iters)\n",
      "[Epoch 67] iter 43/43, avg loss: 0.0005\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QPA3725                   | QPA3725                   | 0.9859\n",
      "MCC17                     | MCC17                     | 0.9702\n",
      "VKN4650                   | VKN4650                   | 0.9928\n",
      "QSW!8828                  | QSW!8828                  | 0.9630\n",
      "VAP!5570                  | VAP!5570                  | 0.9636\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 67 done in 3.2s | train_loss=0.0005  valid_loss=0.5030  valid_acc=76.68%\n",
      "\n",
      "no improvement for 3/100 epochs\n",
      "\n",
      "→ Starting epoch 68  (printing every 43 iters)\n",
      "[Epoch 68] iter 43/43, avg loss: 0.0004\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "RW6398                    | RW6398                    | 0.9459\n",
      "VEH!6204                  | VEH!6204                  | 0.9936\n",
      "VHC5744                   | VHC5744                   | 0.9932\n",
      "VAK1383                   | VAK1383                   | 0.9786\n",
      "WFN4042                   | WFN4042                   | 0.9727\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 68 done in 3.1s | train_loss=0.0004  valid_loss=0.4998  valid_acc=76.97%\n",
      "\n",
      "no improvement for 4/100 epochs\n",
      "\n",
      "→ Starting epoch 69  (printing every 43 iters)\n",
      "[Epoch 69] iter 43/43, avg loss: 0.0004\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WXY6928                   | WXY6928                   | 0.9981\n",
      "VDV7199                   | VDV7199                   | 0.9717\n",
      "QCE40                     | QCE40                     | 0.9834\n",
      "QM2377M                   | QM2377M                   | 0.9462\n",
      "KDN!1893                  | KDN!1893                  | 0.9853\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 69 done in 3.1s | train_loss=0.0004  valid_loss=0.5001  valid_acc=76.97%\n",
      "\n",
      "no improvement for 5/100 epochs\n",
      "\n",
      "→ Starting epoch 70  (printing every 43 iters)\n",
      "[Epoch 70] iter 43/43, avg loss: 0.0004\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QCS1194                   | QCS1194                   | 0.9962\n",
      "TCA7789                   | TCA7789                   | 0.9767\n",
      "T/NA2954                  | T/NA2954                  | 0.9765\n",
      "QMR2567                   | QMR2567                   | 0.9723\n",
      "QCB3330                   | QCB3330                   | 0.9686\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 70 done in 3.3s | train_loss=0.0004  valid_loss=0.4992  valid_acc=76.97%\n",
      "\n",
      "no improvement for 6/100 epochs\n",
      "\n",
      "→ Starting epoch 71  (printing every 43 iters)\n",
      "[Epoch 71] iter 43/43, avg loss: 0.0004\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "MCT8738                   | MCT8738                   | 0.9880\n",
      "TAM!408                   | TAM!408                   | 0.9619\n",
      "BKJ!3569                  | BKJ!3569                  | 0.9908\n",
      "PLX8764                   | PLX8764                   | 0.9997\n",
      "VFX447                    | VFX447                    | 0.9987\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 71 done in 3.2s | train_loss=0.0004  valid_loss=0.4979  valid_acc=77.55%\n",
      "\n",
      "no improvement for 7/100 epochs\n",
      "\n",
      "→ Starting epoch 72  (printing every 43 iters)\n",
      "[Epoch 72] iter 43/43, avg loss: 0.0004\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "PKV4279                   | PKV4279                   | 0.9742\n",
      "RP!5366                   | RP!5366                   | 0.9954\n",
      "QAA!9381W                 | QAA!9381W                 | 0.9847\n",
      "QCE1128                   | QCE1128                   | 0.9943\n",
      "WQN8002                   | WQN8002                   | 0.9446\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 72 done in 3.2s | train_loss=0.0004  valid_loss=0.5066  valid_acc=76.97%\n",
      "\n",
      "no improvement for 8/100 epochs\n",
      "\n",
      "→ Starting epoch 73  (printing every 43 iters)\n",
      "[Epoch 73] iter 43/43, avg loss: 0.0004\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAA8598S                  | QAA8598S                  | 0.9952\n",
      "KDH!2309                  | KDH!2309                  | 0.9801\n",
      "QAA686G                   | QAA686G                   | 0.9995\n",
      "UMK!8883                  | UMK!8883                  | 0.9503\n",
      "JGA2946                   | JGA2946                   | 0.9651\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 73 done in 3.1s | train_loss=0.0004  valid_loss=0.4994  valid_acc=77.55%\n",
      "\n",
      "no improvement for 9/100 epochs\n",
      "\n",
      "→ Starting epoch 74  (printing every 43 iters)\n",
      "[Epoch 74] iter 43/43, avg loss: 0.0004\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "ALX5554                   | ALX5554                   | 0.9920\n",
      "KDH!2309                  | KDH!2309                  | 0.9687\n",
      "KD!6868Q                  | KD!6868Q                  | 0.9832\n",
      "WFG!4626                  | WFG!4626                  | 0.9660\n",
      "QAB1552A                  | QAB1552A                  | 0.9907\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 74 done in 2.9s | train_loss=0.0004  valid_loss=0.5077  valid_acc=76.97%\n",
      "\n",
      "no improvement for 10/100 epochs\n",
      "\n",
      "→ Starting epoch 75  (printing every 43 iters)\n",
      "[Epoch 75] iter 43/43, avg loss: 0.0004\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "T/M3041                   | T/M3041                   | 0.9965\n",
      "PRH5551                   | PRH5551                   | 0.9966\n",
      "QAU4660                   | QAU4660                   | 0.9822\n",
      "NDD5646                   | NDD5646                   | 0.9911\n",
      "VEH!6204                  | VEH!6204                  | 0.9948\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 75 done in 3.0s | train_loss=0.0004  valid_loss=0.5029  valid_acc=77.26%\n",
      "\n",
      "no improvement for 11/100 epochs\n",
      "\n",
      "→ Starting epoch 76  (printing every 43 iters)\n",
      "[Epoch 76] iter 43/43, avg loss: 0.0004\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "ST5657X                   | ST5657X                   | 0.9665\n",
      "QS110D                    | QS110D                    | 0.9859\n",
      "AML!6313                  | AML!6313                  | 0.9766\n",
      "JLK!9805                  | JLK!9805                  | 0.9590\n",
      "BGQ1741                   | BGQ1741                   | 0.9966\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 76 done in 3.1s | train_loss=0.0004  valid_loss=0.5015  valid_acc=77.55%\n",
      "\n",
      "no improvement for 12/100 epochs\n",
      "\n",
      "→ Starting epoch 77  (printing every 43 iters)\n",
      "[Epoch 77] iter 43/43, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAA3323X                  | QAA3323X                  | 0.9954\n",
      "DEY!9981                  | DEY!9981                  | 0.9881\n",
      "QAA2660J                  | QAA2660J                  | 0.9994\n",
      "MDL1672                   | MDL1672                   | 0.9993\n",
      "WKX!6755                  | WKX!6755                  | 0.9716\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 77 done in 3.0s | train_loss=0.0003  valid_loss=0.5062  valid_acc=76.97%\n",
      "\n",
      "no improvement for 13/100 epochs\n",
      "\n",
      "→ Starting epoch 78  (printing every 43 iters)\n",
      "[Epoch 78] iter 43/43, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAA7961C                  | QAA7961C                  | 0.9972\n",
      "QAU4660                   | QAU4660                   | 0.9970\n",
      "QKT8216                   | QKT8216                   | 0.9900\n",
      "QMU6123                   | QMU6123                   | 0.9929\n",
      "VFH!2157                  | VFH!2157                  | 0.9908\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 78 done in 3.0s | train_loss=0.0003  valid_loss=0.5156  valid_acc=77.26%\n",
      "\n",
      "no improvement for 14/100 epochs\n",
      "\n",
      "→ Starting epoch 79  (printing every 43 iters)\n",
      "[Epoch 79] iter 43/43, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WMX9993                   | WMX9993                   | 0.9744\n",
      "NAP4617                   | NAP4617                   | 0.9980\n",
      "BJM!8453                  | BJM!8453                  | 0.9607\n",
      "VMP2929                   | VMP2929                   | 0.9984\n",
      "QAA!4174                  | QAA!4174                  | 0.9850\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 79 done in 3.1s | train_loss=0.0003  valid_loss=0.5050  valid_acc=77.26%\n",
      "\n",
      "no improvement for 15/100 epochs\n",
      "\n",
      "→ Starting epoch 80  (printing every 43 iters)\n",
      "[Epoch 80] iter 43/43, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "RAS1003                   | RAS1003                   | 0.9939\n",
      "W/TP3358                  | W/TP3358                  | 0.9813\n",
      "QAA!4714P                 | QAA!4714P                 | 0.9634\n",
      "QAA5515N                  | QAA5515N                  | 0.9986\n",
      "NBC771                    | NBC771                    | 0.9708\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 80 done in 3.1s | train_loss=0.0003  valid_loss=0.5073  valid_acc=77.26%\n",
      "\n",
      "no improvement for 16/100 epochs\n",
      "\n",
      "→ Starting epoch 81  (printing every 43 iters)\n",
      "[Epoch 81] iter 43/43, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "PKA!440                   | PKA!440                   | 0.9736\n",
      "WTM!3755                  | WTM!3755                  | 0.9446\n",
      "AM7017                    | AM7017                    | 0.9814\n",
      "BQX!3898                  | BQX!3898                  | 0.9888\n",
      "ANB!9161                  | ANB!9161                  | 0.9788\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 81 done in 3.2s | train_loss=0.0003  valid_loss=0.5052  valid_acc=78.13%\n",
      "\n",
      "💾 New best model saved (epoch 81, val_acc=78.13%)\n",
      "\n",
      "→ Starting epoch 82  (printing every 43 iters)\n",
      "[Epoch 82] iter 43/43, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "FD10                      | FD10                      | 0.9442\n",
      "JWY375                    | JWY375                    | 0.9533\n",
      "NBV6243                   | NBV6243                   | 0.9784\n",
      "QS!8095L                  | QS!8095L                  | 0.9156\n",
      "AKX!8453                  | AKX!8453                  | 0.9868\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 82 done in 3.2s | train_loss=0.0003  valid_loss=0.5113  valid_acc=77.26%\n",
      "\n",
      "no improvement for 1/100 epochs\n",
      "\n",
      "→ Starting epoch 83  (printing every 43 iters)\n",
      "[Epoch 83] iter 43/43, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QSU9715                   | QSU9715                   | 0.9928\n",
      "QRR9945                   | QRR9945                   | 0.9934\n",
      "BRW!9                     | BRW!9                     | 0.9977\n",
      "WPY3991                   | WPY3991                   | 0.9471\n",
      "WQN8002                   | WQN8002                   | 0.9329\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 83 done in 3.3s | train_loss=0.0003  valid_loss=0.5097  valid_acc=76.68%\n",
      "\n",
      "no improvement for 2/100 epochs\n",
      "\n",
      "→ Starting epoch 84  (printing every 43 iters)\n",
      "[Epoch 84] iter 43/43, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAM6622                   | QAM6622                   | 0.9841\n",
      "VLD745                    | VLD745                    | 0.9786\n",
      "QAB2288F                  | QAB2288F                  | 0.9903\n",
      "WCR4455                   | WCR4455                   | 0.9565\n",
      "WTE!2868                  | WTE!2868                  | 0.9838\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 84 done in 3.2s | train_loss=0.0003  valid_loss=0.5142  valid_acc=77.26%\n",
      "\n",
      "no improvement for 3/100 epochs\n",
      "\n",
      "→ Starting epoch 85  (printing every 43 iters)\n",
      "[Epoch 85] iter 43/43, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "BJT8812                   | BJT8812                   | 0.9728\n",
      "QKW3360                   | QKW3360                   | 0.9928\n",
      "QCP5533                   | QCP5533                   | 0.9892\n",
      "QKU7812                   | QKU7812                   | 0.9832\n",
      "TCN!6262                  | TCN!6262                  | 0.9967\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 85 done in 3.0s | train_loss=0.0003  valid_loss=0.5156  valid_acc=76.68%\n",
      "\n",
      "no improvement for 4/100 epochs\n",
      "\n",
      "→ Starting epoch 86  (printing every 43 iters)\n",
      "[Epoch 86] iter 43/43, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "NH2225                    | NH2225                    | 0.9865\n",
      "WGS3960                   | WGS3960                   | 0.9794\n",
      "QCS7968                   | QCS7968                   | 0.9806\n",
      "JV271                     | JV271                     | 0.9658\n",
      "TCM3335                   | TCM3335                   | 0.9920\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 86 done in 3.0s | train_loss=0.0003  valid_loss=0.5165  valid_acc=77.55%\n",
      "\n",
      "no improvement for 5/100 epochs\n",
      "\n",
      "→ Starting epoch 87  (printing every 43 iters)\n",
      "[Epoch 87] iter 43/43, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAA!7324R                 | QAA!7324R                 | 0.9776\n",
      "QRL9988                   | QRL9988                   | 0.9586\n",
      "QAA889Y                   | QAA889Y                   | 0.9977\n",
      "QAA!4673S                 | QAA!4673S                 | 0.9981\n",
      "MDA4607                   | MDA4607                   | 0.9810\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 87 done in 3.0s | train_loss=0.0003  valid_loss=0.5140  valid_acc=76.97%\n",
      "\n",
      "no improvement for 6/100 epochs\n",
      "\n",
      "→ Starting epoch 88  (printing every 43 iters)\n",
      "[Epoch 88] iter 43/43, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "RAM6682                   | RAM6682                   | 0.9984\n",
      "WXJ911                    | WXJ911                    | 0.9969\n",
      "MD3426Q                   | MD3426Q                   | 0.9756\n",
      "T/M232                    | T/M232                    | 0.9879\n",
      "AGC!7322                  | AGC!7322                  | 0.9773\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 88 done in 3.0s | train_loss=0.0003  valid_loss=0.5144  valid_acc=77.26%\n",
      "\n",
      "no improvement for 7/100 epochs\n",
      "\n",
      "→ Starting epoch 89  (printing every 43 iters)\n",
      "[Epoch 89] iter 43/43, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QBD9519                   | QBD9519                   | 0.9560\n",
      "JKN8193                   | JKN8193                   | 0.9921\n",
      "QCH6782                   | QCH6782                   | 0.9877\n",
      "PPT549                    | PPT549                    | 0.9636\n",
      "JSG1987                   | JSG1987                   | 0.9997\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 89 done in 3.0s | train_loss=0.0003  valid_loss=0.5200  valid_acc=77.26%\n",
      "\n",
      "no improvement for 8/100 epochs\n",
      "\n",
      "→ Starting epoch 90  (printing every 43 iters)\n",
      "[Epoch 90] iter 43/43, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VJM4722                   | VJM4722                   | 0.9999\n",
      "AGC!7322                  | AGC!7322                  | 0.9698\n",
      "VJE9410                   | VJE9410                   | 0.9859\n",
      "WXY6928                   | WXY6928                   | 0.9990\n",
      "VC6786                    | VC6786                    | 0.9895\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 90 done in 3.0s | train_loss=0.0003  valid_loss=0.5155  valid_acc=76.97%\n",
      "\n",
      "no improvement for 9/100 epochs\n",
      "\n",
      "→ Starting epoch 91  (printing every 43 iters)\n",
      "[Epoch 91] iter 43/43, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "JHW4868                   | JHW4868                   | 0.9948\n",
      "JLW!8830                  | JLW!8830                  | 0.9494\n",
      "SML6789                   | SML6789                   | 0.9641\n",
      "QCJ4164                   | QCJ4164                   | 0.9942\n",
      "NCH!6650                  | NCH!6650                  | 0.9813\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 91 done in 3.2s | train_loss=0.0003  valid_loss=0.5107  valid_acc=76.68%\n",
      "\n",
      "no improvement for 10/100 epochs\n",
      "\n",
      "→ Starting epoch 92  (printing every 43 iters)\n",
      "[Epoch 92] iter 43/43, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAB9551A                  | QAB9551A                  | 0.9908\n",
      "MCC17                     | MCC17                     | 0.9736\n",
      "QCT1194                   | QCT1194                   | 0.9610\n",
      "QAL315                    | QAL315                    | 0.9907\n",
      "QRF!5010                  | QRF!5010                  | 0.9674\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 92 done in 3.2s | train_loss=0.0003  valid_loss=0.5131  valid_acc=77.26%\n",
      "\n",
      "no improvement for 11/100 epochs\n",
      "\n",
      "→ Starting epoch 93  (printing every 43 iters)\n",
      "[Epoch 93] iter 43/43, avg loss: 0.0003\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VBH6554                   | VBH6554                   | 0.9553\n",
      "QAA!328A                  | QAA!328A                  | 0.9754\n",
      "CEY1822                   | CEY1822                   | 0.9980\n",
      "QTW!7053                  | QTW!7053                  | 0.9849\n",
      "QMA3390                   | QMA3390                   | 0.9639\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 93 done in 3.1s | train_loss=0.0003  valid_loss=0.5224  valid_acc=76.97%\n",
      "\n",
      "no improvement for 12/100 epochs\n",
      "\n",
      "→ Starting epoch 94  (printing every 43 iters)\n",
      "[Epoch 94] iter 43/43, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "JWY375                    | JWY375                    | 0.9711\n",
      "QAB2288F                  | QAB2288F                  | 0.9930\n",
      "QAN4488                   | QAN4488                   | 0.9965\n",
      "VJL3065                   | VJL3065                   | 0.9990\n",
      "WB7028W                   | WB7028W                   | 0.9946\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 94 done in 3.1s | train_loss=0.0002  valid_loss=0.5185  valid_acc=76.97%\n",
      "\n",
      "no improvement for 13/100 epochs\n",
      "\n",
      "→ Starting epoch 95  (printing every 43 iters)\n",
      "[Epoch 95] iter 43/43, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QCE40                     | QCE40                     | 0.9572\n",
      "ADU7533                   | ADU7533                   | 0.9915\n",
      "BJF5469                   | BJF5469                   | 0.9699\n",
      "AHU7727                   | AHU7727                   | 0.9722\n",
      "TBC28                     | TBC28                     | 0.9332\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 95 done in 3.3s | train_loss=0.0002  valid_loss=0.5171  valid_acc=77.26%\n",
      "\n",
      "no improvement for 14/100 epochs\n",
      "\n",
      "→ Starting epoch 96  (printing every 43 iters)\n",
      "[Epoch 96] iter 43/43, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VAW4421                   | VAW4421                   | 0.9992\n",
      "JJT5762                   | JJT5762                   | 0.9961\n",
      "QCD8869                   | QCD8869                   | 0.9704\n",
      "VKP!3405                  | VKP!3405                  | 0.9883\n",
      "QSW!8828                  | QSW!8828                  | 0.9700\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 96 done in 3.1s | train_loss=0.0002  valid_loss=0.5126  valid_acc=77.26%\n",
      "\n",
      "no improvement for 15/100 epochs\n",
      "\n",
      "→ Starting epoch 97  (printing every 43 iters)\n",
      "[Epoch 97] iter 43/43, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QCJ2794                   | QCJ2794                   | 0.9877\n",
      "WTE!2868                  | WTE!2868                  | 0.9815\n",
      "QCP5533                   | QCP5533                   | 0.9906\n",
      "CES!4236                  | CES!4236                  | 0.9887\n",
      "VGK9975                   | VGK9975                   | 0.9810\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 97 done in 3.1s | train_loss=0.0002  valid_loss=0.5203  valid_acc=76.97%\n",
      "\n",
      "no improvement for 16/100 epochs\n",
      "\n",
      "→ Starting epoch 98  (printing every 43 iters)\n",
      "[Epoch 98] iter 43/43, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VAK1383                   | VAK1383                   | 0.9907\n",
      "SYM!4893                  | SYM!4893                  | 0.9706\n",
      "VFT!2934                  | VFT!2934                  | 0.9835\n",
      "QAL9927                   | QAL9927                   | 0.9855\n",
      "W763L                     | W763L                     | 0.9987\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 98 done in 3.1s | train_loss=0.0002  valid_loss=0.5187  valid_acc=77.55%\n",
      "\n",
      "no improvement for 17/100 epochs\n",
      "\n",
      "→ Starting epoch 99  (printing every 43 iters)\n",
      "[Epoch 99] iter 43/43, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "TCT2301                   | TCT2301                   | 0.9957\n",
      "QAB3014G                  | QAB3014G                  | 0.9986\n",
      "WTT!1097                  | WTT!1097                  | 0.9789\n",
      "WQD6028                   | WQD6028                   | 0.9561\n",
      "WTE!2868                  | WTE!2868                  | 0.9821\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 99 done in 3.1s | train_loss=0.0002  valid_loss=0.5164  valid_acc=77.26%\n",
      "\n",
      "no improvement for 18/100 epochs\n",
      "\n",
      "→ Starting epoch 100  (printing every 43 iters)\n",
      "[Epoch 100] iter 43/43, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAA5823N                  | QAA5823N                  | 0.9998\n",
      "BSE!6665                  | BSE!6665                  | 0.9496\n",
      "KFX!7711                  | KFX!7711                  | 0.9960\n",
      "RAQ!7277                  | RAQ!7277                  | 0.9930\n",
      "WUH!8857                  | WUH!8857                  | 0.9894\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 100 done in 3.1s | train_loss=0.0002  valid_loss=0.5235  valid_acc=77.26%\n",
      "\n",
      "no improvement for 19/100 epochs\n",
      "\n",
      "→ Starting epoch 101  (printing every 43 iters)\n",
      "[Epoch 101] iter 43/43, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "RT1911                    | RT1911                    | 0.9989\n",
      "WC8640J                   | WC8640J                   | 0.9902\n",
      "QMY4519                   | QMY4519                   | 0.9854\n",
      "QKM70                     | QKM70                     | 0.9952\n",
      "JWW9378                   | JWW9378                   | 0.9752\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 101 done in 3.1s | train_loss=0.0002  valid_loss=0.5195  valid_acc=76.97%\n",
      "\n",
      "no improvement for 20/100 epochs\n",
      "\n",
      "→ Starting epoch 102  (printing every 43 iters)\n",
      "[Epoch 102] iter 43/43, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAP6228                   | QAP6228                   | 0.9879\n",
      "QAB2170K                  | QAB2170K                  | 0.9996\n",
      "JSL!6628                  | JSL!6628                  | 0.9940\n",
      "WFG!4626                  | WFG!4626                  | 0.9777\n",
      "WEC4500                   | WEC4500                   | 0.9807\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 102 done in 3.1s | train_loss=0.0002  valid_loss=0.5240  valid_acc=76.97%\n",
      "\n",
      "no improvement for 21/100 epochs\n",
      "\n",
      "→ Starting epoch 103  (printing every 43 iters)\n",
      "[Epoch 103] iter 43/43, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QCA3252                   | QCA3252                   | 0.9829\n",
      "VCY1946                   | VCY1946                   | 0.9912\n",
      "SYY9112                   | SYY9112                   | 0.9746\n",
      "QRF!5010                  | QRF!5010                  | 0.9702\n",
      "QKV9823                   | QKV9823                   | 0.9732\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 103 done in 3.1s | train_loss=0.0002  valid_loss=0.5245  valid_acc=76.97%\n",
      "\n",
      "no improvement for 22/100 epochs\n",
      "\n",
      "→ Starting epoch 104  (printing every 43 iters)\n",
      "[Epoch 104] iter 43/43, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "NCQ2205                   | NCQ2205                   | 0.9968\n",
      "KP3300Q                   | KP3300Q                   | 0.9945\n",
      "JPX9136                   | JPX9136                   | 0.9991\n",
      "T/BD!8333                 | T/BD!8333                 | 0.9220\n",
      "SMJ1366                   | SMJ1366                   | 0.9740\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 104 done in 3.2s | train_loss=0.0002  valid_loss=0.5225  valid_acc=77.26%\n",
      "\n",
      "no improvement for 23/100 epochs\n",
      "\n",
      "→ Starting epoch 105  (printing every 43 iters)\n",
      "[Epoch 105] iter 43/43, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WXM1116                   | WXM1116                   | 0.9769\n",
      "WQP1991                   | WQP1991                   | 0.9589\n",
      "QTR!80                    | QTR!80                    | 0.9842\n",
      "ALN8722                   | ALN8722                   | 0.9966\n",
      "QP4444                    | QP4444                    | 0.9932\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 105 done in 3.1s | train_loss=0.0002  valid_loss=0.5157  valid_acc=77.26%\n",
      "\n",
      "no improvement for 24/100 epochs\n",
      "\n",
      "→ Starting epoch 106  (printing every 43 iters)\n",
      "[Epoch 106] iter 43/43, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "JMW!7452                  | JMW!7452                  | 0.9916\n",
      "VN815                     | VN815                     | 0.9768\n",
      "QAP6228                   | QAP6228                   | 0.9970\n",
      "QPA2092                   | QPA2092                   | 0.9234\n",
      "QST6086                   | QST6086                   | 0.9733\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 106 done in 3.1s | train_loss=0.0002  valid_loss=0.5232  valid_acc=77.26%\n",
      "\n",
      "no improvement for 25/100 epochs\n",
      "\n",
      "→ Starting epoch 107  (printing every 43 iters)\n",
      "[Epoch 107] iter 43/43, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAB1879C                  | QAB1879C                  | 0.9997\n",
      "WQN4163                   | WQN4163                   | 0.9826\n",
      "LE7021                    | LE7021                    | 0.9996\n",
      "BPT2823                   | BPT2823                   | 0.9943\n",
      "NCB!7903                  | NCB!7903                  | 0.9848\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 107 done in 3.1s | train_loss=0.0002  valid_loss=0.5210  valid_acc=76.97%\n",
      "\n",
      "no improvement for 26/100 epochs\n",
      "\n",
      "→ Starting epoch 108  (printing every 43 iters)\n",
      "[Epoch 108] iter 43/43, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "ANU7888                   | ANU7888                   | 0.9989\n",
      "QSY!27                    | QSY!27                    | 0.9733\n",
      "RAQ!7877                  | RAQ!7877                  | 0.9744\n",
      "SM2004                    | SM2004                    | 0.9529\n",
      "LH9996                    | LH9996                    | 0.9900\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 108 done in 3.1s | train_loss=0.0002  valid_loss=0.5210  valid_acc=76.68%\n",
      "\n",
      "no improvement for 27/100 epochs\n",
      "\n",
      "→ Starting epoch 109  (printing every 43 iters)\n",
      "[Epoch 109] iter 43/43, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "DFC7000                   | DFC7000                   | 0.9995\n",
      "QAT2882                   | QAT2882                   | 0.9976\n",
      "RP!5366                   | RP!5366                   | 0.9803\n",
      "QM6676C                   | QM6676C                   | 0.9954\n",
      "PDP6868                   | PDP6868                   | 0.9429\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 109 done in 3.1s | train_loss=0.0002  valid_loss=0.5302  valid_acc=77.26%\n",
      "\n",
      "no improvement for 28/100 epochs\n",
      "\n",
      "→ Starting epoch 110  (printing every 43 iters)\n",
      "[Epoch 110] iter 43/43, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WC4922X                   | WC4922X                   | 0.9946\n",
      "QAX!2076                  | QAX!2076                  | 0.9982\n",
      "NCP!9457                  | NCP!9457                  | 0.9492\n",
      "WTP210                    | WTP210                    | 0.9658\n",
      "VNQ4338                   | VNQ4338                   | 0.9976\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 110 done in 3.1s | train_loss=0.0002  valid_loss=0.5274  valid_acc=76.38%\n",
      "\n",
      "no improvement for 29/100 epochs\n",
      "\n",
      "→ Starting epoch 111  (printing every 43 iters)\n",
      "[Epoch 111] iter 43/43, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAA!4174                  | QAA!4174                  | 0.9688\n",
      "WSY5453                   | WSY5453                   | 0.9882\n",
      "QAP5276                   | QAP5276                   | 0.9970\n",
      "KD!6868Q                  | KD!6868Q                  | 0.9799\n",
      "QPA3382                   | QPA3382                   | 0.9881\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 111 done in 3.1s | train_loss=0.0002  valid_loss=0.5270  valid_acc=76.97%\n",
      "\n",
      "no improvement for 30/100 epochs\n",
      "\n",
      "→ Starting epoch 112  (printing every 43 iters)\n",
      "[Epoch 112] iter 43/43, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VAQ2618                   | VAQ2618                   | 0.9994\n",
      "JTN!1919                  | JTN!1919                  | 0.9858\n",
      "AKT!3104                  | AKT!3104                  | 0.9781\n",
      "WFB2641                   | WFB2641                   | 0.9699\n",
      "SWK4479                   | SWK4479                   | 0.9174\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 112 done in 3.2s | train_loss=0.0002  valid_loss=0.5278  valid_acc=77.26%\n",
      "\n",
      "no improvement for 31/100 epochs\n",
      "\n",
      "→ Starting epoch 113  (printing every 43 iters)\n",
      "[Epoch 113] iter 43/43, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "KBJ5226                   | KBJ5226                   | 0.9463\n",
      "WUT!2636                  | WUT!2636                  | 0.9982\n",
      "PJS1739                   | PJS1739                   | 0.9830\n",
      "WQX3834                   | WQX3834                   | 0.9921\n",
      "AM9232                    | AM9232                    | 0.9890\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 113 done in 3.2s | train_loss=0.0002  valid_loss=0.5277  valid_acc=76.68%\n",
      "\n",
      "no improvement for 32/100 epochs\n",
      "\n",
      "→ Starting epoch 114  (printing every 43 iters)\n",
      "[Epoch 114] iter 43/43, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VDP!5735                  | VDP!5735                  | 0.9033\n",
      "BFP7470                   | BFP7470                   | 0.9835\n",
      "JTN!1919                  | JTN!1919                  | 0.9798\n",
      "JSH9196                   | JSH9196                   | 0.9613\n",
      "KAK!2474                  | KAK!2474                  | 0.9341\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 114 done in 3.2s | train_loss=0.0002  valid_loss=0.5229  valid_acc=77.55%\n",
      "\n",
      "no improvement for 33/100 epochs\n",
      "\n",
      "→ Starting epoch 115  (printing every 43 iters)\n",
      "[Epoch 115] iter 43/43, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VBH6554                   | VBH6554                   | 0.9776\n",
      "BFP7470                   | BFP7470                   | 0.9889\n",
      "QAA2705N                  | QAA2705N                  | 0.9650\n",
      "QMU595                    | QMU595                    | 0.9324\n",
      "QMU969                    | QMU969                    | 0.9711\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 115 done in 3.1s | train_loss=0.0002  valid_loss=0.5310  valid_acc=76.97%\n",
      "\n",
      "no improvement for 34/100 epochs\n",
      "\n",
      "→ Starting epoch 116  (printing every 43 iters)\n",
      "[Epoch 116] iter 43/43, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WEC4500                   | WEC4500                   | 0.9881\n",
      "BNY!4363                  | BNY!4363                  | 0.9862\n",
      "QAB9668H                  | QAB9668H                  | 0.9623\n",
      "QAB7646E                  | QAB7646E                  | 0.9973\n",
      "WTK7060                   | WTK7060                   | 0.9709\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 116 done in 3.1s | train_loss=0.0002  valid_loss=0.5250  valid_acc=77.55%\n",
      "\n",
      "no improvement for 35/100 epochs\n",
      "\n",
      "→ Starting epoch 117  (printing every 43 iters)\n",
      "[Epoch 117] iter 43/43, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QM3245P                   | QM3245P                   | 0.9779\n",
      "JRN!7985                  | JRN!7985                  | 0.9921\n",
      "QS1595E                   | QS1595E                   | 0.9957\n",
      "JKH9699                   | JKH9699                   | 0.9947\n",
      "QAA5623H                  | QAA5623H                  | 0.9998\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 117 done in 3.1s | train_loss=0.0002  valid_loss=0.5302  valid_acc=77.26%\n",
      "\n",
      "no improvement for 36/100 epochs\n",
      "\n",
      "→ Starting epoch 118  (printing every 43 iters)\n",
      "[Epoch 118] iter 43/43, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAA5823N                  | QAA5823N                  | 0.9996\n",
      "UMT6556                   | UMT6556                   | 0.9647\n",
      "PNB6727                   | PNB6727                   | 0.9981\n",
      "MDH7007                   | MDH7007                   | 0.9681\n",
      "VLL7887                   | VLL7887                   | 0.9997\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 118 done in 3.1s | train_loss=0.0002  valid_loss=0.5330  valid_acc=77.26%\n",
      "\n",
      "no improvement for 37/100 epochs\n",
      "\n",
      "→ Starting epoch 119  (printing every 43 iters)\n",
      "[Epoch 119] iter 43/43, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "AML!6313                  | AML!6313                  | 0.9769\n",
      "QAG3688                   | QAG3688                   | 0.9983\n",
      "QP4444                    | QP4444                    | 0.9957\n",
      "JVD7333                   | JVD7333                   | 0.9461\n",
      "AER7905                   | AER7905                   | 0.9887\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 119 done in 3.1s | train_loss=0.0002  valid_loss=0.5289  valid_acc=76.97%\n",
      "\n",
      "no improvement for 38/100 epochs\n",
      "\n",
      "→ Starting epoch 120  (printing every 43 iters)\n",
      "[Epoch 120] iter 43/43, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "NDN3779                   | NDN3779                   | 0.9995\n",
      "WYX8694                   | WYX8694                   | 0.9638\n",
      "DDM8378                   | DDM8378                   | 0.9895\n",
      "VGT9721                   | VGT9721                   | 0.9889\n",
      "QAK1881                   | QAK1881                   | 0.9760\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 120 done in 3.1s | train_loss=0.0002  valid_loss=0.5327  valid_acc=76.97%\n",
      "\n",
      "no improvement for 39/100 epochs\n",
      "\n",
      "→ Starting epoch 121  (printing every 43 iters)\n",
      "[Epoch 121] iter 43/43, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAR9868                   | QAR9868                   | 0.9837\n",
      "QAX!8997                  | QAX!8997                  | 0.9845\n",
      "QAA!6846U                 | QAA!6846U                 | 0.9382\n",
      "JSG1987                   | JSG1987                   | 0.9998\n",
      "QRT!9620                  | QRT!9620                  | 0.9802\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 121 done in 3.1s | train_loss=0.0002  valid_loss=0.5279  valid_acc=76.97%\n",
      "\n",
      "no improvement for 40/100 epochs\n",
      "\n",
      "→ Starting epoch 122  (printing every 43 iters)\n",
      "[Epoch 122] iter 43/43, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QCE3369                   | QCE3369                   | 0.9938\n",
      "QCB1918                   | QCB1918                   | 0.9777\n",
      "SYM!4893                  | SYM!4893                  | 0.9615\n",
      "VGN2263                   | VGN2263                   | 0.9627\n",
      "CEG8119                   | CEG8119                   | 0.9973\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 122 done in 3.1s | train_loss=0.0002  valid_loss=0.5347  valid_acc=77.55%\n",
      "\n",
      "no improvement for 41/100 epochs\n",
      "\n",
      "→ Starting epoch 123  (printing every 43 iters)\n",
      "[Epoch 123] iter 43/43, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WPH!317                   | WPH!317                   | 0.9645\n",
      "BPL7211                   | BPL7211                   | 0.9688\n",
      "QAB1480F                  | QAB1480F                  | 0.9787\n",
      "JSB1749                   | JSB1749                   | 0.9990\n",
      "QCR271                    | QCR271                    | 0.9620\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 123 done in 3.1s | train_loss=0.0002  valid_loss=0.5305  valid_acc=77.26%\n",
      "\n",
      "no improvement for 42/100 epochs\n",
      "\n",
      "→ Starting epoch 124  (printing every 43 iters)\n",
      "[Epoch 124] iter 43/43, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WC3255U                   | WC3255U                   | 0.9836\n",
      "AHN!1732                  | AHN!1732                  | 0.9695\n",
      "QKV9823                   | QKV9823                   | 0.9766\n",
      "QAA2660J                  | QAA2660J                  | 0.9938\n",
      "ANK!8132                  | ANK!8132                  | 0.9762\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 124 done in 3.1s | train_loss=0.0002  valid_loss=0.5283  valid_acc=77.26%\n",
      "\n",
      "no improvement for 43/100 epochs\n",
      "\n",
      "→ Starting epoch 125  (printing every 43 iters)\n",
      "[Epoch 125] iter 43/43, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "KFT4037                   | KFT4037                   | 0.9978\n",
      "NDL7330                   | NDL7330                   | 0.9982\n",
      "VBH6554                   | VBH6554                   | 0.9666\n",
      "WYX!1232                  | WYX!1232                  | 0.9782\n",
      "PGL!2189                  | PGL!2189                  | 0.9688\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 125 done in 3.1s | train_loss=0.0002  valid_loss=0.5312  valid_acc=76.97%\n",
      "\n",
      "no improvement for 44/100 epochs\n",
      "\n",
      "→ Starting epoch 126  (printing every 43 iters)\n",
      "[Epoch 126] iter 43/43, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QRB8366                   | QRB8366                   | 0.9627\n",
      "QRR9945                   | QRR9945                   | 0.9933\n",
      "MCN!7929                  | MCN!7929                  | 0.9687\n",
      "T/JA213                   | T/JA213                   | 0.9992\n",
      "VNG!8061                  | VNG!8061                  | 0.9497\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 126 done in 3.0s | train_loss=0.0002  valid_loss=0.5331  valid_acc=76.97%\n",
      "\n",
      "no improvement for 45/100 epochs\n",
      "\n",
      "→ Starting epoch 127  (printing every 43 iters)\n",
      "[Epoch 127] iter 43/43, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "BGW!2901                  | BGW!2901                  | 0.9803\n",
      "RAY!5050                  | RAY!5050                  | 0.9989\n",
      "QPA3725                   | QPA3725                   | 0.9247\n",
      "KD!6868Q                  | KD!6868Q                  | 0.9616\n",
      "LD9188                    | LD9188                    | 0.9962\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 127 done in 3.1s | train_loss=0.0002  valid_loss=0.5356  valid_acc=77.26%\n",
      "\n",
      "no improvement for 46/100 epochs\n",
      "\n",
      "→ Starting epoch 128  (printing every 43 iters)\n",
      "[Epoch 128] iter 43/43, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VAU8115                   | VAU8115                   | 0.9992\n",
      "WA8029J                   | WA8029J                   | 0.9769\n",
      "QAA65T                    | QAA65T                    | 0.9993\n",
      "WNH553                    | WNH553                    | 0.9979\n",
      "QAX6109                   | QAX6109                   | 0.9727\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 128 done in 3.1s | train_loss=0.0002  valid_loss=0.5383  valid_acc=76.97%\n",
      "\n",
      "no improvement for 47/100 epochs\n",
      "\n",
      "→ Starting epoch 129  (printing every 43 iters)\n",
      "[Epoch 129] iter 43/43, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAR2857                   | QAR2857                   | 0.9969\n",
      "GOLD!5333                 | GOLD!5333                 | 0.9627\n",
      "QRK6337                   | QRK6337                   | 0.9846\n",
      "WWN6994                   | WWN6994                   | 0.9766\n",
      "RAQ!7877                  | RAQ!7877                  | 0.9769\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 129 done in 3.1s | train_loss=0.0002  valid_loss=0.5355  valid_acc=76.97%\n",
      "\n",
      "no improvement for 48/100 epochs\n",
      "\n",
      "→ Starting epoch 130  (printing every 43 iters)\n",
      "[Epoch 130] iter 43/43, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QTQ1531                   | QTQ1531                   | 0.9839\n",
      "TBH1267                   | TBH1267                   | 0.9934\n",
      "PPR3334                   | PPR3334                   | 0.9281\n",
      "QAB8000C                  | QAB8000C                  | 0.9939\n",
      "JLW!8830                  | JLW!8830                  | 0.9726\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 130 done in 3.1s | train_loss=0.0002  valid_loss=0.5371  valid_acc=76.97%\n",
      "\n",
      "no improvement for 49/100 epochs\n",
      "\n",
      "→ Starting epoch 131  (printing every 43 iters)\n",
      "[Epoch 131] iter 43/43, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QMU3453                   | QMU3453                   | 0.9686\n",
      "NCH9890                   | NCH9890                   | 0.9982\n",
      "FF6061                    | FF6061                    | 0.9714\n",
      "QCH9191                   | QCH9191                   | 0.9684\n",
      "QAA3323X                  | QAA3323X                  | 0.9816\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 131 done in 3.2s | train_loss=0.0002  valid_loss=0.5419  valid_acc=76.97%\n",
      "\n",
      "no improvement for 50/100 epochs\n",
      "\n",
      "→ Starting epoch 132  (printing every 43 iters)\n",
      "[Epoch 132] iter 43/43, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VBV198                    | VBV198                    | 0.9287\n",
      "VFD892                    | VFD892                    | 0.9704\n",
      "SYF8254                   | SYF8254                   | 0.9793\n",
      "VGK9975                   | VGK9975                   | 0.9881\n",
      "JKH9699                   | JKH9699                   | 0.9932\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 132 done in 3.2s | train_loss=0.0002  valid_loss=0.5294  valid_acc=77.26%\n",
      "\n",
      "no improvement for 51/100 epochs\n",
      "\n",
      "→ Starting epoch 133  (printing every 43 iters)\n",
      "[Epoch 133] iter 43/43, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "TCJ!8981                  | TCJ!8981                  | 0.9532\n",
      "VJR!1999                  | VJR!1999                  | 0.9641\n",
      "BPA!4342                  | BPA!4342                  | 0.9622\n",
      "BEP3409                   | BEP3409                   | 0.9938\n",
      "WKX!6755                  | WKX!6755                  | 0.9889\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 133 done in 3.1s | train_loss=0.0002  valid_loss=0.5335  valid_acc=76.68%\n",
      "\n",
      "no improvement for 52/100 epochs\n",
      "\n",
      "→ Starting epoch 134  (printing every 43 iters)\n",
      "[Epoch 134] iter 43/43, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "NBG8520                   | NBG8520                   | 0.9748\n",
      "VLT!8466                  | VLT!8466                  | 0.9722\n",
      "QLB8533                   | QLB8533                   | 0.9967\n",
      "WWH!9169                  | WWH!9169                  | 0.9780\n",
      "VFD892                    | VFD892                    | 0.9794\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 134 done in 3.2s | train_loss=0.0002  valid_loss=0.5285  valid_acc=77.26%\n",
      "\n",
      "no improvement for 53/100 epochs\n",
      "\n",
      "→ Starting epoch 135  (printing every 43 iters)\n",
      "[Epoch 135] iter 43/43, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WJH663                    | WJH663                    | 0.9838\n",
      "QCB!3923                  | QCB!3923                  | 0.9768\n",
      "AMT5830                   | AMT5830                   | 0.9758\n",
      "QAB751H                   | QAB751H                   | 0.9974\n",
      "QKL8220                   | QKL8220                   | 0.9846\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 135 done in 3.1s | train_loss=0.0002  valid_loss=0.5456  valid_acc=76.97%\n",
      "\n",
      "no improvement for 54/100 epochs\n",
      "\n",
      "→ Starting epoch 136  (printing every 43 iters)\n",
      "[Epoch 136] iter 43/43, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "SJA8556                   | SJA8556                   | 0.9712\n",
      "WA!7920W                  | WA!7920W                  | 0.9680\n",
      "VAW4421                   | VAW4421                   | 0.9996\n",
      "VAW!902                   | VAW!902                   | 0.9671\n",
      "QM6676C                   | QM6676C                   | 0.9506\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 136 done in 3.1s | train_loss=0.0001  valid_loss=0.5430  valid_acc=76.68%\n",
      "\n",
      "no improvement for 55/100 epochs\n",
      "\n",
      "→ Starting epoch 137  (printing every 43 iters)\n",
      "[Epoch 137] iter 43/43, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WEC4500                   | WEC4500                   | 0.9888\n",
      "VEN634                    | VEN634                    | 0.9725\n",
      "PMQ2551                   | PMQ2551                   | 0.9986\n",
      "PMW!7851                  | PMW!7851                  | 0.9744\n",
      "QS1815T                   | QS1815T                   | 0.9994\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 137 done in 3.1s | train_loss=0.0001  valid_loss=0.5428  valid_acc=76.97%\n",
      "\n",
      "no improvement for 56/100 epochs\n",
      "\n",
      "→ Starting epoch 138  (printing every 43 iters)\n",
      "[Epoch 138] iter 43/43, avg loss: 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QM!155J                   | QM!155J                   | 0.9770\n",
      "QTR!80                    | QTR!80                    | 0.9770\n",
      "QAG3688                   | QAG3688                   | 0.9995\n",
      "QAA844Q                   | QAA844Q                   | 0.9987\n",
      "WDJ9407                   | WDJ9407                   | 0.9718\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 138 done in 3.1s | train_loss=0.0002  valid_loss=0.5377  valid_acc=76.68%\n",
      "\n",
      "no improvement for 57/100 epochs\n",
      "\n",
      "→ Starting epoch 139  (printing every 43 iters)\n",
      "[Epoch 139] iter 43/43, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAA!4494H                 | QAA!4494H                 | 0.9693\n",
      "QCS5289                   | QCS5289                   | 0.9775\n",
      "QM!3571G                  | QM!3571G                  | 0.9734\n",
      "SW2769                    | SW2769                    | 0.9837\n",
      "SB5563D                   | SB5563D                   | 0.9672\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 139 done in 3.1s | train_loss=0.0001  valid_loss=0.5355  valid_acc=77.84%\n",
      "\n",
      "no improvement for 58/100 epochs\n",
      "\n",
      "→ Starting epoch 140  (printing every 43 iters)\n",
      "[Epoch 140] iter 43/43, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WC3255U                   | WC3255U                   | 0.9864\n",
      "QSU9715                   | QSU9715                   | 0.9819\n",
      "BQP!5287                  | BQP!5287                  | 0.9540\n",
      "ADY!2688                  | ADY!2688                  | 0.9662\n",
      "JRP7041                   | JRP7041                   | 0.9830\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 140 done in 3.1s | train_loss=0.0001  valid_loss=0.5360  valid_acc=76.68%\n",
      "\n",
      "no improvement for 59/100 epochs\n",
      "\n",
      "→ Starting epoch 141  (printing every 43 iters)\n",
      "[Epoch 141] iter 43/43, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WYJ7760                   | WYJ7760                   | 0.9694\n",
      "WA868H                    | WA868H                    | 0.9931\n",
      "WJT342                    | WJT342                    | 0.9589\n",
      "T/NA3623                  | T/NA3623                  | 0.9960\n",
      "QAB1928E                  | QAB1928E                  | 0.9976\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 141 done in 3.2s | train_loss=0.0001  valid_loss=0.5410  valid_acc=76.68%\n",
      "\n",
      "no improvement for 60/100 epochs\n",
      "\n",
      "→ Starting epoch 142  (printing every 43 iters)\n",
      "[Epoch 142] iter 43/43, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VET612                    | VET612                    | 0.9404\n",
      "VEN!9194                  | VEN!9194                  | 0.9945\n",
      "JRN!7985                  | JRN!7985                  | 0.9934\n",
      "WTE!2868                  | WTE!2868                  | 0.9841\n",
      "VGE3354                   | VGE3354                   | 0.9957\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 142 done in 3.1s | train_loss=0.0001  valid_loss=0.5345  valid_acc=77.55%\n",
      "\n",
      "no improvement for 61/100 epochs\n",
      "\n",
      "→ Starting epoch 143  (printing every 43 iters)\n",
      "[Epoch 143] iter 43/43, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QKT8216                   | QKT8216                   | 0.9874\n",
      "PMW!7851                  | PMW!7851                  | 0.9519\n",
      "QCM5317                   | QCM5317                   | 0.9731\n",
      "QM!5826G                  | QM!5826G                  | 0.9908\n",
      "QCE3369                   | QCE3369                   | 0.9948\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 143 done in 3.0s | train_loss=0.0001  valid_loss=0.5375  valid_acc=77.26%\n",
      "\n",
      "no improvement for 62/100 epochs\n",
      "\n",
      "→ Starting epoch 144  (printing every 43 iters)\n",
      "[Epoch 144] iter 43/43, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "BLP1728                   | BLP1728                   | 0.9998\n",
      "VCW2744                   | VCW2744                   | 0.9951\n",
      "QTU!5007                  | QTU!5007                  | 0.9862\n",
      "QAB1928E                  | QAB1928E                  | 0.9878\n",
      "VBU6599                   | VBU6599                   | 0.9772\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 144 done in 3.1s | train_loss=0.0001  valid_loss=0.5389  valid_acc=76.68%\n",
      "\n",
      "no improvement for 63/100 epochs\n",
      "\n",
      "→ Starting epoch 145  (printing every 43 iters)\n",
      "[Epoch 145] iter 43/43, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAA1918D                  | QAA1918D                  | 0.9993\n",
      "WUV!7830                  | WUV!7830                  | 0.9694\n",
      "QD!4211                   | QD!4211                   | 0.9469\n",
      "VDV7199                   | VDV7199                   | 0.9793\n",
      "ST!8309U                  | ST!8309U                  | 0.9725\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 145 done in 3.2s | train_loss=0.0001  valid_loss=0.5472  valid_acc=76.38%\n",
      "\n",
      "no improvement for 64/100 epochs\n",
      "\n",
      "→ Starting epoch 146  (printing every 43 iters)\n",
      "[Epoch 146] iter 43/43, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "HWE8782                   | HWE8782                   | 0.9977\n",
      "QAB9731D                  | QAB9731D                  | 0.9987\n",
      "PMQ2551                   | PMQ2551                   | 0.9973\n",
      "QDB!448                   | QDB!448                   | 0.9557\n",
      "AJJ2772                   | AJJ2772                   | 0.9818\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 146 done in 3.2s | train_loss=0.0001  valid_loss=0.5439  valid_acc=76.68%\n",
      "\n",
      "no improvement for 65/100 epochs\n",
      "\n",
      "→ Starting epoch 147  (printing every 43 iters)\n",
      "[Epoch 147] iter 43/43, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "DDK!6794                  | DDK!6794                  | 0.9827\n",
      "QS110D                    | QS110D                    | 0.9867\n",
      "WYL2575                   | WYL2575                   | 0.9571\n",
      "JLK5650                   | JLK5650                   | 0.9995\n",
      "AHA3878                   | AHA3878                   | 0.9858\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 147 done in 3.2s | train_loss=0.0001  valid_loss=0.5451  valid_acc=76.68%\n",
      "\n",
      "no improvement for 66/100 epochs\n",
      "\n",
      "→ Starting epoch 148  (printing every 43 iters)\n",
      "[Epoch 148] iter 43/43, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WWN6994                   | WWN6994                   | 0.9792\n",
      "WFD3645                   | WFD3645                   | 0.9987\n",
      "QCK7738                   | QCK7738                   | 0.9625\n",
      "JVY1699                   | JVY1699                   | 0.9958\n",
      "WUA2082                   | WUA2082                   | 0.9891\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 148 done in 3.2s | train_loss=0.0001  valid_loss=0.5442  valid_acc=77.26%\n",
      "\n",
      "no improvement for 67/100 epochs\n",
      "\n",
      "→ Starting epoch 149  (printing every 43 iters)\n",
      "[Epoch 149] iter 43/43, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WUX4391                   | WUX4391                   | 0.9779\n",
      "BRY8828                   | BRY8828                   | 0.9841\n",
      "KDB9833                   | KDB9833                   | 0.9635\n",
      "QLC8072                   | QLC8072                   | 0.9778\n",
      "QAL8533                   | QAL8533                   | 0.9976\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 149 done in 3.2s | train_loss=0.0001  valid_loss=0.5387  valid_acc=77.26%\n",
      "\n",
      "no improvement for 68/100 epochs\n",
      "\n",
      "→ Starting epoch 150  (printing every 43 iters)\n",
      "[Epoch 150] iter 43/43, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "TCN!8474                  | TCN!8474                  | 0.9980\n",
      "NDL585                    | NDL585                    | 0.9741\n",
      "JNV4683                   | JNV4683                   | 0.9987\n",
      "AFM2020                   | AFM2020                   | 0.9990\n",
      "QCH7638                   | QCH7638                   | 0.9911\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 150 done in 3.2s | train_loss=0.0001  valid_loss=0.5460  valid_acc=77.26%\n",
      "\n",
      "no improvement for 69/100 epochs\n",
      "\n",
      "→ Starting epoch 151  (printing every 43 iters)\n",
      "[Epoch 151] iter 43/43, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WQP1991                   | WQP1991                   | 0.9719\n",
      "VJE3434                   | VJE3434                   | 0.9952\n",
      "W3328Q                    | W3328Q                    | 0.9872\n",
      "QAB3330B                  | QAB3330B                  | 0.9982\n",
      "WFG!4626                  | WFG!4626                  | 0.9756\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 151 done in 3.0s | train_loss=0.0001  valid_loss=0.5467  valid_acc=77.26%\n",
      "\n",
      "no improvement for 70/100 epochs\n",
      "\n",
      "→ Starting epoch 152  (printing every 43 iters)\n",
      "[Epoch 152] iter 43/43, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "KEG!9999                  | KEG!9999                  | 0.9432\n",
      "KCT6037                   | KCT6037                   | 0.9969\n",
      "KBJ5226                   | KBJ5226                   | 0.9442\n",
      "QM2377M                   | QM2377M                   | 0.9929\n",
      "TTB8278                   | TTB8278                   | 0.9584\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 152 done in 2.9s | train_loss=0.0001  valid_loss=0.5355  valid_acc=77.26%\n",
      "\n",
      "no improvement for 71/100 epochs\n",
      "\n",
      "→ Starting epoch 153  (printing every 43 iters)\n",
      "[Epoch 153] iter 43/43, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "ALN8722                   | ALN8722                   | 0.9645\n",
      "TCD!6404                  | TCD!6404                  | 0.9611\n",
      "QD1811                    | QD1811                    | 0.9992\n",
      "BLP1728                   | BLP1728                   | 0.9999\n",
      "JSH9196                   | JSH9196                   | 0.9868\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 153 done in 3.0s | train_loss=0.0001  valid_loss=0.5489  valid_acc=76.97%\n",
      "\n",
      "no improvement for 72/100 epochs\n",
      "\n",
      "→ Starting epoch 154  (printing every 43 iters)\n",
      "[Epoch 154] iter 43/43, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "NEA1254                   | NEA1254                   | 0.9754\n",
      "SD2901V                   | SD2901V                   | 0.9947\n",
      "NEA5163                   | NEA5163                   | 0.9780\n",
      "WXY6928                   | WXY6928                   | 0.9996\n",
      "WUX4391                   | WUX4391                   | 0.9779\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 154 done in 2.9s | train_loss=0.0001  valid_loss=0.5525  valid_acc=77.26%\n",
      "\n",
      "no improvement for 73/100 epochs\n",
      "\n",
      "→ Starting epoch 155  (printing every 43 iters)\n",
      "[Epoch 155] iter 43/43, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QS9953S                   | QS9953S                   | 0.9934\n",
      "RU8892                    | RU8892                    | 0.9965\n",
      "QTY9455                   | QTY9455                   | 0.9992\n",
      "WC3255U                   | WC3255U                   | 0.9881\n",
      "AM9232                    | AM9232                    | 0.9922\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 155 done in 2.9s | train_loss=0.0001  valid_loss=0.5459  valid_acc=77.26%\n",
      "\n",
      "no improvement for 74/100 epochs\n",
      "\n",
      "→ Starting epoch 156  (printing every 43 iters)\n",
      "[Epoch 156] iter 43/43, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAA7961C                  | QAA7961C                  | 0.9824\n",
      "QAV8900                   | QAV8900                   | 0.9934\n",
      "MAV!2430                  | MAV!2430                  | 0.9818\n",
      "QTM8880                   | QTM8880                   | 0.9929\n",
      "QTR!80                    | QTR!80                    | 0.9848\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 156 done in 2.9s | train_loss=0.0001  valid_loss=0.5486  valid_acc=77.26%\n",
      "\n",
      "no improvement for 75/100 epochs\n",
      "\n",
      "→ Starting epoch 157  (printing every 43 iters)\n",
      "[Epoch 157] iter 43/43, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "AJH9714                   | AJH9714                   | 0.9881\n",
      "QAA5515N                  | QAA5515N                  | 0.9989\n",
      "T/JA6344                  | T/JA6344                  | 0.9786\n",
      "BEQ8584                   | BEQ8584                   | 0.9837\n",
      "BHP7067                   | BHP7067                   | 0.9748\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 157 done in 3.0s | train_loss=0.0001  valid_loss=0.5469  valid_acc=77.26%\n",
      "\n",
      "no improvement for 76/100 epochs\n",
      "\n",
      "→ Starting epoch 158  (printing every 43 iters)\n",
      "[Epoch 158] iter 43/43, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QRR9945                   | QRR9945                   | 0.9906\n",
      "VEQ6291                   | VEQ6291                   | 0.9970\n",
      "VGK9975                   | VGK9975                   | 0.9946\n",
      "WC8053R                   | WC8053R                   | 0.9526\n",
      "RAM6682                   | RAM6682                   | 0.9994\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 158 done in 3.1s | train_loss=0.0001  valid_loss=0.5390  valid_acc=77.55%\n",
      "\n",
      "no improvement for 77/100 epochs\n",
      "\n",
      "→ Starting epoch 159  (printing every 43 iters)\n",
      "[Epoch 159] iter 43/43, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "SAB8373                   | SAB8373                   | 0.9613\n",
      "QAN8882                   | QAN8882                   | 0.9981\n",
      "KAK2779                   | KAK2779                   | 0.9997\n",
      "VCQ7119                   | VCQ7119                   | 0.9571\n",
      "SWM7576                   | SWM7576                   | 0.9949\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 159 done in 3.0s | train_loss=0.0001  valid_loss=0.5471  valid_acc=76.68%\n",
      "\n",
      "no improvement for 78/100 epochs\n",
      "\n",
      "→ Starting epoch 160  (printing every 43 iters)\n",
      "[Epoch 160] iter 43/43, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "WTW6533                   | WTW6533                   | 0.9985\n",
      "JSF2692                   | JSF2692                   | 0.9788\n",
      "VEN634                    | VEN634                    | 0.9851\n",
      "JLX!1296                  | JLX!1296                  | 0.9930\n",
      "JVD7333                   | JVD7333                   | 0.9539\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 160 done in 3.1s | train_loss=0.0001  valid_loss=0.5504  valid_acc=76.97%\n",
      "\n",
      "no improvement for 79/100 epochs\n",
      "\n",
      "→ Starting epoch 161  (printing every 43 iters)\n",
      "[Epoch 161] iter 43/43, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAN!23                    | QAN!23                    | 0.9767\n",
      "AMC6830                   | AMC6830                   | 0.9945\n",
      "T/NA3623                  | T/NA3623                  | 0.9824\n",
      "VEQ6031                   | VEQ6031                   | 0.9610\n",
      "QM9779R                   | QM9779R                   | 0.9695\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 161 done in 3.0s | train_loss=0.0001  valid_loss=0.5461  valid_acc=77.55%\n",
      "\n",
      "no improvement for 80/100 epochs\n",
      "\n",
      "→ Starting epoch 162  (printing every 43 iters)\n",
      "[Epoch 162] iter 43/43, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "JWW9378                   | JWW9378                   | 0.9649\n",
      "QCR!8846                  | QCR!8846                  | 0.9760\n",
      "QS6338M                   | QS6338M                   | 0.9989\n",
      "DR4467                    | DR4467                    | 0.9860\n",
      "VLU1213                   | VLU1213                   | 0.9994\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 162 done in 3.1s | train_loss=0.0001  valid_loss=0.5438  valid_acc=77.26%\n",
      "\n",
      "no improvement for 81/100 epochs\n",
      "\n",
      "→ Starting epoch 163  (printing every 43 iters)\n",
      "[Epoch 163] iter 43/43, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QCS7968                   | QCS7968                   | 0.9930\n",
      "QCR6004                   | QCR6004                   | 0.9819\n",
      "VKD2793                   | VKD2793                   | 0.9507\n",
      "VNM324                    | VNM324                    | 0.9995\n",
      "QCD!2889                  | QCD!2889                  | 0.9649\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 163 done in 3.0s | train_loss=0.0001  valid_loss=0.5521  valid_acc=76.68%\n",
      "\n",
      "no improvement for 82/100 epochs\n",
      "\n",
      "→ Starting epoch 164  (printing every 43 iters)\n",
      "[Epoch 164] iter 43/43, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "ABX8314                   | ABX8314                   | 0.9949\n",
      "AKG9611                   | AKG9611                   | 0.9990\n",
      "JLK5650                   | JLK5650                   | 0.9971\n",
      "QAB9656H                  | QAB9656H                  | 0.9961\n",
      "AER7905                   | AER7905                   | 0.9708\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 164 done in 3.0s | train_loss=0.0001  valid_loss=0.5480  valid_acc=76.68%\n",
      "\n",
      "no improvement for 83/100 epochs\n",
      "\n",
      "→ Starting epoch 165  (printing every 43 iters)\n",
      "[Epoch 165] iter 43/43, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QCJ!6565                  | QCJ!6565                  | 0.9796\n",
      "QPA3725                   | QPA3725                   | 0.9304\n",
      "QS!8781R                  | QS!8781R                  | 0.9854\n",
      "QCB!1921                  | QCB!1921                  | 0.9562\n",
      "RW6398                    | RW6398                    | 0.9267\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 165 done in 3.0s | train_loss=0.0001  valid_loss=0.5498  valid_acc=77.55%\n",
      "\n",
      "no improvement for 84/100 epochs\n",
      "\n",
      "→ Starting epoch 166  (printing every 43 iters)\n",
      "[Epoch 166] iter 43/43, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAN8882                   | QAN8882                   | 0.9979\n",
      "T/M232                    | T/M232                    | 0.9875\n",
      "BDR!2148                  | BDR!2148                  | 0.9464\n",
      "WVV2948                   | WVV2948                   | 0.9790\n",
      "QAB373                    | QAB373                    | 0.9977\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 166 done in 2.9s | train_loss=0.0001  valid_loss=0.5549  valid_acc=77.26%\n",
      "\n",
      "no improvement for 85/100 epochs\n",
      "\n",
      "→ Starting epoch 167  (printing every 43 iters)\n",
      "[Epoch 167] iter 43/43, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "JLX!6457                  | JLX!6457                  | 0.9893\n",
      "UMK!8883                  | UMK!8883                  | 0.9418\n",
      "T/WC3                     | T/WC3                     | 0.9589\n",
      "UNIMAS6119                | UNIMAS6119                | 0.9893\n",
      "VJR!1999                  | VJR!1999                  | 0.9707\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 167 done in 3.0s | train_loss=0.0001  valid_loss=0.5459  valid_acc=77.26%\n",
      "\n",
      "no improvement for 86/100 epochs\n",
      "\n",
      "→ Starting epoch 168  (printing every 43 iters)\n",
      "[Epoch 168] iter 43/43, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAA3618X                  | QAA3618X                  | 0.9740\n",
      "NCH!6650                  | NCH!6650                  | 0.9802\n",
      "JUJ!7630                  | JUJ!7630                  | 0.9960\n",
      "WFX7807                   | WFX7807                   | 0.9634\n",
      "QAV8900                   | QAV8900                   | 0.9762\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 168 done in 2.9s | train_loss=0.0001  valid_loss=0.5486  valid_acc=77.26%\n",
      "\n",
      "no improvement for 87/100 epochs\n",
      "\n",
      "→ Starting epoch 169  (printing every 43 iters)\n",
      "[Epoch 169] iter 43/43, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAA2660J                  | QAA2660J                  | 0.9899\n",
      "PPT549                    | PPT549                    | 0.9519\n",
      "QAL8533                   | QAL8533                   | 0.9778\n",
      "VAH!7666                  | VAH!7666                  | 0.9812\n",
      "PPD2622                   | PPD2622                   | 0.9543\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 169 done in 2.9s | train_loss=0.0001  valid_loss=0.5488  valid_acc=76.97%\n",
      "\n",
      "no improvement for 88/100 epochs\n",
      "\n",
      "→ Starting epoch 170  (printing every 43 iters)\n",
      "[Epoch 170] iter 43/43, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "PPA!4817                  | PPA!4817                  | 0.9525\n",
      "VNA!4207                  | VNA!4207                  | 0.9899\n",
      "WYV3365                   | WYV3365                   | 0.9573\n",
      "SD2367N                   | SD2367N                   | 0.9997\n",
      "QMV!5505                  | QMV!5505                  | 0.9428\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 170 done in 3.0s | train_loss=0.0001  valid_loss=0.5504  valid_acc=77.26%\n",
      "\n",
      "no improvement for 89/100 epochs\n",
      "\n",
      "→ Starting epoch 171  (printing every 43 iters)\n",
      "[Epoch 171] iter 43/43, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "BQU8338                   | BQU8338                   | 0.9984\n",
      "TCA7789                   | TCA7789                   | 0.9873\n",
      "SJB6000                   | SJB6000                   | 0.9458\n",
      "QCJ4164                   | QCJ4164                   | 0.9957\n",
      "KFL!5361                  | KFL!5361                  | 0.9527\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 171 done in 3.0s | train_loss=0.0001  valid_loss=0.5571  valid_acc=76.97%\n",
      "\n",
      "no improvement for 90/100 epochs\n",
      "\n",
      "→ Starting epoch 172  (printing every 43 iters)\n",
      "[Epoch 172] iter 43/43, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "VBB457                    | VBB457                    | 0.9365\n",
      "QAK!8791                  | QAK!8791                  | 0.9794\n",
      "MDJ5126                   | MDJ5126                   | 0.9888\n",
      "QKH4199                   | QKH4199                   | 0.9633\n",
      "QS!8781R                  | QS!8781R                  | 0.9977\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 172 done in 3.1s | train_loss=0.0001  valid_loss=0.5502  valid_acc=76.97%\n",
      "\n",
      "no improvement for 91/100 epochs\n",
      "\n",
      "→ Starting epoch 173  (printing every 43 iters)\n",
      "[Epoch 173] iter 43/43, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QRB8366                   | QRB8366                   | 0.9661\n",
      "VCW2744                   | VCW2744                   | 0.9951\n",
      "QAA6398C                  | QAA6398C                  | 0.9804\n",
      "SWM7576                   | SWM7576                   | 0.9723\n",
      "WDC!4844                  | WDC!4844                  | 0.9977\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 173 done in 3.1s | train_loss=0.0001  valid_loss=0.5497  valid_acc=76.68%\n",
      "\n",
      "no improvement for 92/100 epochs\n",
      "\n",
      "→ Starting epoch 174  (printing every 43 iters)\n",
      "[Epoch 174] iter 43/43, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QKE9575                   | QKE9575                   | 0.9846\n",
      "QCL3857                   | QCL3857                   | 0.9268\n",
      "MDP!3394                  | MDP!3394                  | 0.9677\n",
      "PKA!440                   | PKA!440                   | 0.9715\n",
      "QAR2857                   | QAR2857                   | 0.9927\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 174 done in 3.1s | train_loss=0.0001  valid_loss=0.5500  valid_acc=76.97%\n",
      "\n",
      "no improvement for 93/100 epochs\n",
      "\n",
      "→ Starting epoch 175  (printing every 43 iters)\n",
      "[Epoch 175] iter 43/43, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "JWU3907                   | JWU3907                   | 0.9748\n",
      "VGH!8312                  | VGH!8312                  | 0.9760\n",
      "WUX4391                   | WUX4391                   | 0.9857\n",
      "QCJ2794                   | QCJ2794                   | 0.9945\n",
      "T/BB2347                  | T/BB2347                  | 0.9971\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 175 done in 3.1s | train_loss=0.0001  valid_loss=0.5542  valid_acc=76.38%\n",
      "\n",
      "no improvement for 94/100 epochs\n",
      "\n",
      "→ Starting epoch 176  (printing every 43 iters)\n",
      "[Epoch 176] iter 43/43, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QA                        | QA                        | 0.9880\n",
      "VAP!5570                  | VAP!5570                  | 0.9608\n",
      "WLH6202                   | WLH6202                   | 0.9814\n",
      "KCT6037                   | KCT6037                   | 0.9976\n",
      "RP!5366                   | RP!5366                   | 0.9592\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 176 done in 3.1s | train_loss=0.0001  valid_loss=0.5494  valid_acc=77.84%\n",
      "\n",
      "no improvement for 95/100 epochs\n",
      "\n",
      "→ Starting epoch 177  (printing every 43 iters)\n",
      "[Epoch 177] iter 43/43, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QAR6858                   | QAR6858                   | 0.9987\n",
      "T/AA823                   | T/AA823                   | 0.9845\n",
      "W3426P                    | W3426P                    | 0.9524\n",
      "QMW!65                    | QMW!65                    | 0.9699\n",
      "WD1915A                   | WD1915A                   | 0.9805\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 177 done in 3.1s | train_loss=0.0001  valid_loss=0.5458  valid_acc=77.55%\n",
      "\n",
      "no improvement for 96/100 epochs\n",
      "\n",
      "→ Starting epoch 178  (printing every 43 iters)\n",
      "[Epoch 178] iter 43/43, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QCF471                    | QCF471                    | 0.9394\n",
      "AMC6830                   | AMC6830                   | 0.9851\n",
      "QMW7697                   | QMW7697                   | 0.9720\n",
      "JSG1987                   | JSG1987                   | 0.9998\n",
      "WA3593F                   | WA3593F                   | 0.9730\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 178 done in 3.0s | train_loss=0.0001  valid_loss=0.5605  valid_acc=76.68%\n",
      "\n",
      "no improvement for 97/100 epochs\n",
      "\n",
      "→ Starting epoch 179  (printing every 43 iters)\n",
      "[Epoch 179] iter 43/43, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "QCE3983                   | QCE3983                   | 0.9622\n",
      "JRP7041                   | JRP7041                   | 0.9803\n",
      "WXX!2093                  | WXX!2093                  | 0.9928\n",
      "RAY!5050                  | RAY!5050                  | 0.9993\n",
      "AMR9699                   | AMR9699                   | 0.9480\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 179 done in 2.9s | train_loss=0.0001  valid_loss=0.5541  valid_acc=76.97%\n",
      "\n",
      "no improvement for 98/100 epochs\n",
      "\n",
      "→ Starting epoch 180  (printing every 43 iters)\n",
      "[Epoch 180] iter 43/43, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "RT1911                    | RT1911                    | 0.9764\n",
      "QAL6939                   | QAL6939                   | 0.9986\n",
      "VNA!4207                  | VNA!4207                  | 0.9641\n",
      "QAA5522R                  | QAA5522R                  | 0.9891\n",
      "QAA6198S                  | QAA6198S                  | 0.9983\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 180 done in 3.0s | train_loss=0.0001  valid_loss=0.5625  valid_acc=77.26%\n",
      "\n",
      "no improvement for 99/100 epochs\n",
      "\n",
      "→ Starting epoch 181  (printing every 43 iters)\n",
      "[Epoch 181] iter 43/43, avg loss: 0.0001\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | AvgConfidence\n",
      "--------------------------------------------------------------------------------\n",
      "W!6916B                   | W!6916B                   | 0.9795\n",
      "QAA6816Q                  | QAA6816Q                  | 0.9977\n",
      "MCU1994                   | MCU1994                   | 0.9664\n",
      "DCS!3819                  | DCS!3819                  | 0.9695\n",
      "SYP9169                   | SYP9169                   | 0.9599\n",
      "--------------------------------------------------------------------------------\n",
      "==> Epoch 181 done in 3.0s | train_loss=0.0001  valid_loss=0.5605  valid_acc=77.26%\n",
      "\n",
      "no improvement for 100/100 epochs\n",
      "\n",
      "🔚 Early stopping: val_acc hasn't improved for 100 epochs.\n"
     ]
    }
   ],
   "source": [
    "# ─── Cell 6: training w/ history, best‐model saving + EARLY STOPPING ───\n",
    "\n",
    "# hyper‑params\n",
    "best_val_acc   = 0.0\n",
    "history        = {'epoch': [], 'train_loss': [], 'val_loss': [], 'val_acc': []}\n",
    "\n",
    "patience_cnt   = 0           # how many epochs since last improvement\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    print(f\"→ Starting epoch {epoch}  (printing every {PRINT_EVERY} iters)\")\n",
    "    model.train()\n",
    "    epoch_loss = Averager()\n",
    "    start = time.time()\n",
    "\n",
    "    # ─── training ──────────────────────────────────────────────────────────\n",
    "    for i, (images, texts) in enumerate(train_loader, 1):\n",
    "        images = images.to(device)\n",
    "\n",
    "        text, length   = converter.encode(texts, batch_max_length=MAX_LABEL_LENGTH)\n",
    "        text_input     = text[:, :-1].to(device)\n",
    "        text_target    = text[:,  1:].to(device)\n",
    "\n",
    "        preds = model(\n",
    "            images,\n",
    "            text=text_input,\n",
    "            is_train=True,\n",
    "            batch_max_length=MAX_LABEL_LENGTH\n",
    "        )  # [B, S, C]\n",
    "        B, S, C = preds.size()\n",
    "        loss = criterion(\n",
    "            preds.view(B * S, C),\n",
    "            text_target.contiguous().view(B * S)\n",
    "        )\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "        optimizer.step()\n",
    "        epoch_loss.add(loss)\n",
    "\n",
    "        # mini‐table prints\n",
    "        if i % PRINT_EVERY == 0:\n",
    "            print(f\"[Epoch {epoch}] iter {i}/{len(train_loader)}, avg loss: {epoch_loss.val():.4f}\", flush=True)\n",
    "            with torch.no_grad():\n",
    "                probs     = preds.softmax(2)\n",
    "                max_vals, max_inds = probs.max(2)\n",
    "                pred_strs = converter.decode(max_inds, length)\n",
    "                pred_strs = [s.split('[s]')[0] for s in pred_strs]\n",
    "\n",
    "            print(\"-\" * 80)\n",
    "            print(f\"{'Ground Truth':25s} | {'Prediction':25s} | AvgConfidence\")\n",
    "            print(\"-\" * 80)\n",
    "            for gt, pr, conf_seq in zip(texts[:5], pred_strs[:5], max_vals[:5]):\n",
    "                conf = conf_seq.mean().item()\n",
    "                print(f\"{gt:25s} | {pr:25s} | {conf_seq.mean().item():.4f}\")\n",
    "            print(\"-\" * 80)\n",
    "\n",
    "    # ─── validation ────────────────────────────────────────────────────────\n",
    "    val_loss, val_acc = validate(model, val_loader)\n",
    "    elapsed   = time.time() - start\n",
    "    train_l   = epoch_loss.val()\n",
    "    print(f\"==> Epoch {epoch} done in {elapsed:.1f}s | \"\n",
    "          f\"train_loss={train_l:.4f}  valid_loss={val_loss:.4f}  valid_acc={val_acc:.2f}%\\n\")\n",
    "\n",
    "    # ─── record history ───────────────────────────────────────────────────\n",
    "    history['epoch'].append(epoch)\n",
    "    history['train_loss'].append(train_l)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "\n",
    "    # ─── best‑model tracking & early‑stopping logic ───────────────────────\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"best_attention_crnn_!_notps.pth\")\n",
    "        print(f\"💾 New best model saved (epoch {epoch}, val_acc={val_acc:.2f}%)\\n\")\n",
    "        patience_cnt = 0                          # reset counter\n",
    "    else:\n",
    "        patience_cnt += 1\n",
    "        print(f\"no improvement for {patience_cnt}/{PATIENCE} epochs\\n\")\n",
    "        if patience_cnt >= PATIENCE:\n",
    "            print(f\"🔚 Early stopping: val_acc hasn't improved for {PATIENCE} epochs.\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b49a536f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3.127119</td>\n",
       "      <td>2.760642</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.533146</td>\n",
       "      <td>2.322703</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2.125827</td>\n",
       "      <td>1.874093</td>\n",
       "      <td>0.291545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.816238</td>\n",
       "      <td>1.663414</td>\n",
       "      <td>0.291545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.519804</td>\n",
       "      <td>1.272076</td>\n",
       "      <td>1.749271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>177</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.545848</td>\n",
       "      <td>77.551020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>178</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.560509</td>\n",
       "      <td>76.676385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>179</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.554052</td>\n",
       "      <td>76.967930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>180</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.562494</td>\n",
       "      <td>77.259475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>181</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.560500</td>\n",
       "      <td>77.259475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>181 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     epoch  train_loss  val_loss    val_acc\n",
       "0        1    3.127119  2.760642   0.000000\n",
       "1        2    2.533146  2.322703   0.000000\n",
       "2        3    2.125827  1.874093   0.291545\n",
       "3        4    1.816238  1.663414   0.291545\n",
       "4        5    1.519804  1.272076   1.749271\n",
       "..     ...         ...       ...        ...\n",
       "176    177    0.000110  0.545848  77.551020\n",
       "177    178    0.000108  0.560509  76.676385\n",
       "178    179    0.000107  0.554052  76.967930\n",
       "179    180    0.000108  0.562494  77.259475\n",
       "180    181    0.000105  0.560500  77.259475\n",
       "\n",
       "[181 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clean_history = {\n",
    "  'epoch':      history['epoch'],\n",
    "  'train_loss': [x.cpu().item() if hasattr(x, 'cpu') else x for x in history['train_loss']],\n",
    "  'val_loss':   [x.cpu().item() if hasattr(x, 'cpu') else x for x in history['val_loss']],\n",
    "  'val_acc':    [x.cpu().item() if hasattr(x, 'cpu') else x for x in history['val_acc']],\n",
    "}\n",
    "df = pd.DataFrame(clean_history)\n",
    "display(df)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(df['epoch'], df['train_loss'], label='Train Loss')\n",
    "plt.plot(df['epoch'], df['val_loss'],   label='Val Loss')\n",
    "plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.legend()\n",
    "plt.title('Loss over Epochs')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(df['epoch'], df['val_acc'],   label='Val Accuracy')\n",
    "plt.xlabel('Epoch'); plt.ylabel('Accuracy (%)'); plt.legend()\n",
    "plt.title('Val Accuracy over Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe117ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ─── Cell 9: ONNX export via isolated inference head ─────────────────────────\n",
    "# import torch\n",
    "\n",
    "# class CRNNInference(torch.nn.Module):\n",
    "#     def __init__(self, crnn, max_len):\n",
    "#         super().__init__()\n",
    "#         # use exactly the names printed out by your inspection\n",
    "#         self.Transformation     = crnn.Transformation\n",
    "#         self.FeatureExtraction = crnn.FeatureExtraction\n",
    "#         self.AdaptiveAvgPool    = crnn.AdaptiveAvgPool\n",
    "#         self.SequenceModeling   = crnn.SequenceModeling\n",
    "#         self.Prediction         = crnn.Prediction\n",
    "#         self.max_len           = max_len\n",
    "#         # adjust this if your converter stores start-token under a different key\n",
    "#         self.start_id          = crnn.converter.dict['[GO]']\n",
    "\n",
    "#     def forward(self, image):\n",
    "#         # 1) Spatial‐transformer + feature CNN\n",
    "#         x = self.Transformation(image)                     # [B, C, H, W]\n",
    "#         x = self.FeatureExtraction(x)                      # [B, C, H, W]\n",
    "\n",
    "#         # 2) Pool down height to 1\n",
    "#         x = self.AdaptiveAvgPool(x)                        # [B, C, 1, W]\n",
    "#         x = x.squeeze(2)                                   # [B, C, W]\n",
    "#         x = x.permute(0, 2, 1)                             # [B, W, C]\n",
    "\n",
    "#         # 3) 2‐layer BiLSTM\n",
    "#         contextual = self.SequenceModeling(x)              # [B, W, hidden]\n",
    "\n",
    "#         # 4) Dummy “[GO]” token vector\n",
    "#         B = contextual.size(0)\n",
    "#         dummy_text = torch.full(\n",
    "#             (B,),\n",
    "#             self.start_id,\n",
    "#             dtype=torch.long,\n",
    "#             device=image.device\n",
    "#         )  # shape [B]\n",
    "\n",
    "#         # 5) Attention decoder (inference path)\n",
    "#         return self.Prediction(\n",
    "#             batch_H           = contextual,\n",
    "#             text              = dummy_text,\n",
    "#             is_train          = False,\n",
    "#             batch_max_length  = self.max_len\n",
    "#         )\n",
    "\n",
    "# # Wrap and export\n",
    "# inference_model = CRNNInference(model, BATCH_MAX_LENGTH).eval()\n",
    "# dummy_img       = torch.randn(1, INPUT_CHANNEL, IMG_HEIGHT, IMG_WIDTH, device=device)\n",
    "\n",
    "# torch.onnx.export(\n",
    "#     inference_model,\n",
    "#     dummy_img,\n",
    "#     \"best_attention_crnn.onnx\",\n",
    "#     input_names   = ['image'],\n",
    "#     output_names  = ['logits'],\n",
    "#     dynamic_axes  = {\n",
    "#         'image':  {0: 'batch'},\n",
    "#         'logits': {0: 'batch', 1: 'time'}\n",
    "#     },\n",
    "#     opset_version = 13,\n",
    "# )\n",
    "\n",
    "# print(\"✅ Exported best_attention_crnn.onnx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9587a5dc",
   "metadata": {},
   "source": [
    "# DUMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99a300a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ─── cell 6: attention‐based training loop ──────────────────────────────────────\n",
    "# for epoch in range(1, NUM_EPOCHS+1):\n",
    "#     print(f\"→ Starting epoch {epoch}  (printing every {PRINT_EVERY} iters)\")\n",
    "#     model.train()\n",
    "#     epoch_loss = Averager()\n",
    "#     start      = time.time()\n",
    "\n",
    "#     for i, (images, texts) in enumerate(train_loader, 1):\n",
    "#         images = images.to(device)\n",
    "\n",
    "#         # encode with [GO] & [s]; also get lengths\n",
    "#         text, length = converter.encode(texts, batch_max_length=BATCH_MAX_LENGTH)\n",
    "#         text_input  = text[:, :-1].to(device)   # drop final [s]\n",
    "#         text_target = text[:,  1:].to(device)   # everything after [GO]\n",
    "\n",
    "#         # forward + loss\n",
    "#         preds = model(images,\n",
    "#                       text=text_input,\n",
    "#                       is_train=True,\n",
    "#                       batch_max_length=BATCH_MAX_LENGTH)  # [B, S, C]\n",
    "#         B, S, C = preds.size()\n",
    "#         loss = criterion(\n",
    "#             preds.view(B * S, C),\n",
    "#             text_target.contiguous().view(B * S)\n",
    "#         )\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "#         optimizer.step()\n",
    "#         epoch_loss.add(loss)\n",
    "\n",
    "#         if i % PRINT_EVERY == 0 or i == 1:\n",
    "#             print(f\"[Epoch {epoch}] iter {i}/{len(train_loader)}, avg loss: {epoch_loss.val():.4f}\", flush=True)\n",
    "\n",
    "#             # quick greedy‐decode\n",
    "#             with torch.no_grad():\n",
    "#                 probs        = preds.softmax(2)           # [B, S, C]\n",
    "#                 max_vals, max_inds = probs.max(2)         # [B, S]\n",
    "#                 pred_strs    = converter.decode(max_inds, length)\n",
    "#                 pred_strs    = [s.split('[s]')[0] for s in pred_strs]\n",
    "\n",
    "#             # print a mini‐table\n",
    "#             print(\"-\" * 80)\n",
    "#             print(f\"{'Ground Truth':25s} | {'Prediction':25s} | AvgConfidence\")\n",
    "#             print(\"-\" * 80)\n",
    "#             for gt, pr, conf_seq in zip(texts[:5], pred_strs[:5], max_vals[:5]):\n",
    "#                 conf = conf_seq.mean().item()\n",
    "#                 print(f\"{gt:25s} | {pr:25s} | {conf:0.4f}\")\n",
    "#             print(\"-\" * 80)\n",
    "\n",
    "#     # end‐of‐epoch validation\n",
    "#     val_loss, val_acc = validate(model, val_loader)\n",
    "#     elapsed = time.time() - start\n",
    "#     print(f\"==> Epoch {epoch} done in {elapsed:.1f}s | \"\n",
    "#           f\"train_loss={epoch_loss.val():.4f}\"\n",
    "#           f\"  valid_loss={val_loss:.4f}  valid_acc={val_acc:.2f}%\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d861ce44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ─── Cell 6: training w/ history, best‐model saving ───\n",
    "\n",
    "# # hyper‐params\n",
    "# best_val_acc    = 0.0\n",
    "# history         = {'epoch': [], 'train_loss': [], 'val_loss': [], 'val_acc': []}\n",
    "\n",
    "# for epoch in range(1, NUM_EPOCHS+1):\n",
    "#     print(f\"→ Starting epoch {epoch}  (printing every {PRINT_EVERY} iters)\")\n",
    "#     model.train()\n",
    "#     epoch_loss = Averager()\n",
    "#     start = time.time()\n",
    "\n",
    "#     # ─── training ─────────────────────────────────────────────────────────────\n",
    "#     for i, (images, texts) in enumerate(train_loader, 1):\n",
    "#         images = images.to(device)\n",
    "\n",
    "#         text, length   = converter.encode(texts, batch_max_length=MAX_LABEL_LENGTH)\n",
    "#         text_input     = text[:, :-1].to(device)\n",
    "#         text_target    = text[:,  1:].to(device)\n",
    "\n",
    "#         preds = model(\n",
    "#             images,\n",
    "#             text=text_input,\n",
    "#             is_train=True,\n",
    "#             batch_max_length=MAX_LABEL_LENGTH\n",
    "#         )  # [B, S, C]\n",
    "#         B, S, C = preds.size()\n",
    "#         loss = criterion(\n",
    "#             preds.view(B * S, C),\n",
    "#             text_target.contiguous().view(B * S)\n",
    "#         )\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "#         optimizer.step()\n",
    "#         epoch_loss.add(loss)\n",
    "\n",
    "#         # mini‐table prints\n",
    "#         if i % PRINT_EVERY == 0:\n",
    "#             print(f\"[Epoch {epoch}] iter {i}/{len(train_loader)}, avg loss: {epoch_loss.val():.4f}\", flush=True)\n",
    "#             with torch.no_grad():\n",
    "#                 probs     = preds.softmax(2)\n",
    "#                 max_vals, max_inds = probs.max(2)\n",
    "#                 pred_strs = converter.decode(max_inds, length)\n",
    "#                 pred_strs = [s.split('[s]')[0] for s in pred_strs]\n",
    "\n",
    "#             print(\"-\" * 80)\n",
    "#             print(f\"{'Ground Truth':25s} | {'Prediction':25s} | AvgConfidence\")\n",
    "#             print(\"-\" * 80)\n",
    "#             for gt, pr, conf_seq in zip(texts[:5], pred_strs[:5], max_vals[:5]):\n",
    "#                 conf = conf_seq.mean().item()\n",
    "#                 print(f\"{gt:25s} | {pr:25s} | {conf_seq.mean().item():.4f}\")\n",
    "#             print(\"-\" * 80)\n",
    "\n",
    "#     # ─── validation ────────────────────────────────────────────────────────────\n",
    "#     val_loss, val_acc = validate(model, val_loader)\n",
    "#     elapsed = time.time() - start\n",
    "#     train_l = epoch_loss.val()\n",
    "#     print(f\"==> Epoch {epoch} done in {elapsed:.1f}s | \"\n",
    "#           f\"train_loss={train_l:.4f}  valid_loss={val_loss:.4f}  valid_acc={val_acc:.2f}%\\n\")\n",
    "\n",
    "#     # ─── record history & save best ──────────────────────────────────────────\n",
    "#     history['epoch'].append(epoch)\n",
    "#     history['train_loss'].append(train_l)\n",
    "#     history['val_loss'].append(val_loss)\n",
    "#     history['val_acc'].append(val_acc)\n",
    "\n",
    "#     if val_acc > best_val_acc:\n",
    "#         best_val_acc = val_acc\n",
    "#         torch.save(model.state_dict(), \"best_attention_crnn_!.pth\")\n",
    "#         print(f\"💾 New best model saved (epoch {epoch}, val_acc={val_acc:.2f}%)\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
