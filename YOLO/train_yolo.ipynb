{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f1f2f6c",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1309460",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import glob\n",
    "import shutil\n",
    "import json\n",
    "import yaml\n",
    "from pprint import pprint\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc30b8c",
   "metadata": {},
   "source": [
    "## Check CUDA availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a18cf216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "Device Name: NVIDIA GeForce RTX 5070 Ti\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(\"CUDA Available:\", cuda_available)\n",
    "\n",
    "# If CUDA is available, print details\n",
    "if cuda_available:\n",
    "    DEVICE = torch.cuda.current_device()\n",
    "    device_name = torch.cuda.get_device_name(DEVICE)\n",
    "    print(f\"Device Name: {device_name}\")\n",
    "\n",
    "else:\n",
    "    print(\"CUDA is not available. Please check your GPU drivers and CUDA installation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb981f91",
   "metadata": {},
   "source": [
    "## Global Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b431505d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for reproducibility\n",
    "RANDOM_SEED = 300188\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "\n",
    "# Dataset directory\n",
    "DATASET_DIR = \"datasets/Vehicle-License-Plate-Detection\"\n",
    "# YAML config for dataset splits and class names\n",
    "DATA_YAML = os.path.join(DATASET_DIR, \"data.yaml\")\n",
    "\n",
    "# Unique project identifier\n",
    "PROJECT_NAME = \"vehicle-license-plate-detection\"\n",
    "# Which version of the dataset to use\n",
    "DATASET_VERSION = \"final\"\n",
    "# Tag for this set of hyperparameters / training settings\n",
    "EXPERIMENT_NAME = \"imgsz1280-500\"\n",
    "\n",
    "RUN_DIR = os.path.join(PROJECT_NAME, DATASET_VERSION, EXPERIMENT_NAME)\n",
    "\n",
    "# Base folder for saving evaluation outputs\n",
    "EVALUATION_DIR = os.path.join(RUN_DIR, \"evaluation\")\n",
    "# Base folder for saving model architecture & hyperparameters\n",
    "ARCHITECTURE_DIR = os.path.join(RUN_DIR, \"architecture\")\n",
    "\n",
    "# Location of the best-performing weights file of the trained model \n",
    "TRAINED_MODEL_WEIGHTS = os.path.join(RUN_DIR, \"weights/best.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc9de15",
   "metadata": {},
   "source": [
    "## Dataset Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11bd9e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split complete:\n",
      "  train: 1279 images\n",
      "  valid: 182 images\n",
      "  test : 365 images\n"
     ]
    }
   ],
   "source": [
    "# ─── CONFIG ────────────────────────────────────────────────────────────\n",
    "TRAIN_IMG_DIR  = os.path.join(DATASET_DIR, \"train\", \"images\")\n",
    "TRAIN_LBL_DIR  = os.path.join(DATASET_DIR, \"train\", \"labels\")\n",
    "VAL_IMG_DIR    = os.path.join(DATASET_DIR, \"valid\", \"images\")\n",
    "VAL_LBL_DIR    = os.path.join(DATASET_DIR, \"valid\", \"labels\")\n",
    "TEST_IMG_DIR   = os.path.join(DATASET_DIR, \"test\",  \"images\")\n",
    "TEST_LBL_DIR   = os.path.join(DATASET_DIR, \"test\",  \"labels\")\n",
    "\n",
    "# Split ratios\n",
    "TRAIN_RATIO = 7\n",
    "VAL_RATIO   = 1\n",
    "\n",
    "# Ensure reproducibility\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "# 1️⃣ Ensure split directories exist\n",
    "for d in (TRAIN_IMG_DIR, TRAIN_LBL_DIR, VAL_IMG_DIR, VAL_LBL_DIR):\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "# 2️⃣ Gather current train & valid images\n",
    "train_imgs_before = glob.glob(os.path.join(TRAIN_IMG_DIR, \"*.jpg\")) + \\\n",
    "                    glob.glob(os.path.join(TRAIN_IMG_DIR, \"*.png\"))\n",
    "val_imgs_before   = glob.glob(os.path.join(VAL_IMG_DIR,   \"*.jpg\")) + \\\n",
    "                    glob.glob(os.path.join(VAL_IMG_DIR,   \"*.png\"))\n",
    "test_imgs_before   = glob.glob(os.path.join(TEST_IMG_DIR,   \"*.jpg\")) + \\\n",
    "                    glob.glob(os.path.join(TEST_IMG_DIR,   \"*.png\"))\n",
    "\n",
    "# 3️⃣ Compute how many should be in valid after split\n",
    "total_images = len(train_imgs_before) + len(val_imgs_before) + len(test_imgs_before)\n",
    "# Desired count for validation based on overall ratio\n",
    "desired_val   = int(total_images * VAL_RATIO / 10)\n",
    "\n",
    "# 4️⃣ Shuffle and pick from train\n",
    "all_train_imgs = train_imgs_before.copy()\n",
    "random.shuffle(all_train_imgs)\n",
    "\n",
    "# 5️⃣ Determine how many to move into validation\n",
    "n_val_to_move = max(0, desired_val - len(val_imgs_before))\n",
    "val_to_move   = all_train_imgs[:n_val_to_move]\n",
    "\n",
    "# 6️⃣ Move images & corresponding labels\n",
    "for img_path in val_to_move:\n",
    "    fname   = os.path.basename(img_path)\n",
    "    stem    = os.path.splitext(fname)[0]\n",
    "    lbl_src = os.path.join(TRAIN_LBL_DIR, stem + \".txt\")\n",
    "    # Move image file to validation folder\n",
    "    shutil.move(img_path, os.path.join(VAL_IMG_DIR, fname))\n",
    "    # Move label file if it exists\n",
    "    if os.path.exists(lbl_src):\n",
    "        shutil.move(lbl_src, os.path.join(VAL_LBL_DIR, stem + \".txt\"))\n",
    "\n",
    "# 7️⃣ Report final counts\n",
    "final_train_count = len(glob.glob(os.path.join(TRAIN_IMG_DIR, \"*.jpg\"))) + \\\n",
    "                    len(glob.glob(os.path.join(TRAIN_IMG_DIR, \"*.png\")))\n",
    "final_val_count   = len(glob.glob(os.path.join(VAL_IMG_DIR,   \"*.jpg\"))) + \\\n",
    "                    len(glob.glob(os.path.join(VAL_IMG_DIR,   \"*.png\")))\n",
    "final_test_count  = len(glob.glob(os.path.join(TEST_IMG_DIR,  \"*.jpg\"))) + \\\n",
    "                    len(glob.glob(os.path.join(TEST_IMG_DIR,  \"*.png\")))\n",
    "\n",
    "print(\"Split complete:\")\n",
    "print(f\"  train: {final_train_count} images\")\n",
    "print(f\"  valid: {final_val_count} images\")\n",
    "print(f\"  test : {final_test_count} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe315981",
   "metadata": {},
   "source": [
    "## Ensure full path dataset in data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1302f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original paths:\n",
      "{'test': 'C:/Users/herma/dev/IS/yolo/datasets/Vehicle-License-Plate-Detection/test/images',\n",
      " 'train': 'C:/Users/herma/dev/IS/yolo/datasets/Vehicle-License-Plate-Detection/train/images',\n",
      " 'val': 'C:/Users/herma/dev/IS/yolo/datasets/Vehicle-License-Plate-Detection/valid/images'}\n",
      "\n",
      "Updated paths:\n",
      "{'test': 'C:/Users/herma/dev/IS/yolo/datasets/Vehicle-License-Plate-Detection/test/images',\n",
      " 'train': 'C:/Users/herma/dev/IS/yolo/datasets/Vehicle-License-Plate-Detection/train/images',\n",
      " 'val': 'C:/Users/herma/dev/IS/yolo/datasets/Vehicle-License-Plate-Detection/valid/images'}\n",
      "\n",
      "Modified YAML saved directly to 'datasets/Vehicle-License-Plate-Detection\\data.yaml'\n"
     ]
    }
   ],
   "source": [
    "BASE_DIR = Path(os.getcwd()) / DATASET_DIR\n",
    "\n",
    "# 1️⃣ Load existing YAML\n",
    "with open(DATA_YAML, \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(\"Original paths:\")\n",
    "pprint({k: config.get(k) for k in (\"train\", \"val\", \"test\")})\n",
    "\n",
    "# 2️⃣ Update train/val/test entries to absolute POSIX paths with uppercase drive\n",
    "for split in (\"train\", \"val\", \"test\"):\n",
    "    orig = config.get(split, \"\")\n",
    "    if orig.startswith(\"..\"):\n",
    "        # Build new path by appending subpath beyond '..'\n",
    "        rel = Path(orig)\n",
    "        parts = rel.parts[1:]  # drop leading '..'\n",
    "        new_path = BASE_DIR.joinpath(*parts)\n",
    "    else:\n",
    "        new_path = Path(orig)\n",
    "    # Convert to forward-slash style\n",
    "    path_str = new_path.as_posix()\n",
    "    # Ensure drive letter is uppercase (e.g. 'c:/...' → 'C:/...')\n",
    "    if len(path_str) >= 2 and path_str[1] == ':' and path_str[0].islower():\n",
    "        path_str = path_str[0].upper() + path_str[1:]\n",
    "    config[split] = path_str\n",
    "\n",
    "print(\"\\nUpdated paths:\")\n",
    "pprint({k: config.get(k) for k in (\"train\", \"val\", \"test\")})\n",
    "\n",
    "# 3️⃣ Overwrite data.yaml in place\n",
    "with open(DATA_YAML, \"w\") as f:\n",
    "    yaml.dump(config, f, sort_keys=False)\n",
    "\n",
    "print(f\"\\nModified YAML saved directly to '{DATA_YAML}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227b7039",
   "metadata": {},
   "source": [
    "## Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2fe1bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUGMENT=True\n",
    "\n",
    "HSV_V = 0.2\n",
    "DEGREES = 15.0\n",
    "FLIPUD = 0.25\n",
    "FLIPLR = 0.25\n",
    "MOSAIC = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278a26f0",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2511bace",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_EPOCHS = 500\n",
    "IMAGE_SIZE = 1280\n",
    "BATCH_SIZE = 16\n",
    "PATIENCE = 50\n",
    "NUM_OF_WORKERS = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2b3b2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if AUGMENT:\n",
    "    HYPERPARAMS = {\n",
    "        \"project\": PROJECT_NAME,  # Name of the project\n",
    "        \"name\": os.path.join(DATASET_VERSION, EXPERIMENT_NAME),  # Name of the training run\n",
    "        \"data\": DATA_YAML, # Path to the dataset configuration file\n",
    "        \"epochs\": NUMBER_OF_EPOCHS, # Number of epochs to train for\n",
    "        \"imgsz\": IMAGE_SIZE, # Image size for training (640x640 pixels)\n",
    "        \"batch\": BATCH_SIZE,  # Batch size\n",
    "        \"device\": DEVICE,  # Use GPU if available, otherwise set to -1 for CPU,\n",
    "        \"patience\": PATIENCE,  # Number of epochs with no improvement after which training will be stopped\n",
    "        \"cache\": \"disk\",  # Cache images for faster training\n",
    "        \"workers\": NUM_OF_WORKERS,    # Number of data loading workers\n",
    "\n",
    "        \"hsv_v\":    HSV_V,     # brightness jitter ±20%\n",
    "        \"degrees\":  DEGREES,   # rotation ±15°\n",
    "        \"flipud\":   FLIPUD,    # vertical flip with 25% chance\n",
    "        \"fliplr\":   FLIPLR,    # horizontal flip with 25% chance\n",
    "    }\n",
    "else:\n",
    "    HYPERPARAMS = {\n",
    "        \"project\": PROJECT_NAME,  # Name of the project\n",
    "        \"name\": os.path.join(DATASET_VERSION, EXPERIMENT_NAME),  # Name of the training run\n",
    "        \"data\": DATA_YAML, # Path to the dataset configuration file\n",
    "        \"epochs\": NUMBER_OF_EPOCHS, # Number of epochs to train for\n",
    "        \"imgsz\": IMAGE_SIZE, # Image size for training (640x640 pixels)\n",
    "        \"batch\": BATCH_SIZE,  # Batch size\n",
    "        \"device\": DEVICE,  # Use GPU if available, otherwise set to -1 for CPU,\n",
    "        \"patience\": PATIENCE,  # Number of epochs with no improvement after which training will be stopped\n",
    "        \"cache\": \"disk\",  # Cache images for faster training\n",
    "        \"workers\": NUM_OF_WORKERS,    # Number of data loading workers\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4147f4",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d172fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'YOLO' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m      2\u001b[39m     \u001b[38;5;66;03m# Initialize YOLOv8n model using the pre-trained weights\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     model = \u001b[43mYOLO\u001b[49m(\u001b[33m\"\u001b[39m\u001b[33myolo_pretrained/yolov8n.pt\u001b[39m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# Load a pretrained YOLOv8 model\u001b[39;00m\n\u001b[32m      5\u001b[39m     \u001b[38;5;66;03m# # Start training with the pre-trained weights as the initialization\u001b[39;00m\n\u001b[32m      6\u001b[39m     \u001b[38;5;66;03m# results = model.train(\u001b[39;00m\n\u001b[32m      7\u001b[39m     \u001b[38;5;66;03m#     **HYPERPARAMS,  # Unpack hyperparameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     10\u001b[39m     \u001b[38;5;66;03m# # Export the trained weights to ONNX format once training completes:\u001b[39;00m\n\u001b[32m     11\u001b[39m     \u001b[38;5;66;03m# model.export(format='onnx')\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'YOLO' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Initialize YOLOv8n model using the pre-trained weights\n",
    "    model = YOLO(\"yolo_pretrained/yolov8m.pt\")  # Load a pretrained YOLOv8 model\n",
    "\n",
    "    # Start training with the pre-trained weights as the initialization\n",
    "    results = model.train(\n",
    "        **HYPERPARAMS,  # Unpack hyperparameters\n",
    "    )\n",
    "\n",
    "    # Export the trained weights to ONNX format once training completes:\n",
    "    model.export(format='onnx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3524ecc",
   "metadata": {},
   "source": [
    "## Save Model Architecture & Hyperparamaters used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d10d0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Hyperparameters written to vehicle-license-plate-detection\\final\\imgsz1280-500-augment-n\\architecture\\hyperparameters.json\n",
      "→ Model architecture written to vehicle-license-plate-detection\\final\\imgsz1280-500-augment-n\\architecture\\model_architecture.txt\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(ARCHITECTURE_DIR, exist_ok=True)\n",
    "\n",
    "# 1️⃣ Save hyperparameters as JSON\n",
    "hyp_path = os.path.join(ARCHITECTURE_DIR, \"hyperparameters.json\")\n",
    "with open(hyp_path, \"w\") as f:\n",
    "    json.dump(HYPERPARAMS, f, indent=2)\n",
    "print(f\"→ Hyperparameters written to {hyp_path}\")\n",
    "\n",
    "# 2️⃣ Save the model architecture (as text)\n",
    "arch_path = os.path.join(ARCHITECTURE_DIR, \"model_architecture.txt\")\n",
    "with open(arch_path, \"w\") as f:\n",
    "    f.write(str(model.model))  \n",
    "print(f\"→ Model architecture written to {arch_path}\")\n",
    "\n",
    "# 3️⃣ (Optional) Copy the best weights over\n",
    "best_weights = os.path.join(ARCHITECTURE_DIR, \"weights\", \"best.onnx\")\n",
    "if os.path.isfile(best_weights):\n",
    "    os.replace(best_weights, os.path.join(ARCHITECTURE_DIR, \"best_{EXPERIMENT_NAME}.onnx\"))\n",
    "    print(\"→ Copied best.onnx with custom name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c853eb73",
   "metadata": {},
   "source": [
    "## Testing Dataset Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "527bf855",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINED_MODEL_WEIGHTS = 'vehicle-license-plate-detection/near-complete/imgsz1280-500/weights/best.pt'\n",
    "IMAGE_SIZE = 1280"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "53cf22bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.146  Python-3.13.3 torch-2.7.0+cu128 CUDA:0 (NVIDIA GeForce RTX 5070 Ti, 16303MiB)\n",
      "Model summary (fused): 72 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 3297.01561.6 MB/s, size: 884.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\herma\\dev\\IS\\yolo\\datasets\\Vehicle-License-Plate-Detection\\test\\labels.cache... 365 images, 0 backgrounds, 0 corrupt: 100%|██████████| 365/365 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:02<00:00,  7.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        365       1972      0.897      0.818      0.888        0.7\n",
      "              carplate        363        674      0.941      0.822      0.896      0.637\n",
      "               vehicle        365       1298      0.854      0.814       0.88      0.763\n",
      "Speed: 0.3ms preprocess, 2.7ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Saving vehicle-license-plate-detection\\final\\imgsz1280-500\\evaluation\\0.25\\predictions.json...\n",
      "Results saved to \u001b[1mvehicle-license-plate-detection\\final\\imgsz1280-500\\evaluation\\0.25\u001b[0m\n",
      "Finished evaluation at conf=0.25\n",
      "Ultralytics 8.3.146  Python-3.13.3 torch-2.7.0+cu128 CUDA:0 (NVIDIA GeForce RTX 5070 Ti, 16303MiB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 3730.82375.6 MB/s, size: 431.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\herma\\dev\\IS\\yolo\\datasets\\Vehicle-License-Plate-Detection\\test\\labels.cache... 365 images, 0 backgrounds, 0 corrupt: 100%|██████████| 365/365 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:02<00:00,  8.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        365       1972      0.945      0.772      0.872      0.696\n",
      "              carplate        363        674      0.961      0.774      0.876       0.63\n",
      "               vehicle        365       1298      0.928      0.769      0.869      0.763\n",
      "Speed: 0.4ms preprocess, 2.5ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Saving vehicle-license-plate-detection\\final\\imgsz1280-500\\evaluation\\0.50\\predictions.json...\n",
      "Results saved to \u001b[1mvehicle-license-plate-detection\\final\\imgsz1280-500\\evaluation\\0.50\u001b[0m\n",
      "Finished evaluation at conf=0.50\n",
      "Ultralytics 8.3.146  Python-3.13.3 torch-2.7.0+cu128 CUDA:0 (NVIDIA GeForce RTX 5070 Ti, 16303MiB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 4100.61767.2 MB/s, size: 1201.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\herma\\dev\\IS\\yolo\\datasets\\Vehicle-License-Plate-Detection\\test\\labels.cache... 365 images, 0 backgrounds, 0 corrupt: 100%|██████████| 365/365 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:02<00:00,  8.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        365       1972      0.981      0.674      0.829       0.68\n",
      "              carplate        363        674      0.989      0.671      0.828      0.609\n",
      "               vehicle        365       1298      0.973      0.677       0.83       0.75\n",
      "Speed: 0.3ms preprocess, 2.6ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Saving vehicle-license-plate-detection\\final\\imgsz1280-500\\evaluation\\0.75\\predictions.json...\n",
      "Results saved to \u001b[1mvehicle-license-plate-detection\\final\\imgsz1280-500\\evaluation\\0.75\u001b[0m\n",
      "Finished evaluation at conf=0.75\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # 1️⃣ Load the model once, with task pre-declared\n",
    "    model = YOLO(TRAINED_MODEL_WEIGHTS, task=\"detect\")\n",
    "\n",
    "    # 2️⃣ Evaluate at several confidence thresholds\n",
    "    for conf in (0.25, 0.50, 0.75):\n",
    "        model.val(\n",
    "            data=DATA_YAML,\n",
    "            split=\"test\",\n",
    "            project=EVALUATION_DIR,      \n",
    "            name=f\"{conf:.2f}\",          \n",
    "            exist_ok=True,\n",
    "            workers=NUM_OF_WORKERS,\n",
    "            conf=conf,                   \n",
    "            device=DEVICE,\n",
    "            save_json=True,\n",
    "            half=False,\n",
    "            imgsz=IMAGE_SIZE,\n",
    "        )\n",
    "        print(f\"Finished evaluation at conf={conf:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e811e258",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "371bcded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for reproducibility\n",
    "RANDOM_SEED = 300188\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "\n",
    "# Dataset directory\n",
    "DATASET_DIR = \"datasets/Vehicle-License-Plate-Detection\"\n",
    "# YAML config for dataset splits and class names\n",
    "DATA_YAML = os.path.join(DATASET_DIR, \"data.yaml\")\n",
    "\n",
    "# Unique project identifier\n",
    "PROJECT_NAME = \"vehicle-license-plate-detection\"\n",
    "# Which version of the dataset to use\n",
    "DATASET_VERSION = \"baseline\"\n",
    "# Tag for this set of hyperparameters / training settings\n",
    "EXPERIMENT_NAME = \"default\"\n",
    "\n",
    "RUN_DIR = os.path.join(PROJECT_NAME, DATASET_VERSION, EXPERIMENT_NAME)\n",
    "\n",
    "# Base folder for saving evaluation outputs\n",
    "EVALUATION_DIR = os.path.join(RUN_DIR, \"evaluation\")\n",
    "# Base folder for saving model architecture & hyperparameters\n",
    "ARCHITECTURE_DIR = os.path.join(RUN_DIR, \"architecture\")\n",
    "\n",
    "# Location of the best-performing weights file of the trained model \n",
    "TRAINED_MODEL_WEIGHTS = os.path.join(RUN_DIR, \"weights/best.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7d32eac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINED_MODEL_WEIGHTS = 'vehicle-license-plate-detection/baseline/default/weights/best.pt'\n",
    "IMAGE_SIZE = 640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "19a11fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.146  Python-3.13.3 torch-2.7.0+cu128 CUDA:0 (NVIDIA GeForce RTX 5070 Ti, 16303MiB)\n",
      "Model summary (fused): 72 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 3882.41451.7 MB/s, size: 884.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\herma\\dev\\IS\\yolo\\datasets\\Vehicle-License-Plate-Detection\\test\\labels.cache... 365 images, 0 backgrounds, 0 corrupt: 100%|██████████| 365/365 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:02<00:00, 11.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        365       1972      0.887      0.663      0.801      0.597\n",
      "              carplate        363        674      0.893      0.622      0.775      0.497\n",
      "               vehicle        365       1298       0.88      0.704      0.827      0.696\n",
      "Speed: 0.1ms preprocess, 0.6ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Saving vehicle-license-plate-detection\\baseline\\default\\evaluation\\0.25\\predictions.json...\n",
      "Results saved to \u001b[1mvehicle-license-plate-detection\\baseline\\default\\evaluation\\0.25\u001b[0m\n",
      "Finished evaluation at conf=0.25\n",
      "Ultralytics 8.3.146  Python-3.13.3 torch-2.7.0+cu128 CUDA:0 (NVIDIA GeForce RTX 5070 Ti, 16303MiB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 3826.52573.2 MB/s, size: 431.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\herma\\dev\\IS\\yolo\\datasets\\Vehicle-License-Plate-Detection\\test\\labels.cache... 365 images, 0 backgrounds, 0 corrupt: 100%|██████████| 365/365 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:02<00:00,  9.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        365       1972      0.934      0.622       0.79      0.599\n",
      "              carplate        363        674      0.937      0.576      0.762      0.499\n",
      "               vehicle        365       1298      0.931      0.668      0.818      0.699\n",
      "Speed: 0.1ms preprocess, 0.8ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "Saving vehicle-license-plate-detection\\baseline\\default\\evaluation\\0.50\\predictions.json...\n",
      "Results saved to \u001b[1mvehicle-license-plate-detection\\baseline\\default\\evaluation\\0.50\u001b[0m\n",
      "Finished evaluation at conf=0.50\n",
      "Ultralytics 8.3.146  Python-3.13.3 torch-2.7.0+cu128 CUDA:0 (NVIDIA GeForce RTX 5070 Ti, 16303MiB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 3392.81503.4 MB/s, size: 1201.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\herma\\dev\\IS\\yolo\\datasets\\Vehicle-License-Plate-Detection\\test\\labels.cache... 365 images, 0 backgrounds, 0 corrupt: 100%|██████████| 365/365 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:02<00:00,  9.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        365       1972      0.966      0.555      0.765      0.599\n",
      "              carplate        363        674       0.96      0.496      0.729      0.497\n",
      "               vehicle        365       1298      0.973      0.615        0.8      0.701\n",
      "Speed: 0.1ms preprocess, 0.8ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Saving vehicle-license-plate-detection\\baseline\\default\\evaluation\\0.75\\predictions.json...\n",
      "Results saved to \u001b[1mvehicle-license-plate-detection\\baseline\\default\\evaluation\\0.75\u001b[0m\n",
      "Finished evaluation at conf=0.75\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # 1️⃣ Load the model once, with task pre-declared\n",
    "    model = YOLO(TRAINED_MODEL_WEIGHTS, task=\"detect\")\n",
    "\n",
    "    # 2️⃣ Evaluate at several confidence thresholds\n",
    "    for conf in (0.25, 0.50, 0.75):\n",
    "        model.val(\n",
    "            data=DATA_YAML,\n",
    "            split=\"test\",\n",
    "            project=EVALUATION_DIR,      \n",
    "            name=f\"{conf:.2f}\",          \n",
    "            exist_ok=True,\n",
    "            workers=NUM_OF_WORKERS,\n",
    "            conf=conf,                   \n",
    "            device=DEVICE,\n",
    "            save_json=True,\n",
    "            half=False,\n",
    "            imgsz=IMAGE_SIZE,\n",
    "        )\n",
    "        print(f\"Finished evaluation at conf={conf:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
